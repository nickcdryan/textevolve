
            You are performing SURGICAL REFINEMENT of the single best-performing script.
            Your goal is to identify specific weaknesses in this script and make targeted improvements while preserving its strengths.

            Here are example problems from previously seen data:
            [
  {
    "id": 0,
    "question": "In triangle $ABC,$ $AB = 3$ and $AC = 5.$  Let $O$ be the circumcenter of triangle $ABC.$  Find $\\overrightarrow{OA} \\cdot \\overrightarrow{BC}.$",
    "answer": "Let $\\mathbf{a} = \\overrightarrow{OA},$ $\\mathbf{b} = \\overrightarrow{OB},$ and $\\mathbf{c} = \\overrightarrow{OC}.$  Then\n\\[\\overrightarrow{AB} = \\overrightarrow{OB} - \\overrightarrow{OA} = \\mathbf{b} - \\mathbf{a}.\\]Similarly, $\\overrightarrow{AC} = \\mathbf{c} - \\mathbf{a}$ and $\\overrightarrow{BC} = \\mathbf{c} - \\mathbf{b}.$  We then want to compute\n\\[\\overrightarrow{OA} \\cdot \\overrightarrow{BC} = \\mathbf{a} \\cdot (\\mathbf{c} - \\mathbf{b}) = \\mathbf{a} \\cdot \\mathbf{c} - \\mathbf{a} \\cdot \\mathbf{b}.\\][asy]\nunitsize(2 cm);\n\npair A, B, C, O;\n\nA = dir(100);\nB = dir(200);\nC = dir(340);\nO = (0,0);\n\ndraw(Circle(O,1));\ndraw(A--B--C--cycle);\ndraw(O--A,Arrow(6));\ndraw(O--B,Arrow(6));\ndraw(O--C,Arrow(6));\n\nlabel(\"$A$\", A, A);\nlabel(\"$B$\", B, B);\nlabel(\"$C$\", C, C);\nlabel(\"$O$\", O, NE);\nlabel(\"$\\mathbf{a}$\", A/2, SW);\nlabel(\"$\\mathbf{b}$\", B/2, SE);\nlabel(\"$\\mathbf{c}$\", C/2, SW);\n[/asy]\n\nSince $AC = 5,$ $AC^2 = 25.$  But\n\\begin{align*}\nAC^2 &= \\|\\mathbf{c} - \\mathbf{a}\\|^2 \\\\\n&= (\\mathbf{c} - \\mathbf{a}) \\cdot (\\mathbf{c} - \\mathbf{a}) \\\\\n&= \\|\\mathbf{c}\\|^2 - 2 \\mathbf{a} \\cdot \\mathbf{c} + \\|\\mathbf{a}\\|^2 \\\\\n&= 2R^2 - 2 \\mathbf{a} \\cdot \\mathbf{c},\n\\end{align*}where $R$ is the circumradius.  Hence,\n\\[\\mathbf{a} \\cdot \\mathbf{c} = R^2 - \\frac{AC^2}{2}.\\]Similarly, we can prove that\n\\[\\mathbf{a} \\cdot \\mathbf{b} = R^2 - \\frac{AB^2}{2}.\\]Therefore,\n\\[\\mathbf{a} \\cdot \\mathbf{c} - \\mathbf{a} \\cdot \\mathbf{b} = \\left( R^2 - \\frac{AC^2}{2} \\right) - \\left( R^2 - \\frac{AB^2}{2} \\right) = \\frac{AB^2 - AC^2}{2} = \\frac{3^2 - 5^2}{2} = \\boxed{-8}.\\]"
  },
  {
    "id": 1,
    "question": "The sum of four two-digit numbers is 221. None of the eight digits is $0$ and no two of them are the same. Which of the digits $1$ through $9$ does not appear in one of the four two-digit numbers?",
    "answer": "The sum of the digits 1 through 9 is 45, so the sum of the eight digits is between 36 and 44, inclusive. The sum of the four units digits is between $1 + 2 + 3 + 4 = 10$ and $6 + 7 + 8 + 9 =30$, inclusive, and also ends in 1. Therefore the sum of the units digits is either 11 or 21. If the sum of the units digits is 11, then the sum of the tens digits is 21, so the sum of all eight digits is 32, an impossibility. If the sum of the units digits is 21, then the sum of the tens digits is 20, so the sum of all eight digits is 41. Thus the missing digit is $45 - 41 = \\boxed{4}$. Note that the numbers $13, 25, 86,$ and $97$ sum to $221$."
  },
  {
    "id": 2,
    "question": "On the game board below Kendra will start at the center of the board. For each turn she will spin this spinner with four congruent sectors once, and then she will move one space in the direction indicated on the spinner. The \"Start'' square does not have a numerical value, but Kendra may land on it during her turns. What is the probability that the sum of the numbers in the spaces on which she will land will be exactly 30 after her third complete turn? Express your answer as a common fraction.\n\n[asy]size(80);\nimport graph;\ndraw(Circle((0,0),1),linewidth(1));\ndraw((-1,0)--(1,0),linewidth(1)); draw((0,-1)--(0,1),linewidth(1));\nlabel(\"Move\",(sqrt(2)/4,sqrt(2)/4+.15),fontsize(10pt));\nlabel(\"Left\",(sqrt(2)/4,sqrt(2)/4-.15),fontsize(10pt));\nlabel(\"Move\",(-sqrt(2)/4,sqrt(2)/4+.15),fontsize(10pt));\nlabel(\"Right\",(-sqrt(2)/4,sqrt(2)/4-.15),fontsize(10pt));\nlabel(\"Move\",(-sqrt(2)/4,-(sqrt(2)/4-.15)),fontsize(10pt));\nlabel(\"Down\",(-sqrt(2)/4,-(sqrt(2)/4+.15)),fontsize(10pt));\nlabel(\"Move\",(sqrt(2)/4,-(sqrt(2)/4-.15)),fontsize(10pt));\nlabel(\"Up\",(sqrt(2)/4,-(sqrt(2)/4+.15)),fontsize(10pt));\ndot((0,0),linewidth(5)); draw((0,0)--1/2 dir(-70),linewidth(1.5),EndArrow(5));[/asy]\n\n[asy]size(200);\npicture box10,box15,box5,box20;\nfilldraw(box5,(-1,-.5)--(-1,.5)--(1,.5)--(1,-.5)--cycle,white,linewidth(1)); label(box5,\"5\",(0,0));\nfilldraw(box10,(-1,-.5)--(-1,.5)--(1,.5)--(1,-.5)--cycle,gray(.6),linewidth(1)); label(box10,\"10\",(0,0));\nfilldraw(box15,(-1,-.5)--(-1,.5)--(1,.5)--(1,-.5)--cycle,white,linewidth(1)); label(box15,\"15\",(0,0));\nfilldraw(box20,(-1,-.5)--(-1,.5)--(1,.5)--(1,-.5)--cycle,gray(.6),linewidth(1)); label(box20,\"20\",(0,0));\nvoid b10(real x, real y)\n{\nadd(shift(x*right)*shift(y*up)*box10);\n}\nvoid b15(real x, real y)\n{\nadd(shift(x*right)*shift(y*up)*box15);\n}\nvoid b5(real x, real y)\n{\nadd(shift(x*right)*shift(y*up)*box5);\n}\nvoid b20(real x, real y)\n{\nadd(shift(x*right)*shift(y*up)*box20);\n}\nfor(int i = 0; i<3; ++i)\n{\ndraw((8.5-2.5i,1.5i+2)--(-8.5+2.5i,1.5i+2),linewidth(1));\ndraw((8.5-2.5i,-1.5i-2)--(-8.5+2.5i,-1.5i-2),linewidth(1));\n}\nfor(int i = 0; i<3; ++i)\n{\ndraw((8.5-2.5i,2+1.5i)--(8.5-2.5i,-2-1.5i),linewidth(1));\ndraw((-8.5+2.5i,2+1.5i)--(-8.5+2.5i,-2-1.5i),linewidth(1));\n}\ndraw((8.5,0)--(-8.5,0),linewidth(1));\ndraw((0,5)--(0,-5),linewidth(1));\nfilldraw((-1,1)--(1,1)--(1,-1)--(-1,-1)--cycle,white,linewidth(1)); label(\"Start\",(0,0),fontsize(8pt));\nb10(0,2); b10(-3.5,2); b10(3.5,2); b10(-3.5,0); b10(3.5,0); b10(0,-2); b10(-3.5,-2); b10(3.5,-2); b10(3.5,5); b10(-3.5,5); b10(3.5,-5); b10(-3.5,-5);\nb5(6,0); b5(8.5,0); b5(0,3.5); b5(0,5); b5(0,-3.5); b5(0,-5); b5(3.5,-3.5); b5(3.5,3.5);b5(-3.5,-3.5);b5(-3.5,3.5); b5(-6,0); b5(-8.5,0);\n\nb20(6,3.5); b20(6,-3.5); b20(-6,3.5); b20(-6,-3.5); b20(8.5,2); b20(-8.5,2); b20(8.5,-2); b20(-8.5,-2);\n\nb15(6,2); b15(6,-2); b15(-6,2); b15(-6,-2);[/asy]",
    "answer": "On her first turn, Kendra must get 10 points.  If she wants a total of 30 after three turns, she must then either get two tens in a row or a 5 and then a 15.  To get three tens in a row, she can move any direction on her first move, go in two possible directions for her second move, and go in two possible directions for her third spin, meaning her probability of success is $\\frac{1}{4}$.  On the other hand, if she wants to get a 10, a 5, and a 15, she can only move left or right on her first move, further out on her second move, and then up or down on her third move, leading to a probability of success of $\\frac{1}{2}\\cdot \\frac{1}{4}\\cdot \\frac{1}{2} = \\frac{1}{16}$.  Adding, her total probability is $\\frac{1}{4} + \\frac{1}{16} = \\boxed{\\frac{5}{16}}$."
  }
]

            
        ITERATION HISTORY SUMMARY:
        - Total iterations completed: 5
        - Current explore/exploit balance: 40/40
        - Best accuracy achieved: 1.00 (iteration 3)

        APPROACH HISTORY (last 5 iterations):
        [
  {
    "iteration": 0,
    "strategy": "baseline",
    "accuracy": 0.5,
    "approach": "Simple baseline script: Direct LLM call without sophisticated techniques"
  },
  {
    "iteration": 1,
    "strategy": "refine",
    "accuracy": 0.0,
    "approach": "The script implements a chain-of-thought approach to answer a question by breaking it down into sub-questions, answering each sub-question independently, and then synthesizing the individual answers into a final response. The `main` function orchestrates this process, using `call_llm` to interact with the Gemini model for question breakdown, answering sub-questions, and synthesizing the final answer. No agent roles are explicitly defined. The `call_llm` function is used to send prompts to the LLM and return the response, `main` takes the question and orchestrates the calls to `call_llm` to get the sub-questions, answers to sub-questions, and a final synthesis. The overall workflow involves question decomposition, answering sub-questions, and synthesizing the final answer."
  },
  {
    "iteration": 2,
    "strategy": "explore",
    "accuracy": 0.3333333333333333,
    "approach": "The script employs a two-agent approach using the Gemini LLM to solve math problems: a \"Problem Analyzer\" that formats the question into a structured JSON and a \"Solution Generator\" that produces a step-by-step solution based on the analysis. A third \"Solution Validator\" agent is also used to validate the generated solution against the original question. The problem is decomposed into analysis, solution generation, and validation steps. The `main` function orchestrates the process by calling `analyze_problem` to analyze the input question, then `generate_solution` to create the solution, and finally `validate_solution` to check the solution, and the `call_llm` function is used to call the LLM with different system instructions and prompts for each agent."
  },
  {
    "iteration": 3,
    "strategy": "explore",
    "accuracy": 1.0,
    "approach": "The script employs a \"Decompose-Solve-Verify\" approach using the Gemini LLM, enhanced by multi-example prompting to improve accuracy. The problem is broken down into smaller steps by `decompose_problem`, then `solve_sub_problems` solves these steps, and `synthesize_solutions` combines the solutions into a final answer which is then verified for coherency using `check_coherency`. The `call_llm` function is used as a wrapper to call the Gemini API with different prompts and system instructions, defining roles like \"expert at decomposing complex math problems\" for each step. The overall workflow involves decomposing the initial question, solving the sub-problems, synthesizing the solutions, verifying that the response is coherent and then returning the final answer or an error message if the coherency check fails."
  },
  {
    "iteration": 4,
    "strategy": "explore",
    "accuracy": 0.6666666666666666,
    "approach": "The script employs a \"Knowledge Retrieval and Solution Synthesis\" approach using the Gemini LLM with specialized agents. First, `retrieve_knowledge` retrieves relevant information based on the input question, acting as a knowledge retrieval expert. The `verify_knowledge_retrieval` function then verifies the relevance of the knowledge. Finally, `synthesize_solution` acts as a solution synthesis expert, generating a step-by-step solution using the retrieved knowledge. The overall workflow involves retrieving knowledge, verifying it, and then synthesizing a solution based on that knowledge."
  }
]

        COMMON ERROR PATTERNS:
        []

        PRIMARY ISSUES (last 3 iterations):
        [
  {
    "iteration": 0,
    "issue": "The most critical problem to fix is the **inaccuracy in performing arithmetic and logical calculations**. This includes median calculation, LCM calculations, and general numerical manipulation errors within algebraic solutions. This undermines the entire solution process, even if the initial problem setup and equation formulation are correct."
  },
  {
    "iteration": 1,
    "issue": "The most critical problem is the consistent failure of the LLM call due to a `NoneType` argument. This suggests a data processing stage before the LLM call is producing a `None` value unexpectedly, which is then being passed as an argument when it should be an iterable. We need to identify *where* this `None` is originating and *why*."
  },
  {
    "iteration": 2,
    "issue": "The most critical problem is the **inconsistent and incomplete application of constraints within the problem statement**. This results in misinterpretations, contradictions, and ultimately, incorrect solutions or the system giving up."
  },
  {
    "iteration": 3,
    "issue": "Given there are no error cases to analyze, there is no primary issue to fix."
  },
  {
    "iteration": 4,
    "issue": "The most critical problem to fix is the **incomplete enumeration of possibilities and the lack of rigorous constraint enforcement**. This leads to undercounting favorable outcomes in probability problems or overlooking invalid solutions in other problem types. The system needs a better mechanism to ensure all possibilities are considered and that solutions are rigorously checked against constraints."
  }
]

        TARGETED IMPROVEMENTS:
        [
  "Develop More Robust Board State Representation and Transition Logic:** For game board problems, improve the internal representation of the board state and the logic for determining valid transitions between states. This might involve using graph structures or state transition tables.",
  "Implement a Numerical Verification Module:** Integrate a numerical verification module to double-check the correctness of arithmetic computations. This could involve unit testing or using an external calculator to confirm results. For median calculation, explicitly check all values and their positions in sorted order.",
  "Enhanced Constraint Handling:** Add explicit checks and validation steps to ensure all problem constraints are considered throughout the solution process. This could involve using automated constraint satisfaction techniques or incorporating constraint programming elements.",
  "Constraint Programming Techniques:** Incorporate constraint programming techniques to represent and manage constraints explicitly, allowing the system to prune search paths that violate constraints early on.",
  "Implement a Systematic Search Algorithm:** Employ a search algorithm (e.g., backtracking, breadth-first search) to systematically explore all possible solutions, ensuring that no possibility is overlooked.",
  "Return a default response indicating that the system was unable to solve the problem.",
  "Add more Print Statements for Future Debugging:** Add more print statements to show the intermediate stages of calculations so that in the future you can tell where things went wrong.",
  "Generate an error message that is more informative than the current \"Error calling LLM\" message.",
  "Add Explicit Verification Steps:** Include explicit verification steps in the solution process, where each candidate solution is rigorously checked against all constraints.",
  "Retry the LLM call with slightly different parameters (e.g., a shorter question, a different prompt)."
]
        

EXAMPLE OF EFFECTIVE LLM USAGE PATTERNS:

```python
def extract_information_with_examples(text):
    """Extract key information from the input text using embedded examples."""
    system_instruction = "You are an information extraction specialist focusing on identifying key entities and relationships."
    
    prompt = f"""
    Extract key information from this text. Focus on identifying all entities, relationships, and important attributes.
    
    Example usage:
    
    Input Text:
    The company XYZ Corp reported quarterly earnings of $3.5 million, which represents a 12% increase from last year. The CEO, Jane Smith, attributed this growth to their new product line launched in March, which has already captured 8% of the market share. They expect to expand their operations to Europe by Q2 2023.
    
    Let's think step by step.
    
    The key entities are:
    - XYZ Corp (company)
    - Jane Smith (person, CEO)
    - New product line (product)
    
    The key information points are:
    - Financial: Quarterly earnings of $3.5 million
    - Performance: 12% increase from previous year
    - Product: New product line launched in March
    - Market: 8% market share for new product
    - Plans: Expansion to Europe by Q2 2023
    
    Extracted Information:
    {{
      "entities": [
        {{"name": "XYZ Corp", "type": "company"}},
        {{"name": "Jane Smith", "type": "person", "role": "CEO"}},
        {{"name": "New product line", "type": "product", "launch_date": "March"}}
      ],
      "financial_data": {{
        "quarterly_earnings": "$3.5 million",
        "growth_rate": "12%"
      }},
      "market_data": {{
        "product_market_share": "8%"
      }},
      "future_plans": [
        {{"type": "expansion", "region": "Europe", "timeline": "Q2 2023"}}
      ]
    }}
    
    Now, extract information from this new text:
    {text}
    """
    
    return call_llm(prompt, system_instruction)
```

```python
def verify_solution_with_examples(problem, proposed_solution):
    """Verify if the proposed solution satisfies all requirements using embedded examples."""
    system_instruction = "You are a critical evaluator who verifies if solutions correctly address problems."
    
    prompt = f"""
    Verify if this proposed solution correctly addresses all aspects of the problem.
    
    Example usage:
    
    Problem:
    Design a data structure that can efficiently perform the following operations:
    1. Insert a value
    2. Delete a value
    3. Get a random value with equal probability for all stored values
    All operations should have average time complexity of O(1).
    
    Proposed Solution:
    I'll use a combination of a hashmap and an array. The hashmap will store the value as the key and its index in the array as the value. The array will store all the inserted values.
    
    For insert: Add the value to the end of the array and update the hashmap with the value and its index. O(1) time.
    
    For delete: Look up the index of the value in the hashmap, swap the value with the last element in the array, update the hashmap for the swapped element, remove the last element from the array, and remove the value from the hashmap. O(1) time.
    
    For get random: Generate a random index within the array's bounds and return the value at that index. O(1) time.
    
    Verification:
    Let me check each requirement:
    1. Insert operation: The solution adds the value to the end of the array and updates the hashmap with O(1) time complexity ✓
    2. Delete operation: The solution uses the hashmap to find the index, then swaps with the last element and updates accordingly with O(1) time complexity ✓
    3. Get random operation: The solution generates a random index within the array bounds with O(1) time complexity ✓
    4. All operations have O(1) average time complexity ✓
    
    Result: VALID - The solution correctly addresses all requirements with the specified time complexity.
    
    Problem:
    {problem}
    
    Proposed Solution:
    {proposed_solution}
    
    Verification:
    """
    
    return call_llm(prompt, system_instruction)
```

```python
def solve_with_validation_loop(problem, max_attempts=3):
    """Solve a problem with iterative refinement through validation feedback loop."""
    system_instruction_solver = "You are an expert problem solver who creates detailed, correct solutions."
    system_instruction_validator = "You are a critical validator who carefully checks solutions against all requirements."
    
    # Initial solution generation
    solution_prompt = f"""
    Provide a detailed solution to this problem. Be thorough and ensure you address all requirements.
    
    Problem:
    {problem}
    """
    
    solution = call_llm(solution_prompt, system_instruction_solver)
    
    # Validation loop
    for attempt in range(max_attempts):
        # Validate the current solution
        validation_prompt = f"""
        Carefully validate if this solution correctly addresses all aspects of the problem.
        If the solution is valid, respond with "VALID: [brief reason]".
        If the solution has any issues, respond with "INVALID: [detailed explanation of issues]".
        
        Problem:
        {problem}
        
        Proposed Solution:
        {solution}
        """
        
        validation_result = call_llm(validation_prompt, system_instruction_validator)
        
        # Check if solution is valid
        if validation_result.startswith("VALID:"):
            return solution
        
        # If invalid, refine the solution
        refined_prompt = f"""
        Your previous solution to this problem has some issues that need to be addressed.
        
        Problem:
        {problem}
        
        Your previous solution:
        {solution}
        
        Validation feedback:
        {validation_result}
        
        Please provide a completely revised solution that addresses all the issues mentioned.
        """
        
        solution = call_llm(refined_prompt, system_instruction_solver)
    
    return solution
```

```python
def multi_perspective_analysis(problem):
    """Analyze a problem from multiple specialized perspectives and synthesize the insights."""
    # Define specialized analysis functions
    def analyze_factual_content(problem):
        system_instruction = "You are a factual analyst who focuses on identifying key facts and data points."
        prompt = f"""
        Analyze this problem for factual content only. Identify explicit facts, constraints, and requirements.
        
        Problem:
        {problem}
        """
        return call_llm(prompt, system_instruction)
    
    def analyze_structure(problem):
        system_instruction = "You are a structural analyst who specializes in problem organization and patterns."
        prompt = f"""
        Analyze the structure of this problem. Identify its components, relationships, and patterns.
        
        Problem:
        {problem}
        """
        return call_llm(prompt, system_instruction)
    
    # Execute parallel analyses
    factual_analysis = analyze_factual_content(problem)
    structural_analysis = analyze_structure(problem)
    
    # Synthesize the results
    synthesis_prompt = f"""
    Synthesize these two different analyses of the same problem into a comprehensive understanding.
    
    Factual Analysis:
    {factual_analysis}
    
    Structural Analysis:
    {structural_analysis}
    
    Provide a unified analysis that leverages both perspectives.
    """
    
    return call_llm(synthesis_prompt, "You are an insight synthesizer who combines multiple analyses.")
```

```python
def best_of_n_approach(problem, n=3):
    """Generate multiple solutions and select the best one based on a quality evaluation."""
    system_instruction_solver = "You are an expert problem solver who provides detailed, correct solutions."
    system_instruction_evaluator = "You are a quality evaluator who assesses solutions based on correctness, completeness, and clarity."
    
    # Generate n different solutions
    solutions = []
    for i in range(n):
        diversity_factor = f"Solution approach {i+1}/{n}: Use a different perspective from previous solutions."
        solution_prompt = f"""
        Provide a detailed solution to this problem.
        {diversity_factor if i > 0 else ""}
        
        Problem:
        {problem}
        """
        
        solutions.append(call_llm(solution_prompt, system_instruction_solver))
    
    # Evaluate each solution
    evaluations = []
    for i, solution in enumerate(solutions):
        evaluation_prompt = f"""
        Evaluate this solution on correctness, completeness, and clarity (1-10 scale).
        
        Problem:
        {problem}
        
        Solution {i+1}:
        {solution}
        
        Provide your evaluation as a JSON with scores and explanation.
        """
        
        evaluations.append(call_llm(evaluation_prompt, system_instruction_evaluator))
    
    # Find the best solution
    comparison_prompt = f"""
    Compare these solutions and their evaluations. Select the best one.
    
    Problem:
    {problem}
    
    {["Solution " + str(i+1) + ": " + solutions[i] + "\n\nEvaluation: " + evaluations[i] for i in range(n)]}
    
    Which solution is best? Respond with the solution number and explanation.
    """
    
    best_solution_index = int(call_llm(comparison_prompt, "You are a solution selector.").split()[1]) - 1
    return solutions[best_solution_index]
```

```python
def solve_with_react_pattern(problem):
    """Solve problems through iterative Reasoning and Acting (ReAct) approach."""
    system_instruction = "You are a problem-solving agent that follows the ReAct pattern: Reason about the current state, take an Action, observe the result, and repeat until reaching a solution."
    
    # Initialize ReAct process
    prompt = f"""
    Solve this problem using the ReAct pattern - alternate between Reasoning and Acting until you reach a final answer.
    
    Example usage:
    
    Problem: What is the capital of the country where the Great Barrier Reef is located, and what is the population of that capital?
    
    Thought 1: I need to determine which country the Great Barrier Reef is in, then find its capital, and finally the population of that capital.
    Action 1: Search[Great Barrier Reef location]
    Observation 1: The Great Barrier Reef is located off the coast of Queensland in northeastern Australia.
    
    Thought 2: Now I know the Great Barrier Reef is in Australia. I need to find Australia's capital city.
    Action 2: Search[capital of Australia]
    Observation 2: The capital of Australia is Canberra.
    
    Thought 3: Now I need to find the population of Canberra.
    Action 3: Search[population of Canberra]
    Observation 3: As of 2021, the population of Canberra is approximately 431,500.
    
    Thought 4: I have found all the required information. The capital of Australia (where the Great Barrier Reef is located) is Canberra, and its population is approximately 431,500.
    Action 4: Finish[The capital of Australia is Canberra, with a population of approximately 431,500.]
    
    Now solve this new problem:
    {problem}
    
    Start with Thought 1:
    """
    
    # Initial reasoning and action planning
    react_response = call_llm(prompt, system_instruction)
    
    # Extract the action from the response
    action = extract_action(react_response)
    
    # Continue the ReAct loop until we reach a "Finish" action
    while not action["type"] == "Finish":
        # Perform the requested action and get an observation
        if action["type"] == "Search":
            observation = perform_search(action["query"])
        elif action["type"] == "Calculate":
            observation = perform_calculation(action["expression"])
        elif action["type"] == "Lookup":
            observation = perform_lookup(action["term"])
        else:
            observation = f"Unknown action type: {action['type']}"
        
        # Continue the ReAct process with the new observation
        continuation_prompt = f"""
        {react_response}
        Observation {action["step_number"]}: {observation}
        
        Continue with the next thought and action:
        """
        
        # Get the next reasoning step and action
        react_response += "\n" + call_llm(continuation_prompt, system_instruction)
        
        # Extract the next action
        action = extract_action(react_response)
    
    # Extract the final answer from the Finish action
    final_answer = action["answer"]
    return final_answer

def extract_action(text):
    """Parse the ReAct response to extract the current action."""
    # Find the last action in the text
    action_matches = re.findall(r"Action (\d+): (\w+)\[(.*?)\]", text)
    if not action_matches:
        return {"type": "Error", "step_number": 0, "query": "No action found"}
    
    # Get the most recent action
    last_action = action_matches[-1]
    step_number = int(last_action[0])
    action_type = last_action[1]
    action_content = last_action[2]
    
    # Handle different action types
    if action_type == "Finish":
        return {"type": "Finish", "step_number": step_number, "answer": action_content}
    elif action_type in ["Search", "Lookup", "Calculate"]:
        return {"type": action_type, "step_number": step_number, "query": action_content}
    else:
        return {"type": "Unknown", "step_number": step_number, "query": action_content}

def perform_search(query):
    """Simulate a search action in the ReAct pattern."""
    # In a real implementation, this would call an actual search API
    return call_llm(f"Provide a factual answer about: {query}", "You are a helpful search engine that provides concise, factual information.")

def perform_calculation(expression):
    """Perform a calculation action in the ReAct pattern."""
    try:
        # Safely evaluate the expression
        result = eval(expression, {"__builtins__": {}}, {"math": math})
        return f"The result is {result}"
    except Exception as e:
        return f"Error in calculation: {str(e)}"

def perform_lookup(term):
    """Simulate a lookup action for specific information."""
    # In a real implementation, this would query a knowledge base or database
    return call_llm(f"Provide specific information about: {term}", "You are a knowledge base that provides specific factual information.")
```MULTI-EXAMPLE PROMPTING GUIDANCE:
        1. CRITICAL: Use MULTIPLE examples (2-5) in EVERY LLM prompt, not just one
        2. Vary the number of examples based on task complexity - more complex tasks need more examples
        3. Select diverse examples that showcase different patterns and edge cases
        4. Structure your few-shot examples to demonstrate clear step-by-step reasoning
        5. Consider using both "easy" and "challenging" examples to help the LLM learn from contrasts
        6. The collection of examples should collectively cover all key aspects of the problem
        7. When available, use examples from previous iterations that revealed specific strengths or weaknesses.
        8. USE REAL EXAMPLES FROM THE DATASET WHERE POSSIBLE!!

        Example of poor single-example prompting:
        ```python
        def extract_entities(text):
            prompt = f'''
            Extract entities from this text.

            Example:
            Text: John will meet Mary at 3pm on Tuesday.
            Entities: {{"people": ["John", "Mary"], "time": "3pm", "day": "Tuesday"}}

            Text: {text}
            Entities:
            '''
            return call_llm(prompt)
        ```

        Example of effective multi-example prompting:
        ```python
        def extract_entities(text):
            prompt = f'''
            Extract entities from this text.

            Example 1:
            Text: John will meet Mary at 3pm on Tuesday.
            Entities: {{"people": ["John", "Mary"], "time": "3pm", "day": "Tuesday"}}

            Example 2:
            Text: The team needs to submit the report by Friday at noon.
            Entities: {{"people": ["the team"], "time": "noon", "day": "Friday", "object": "report"}}

            Example 3:
            Text: Alex cannot attend the conference from Jan 3-5 due to prior commitments.
            Entities: {{"people": ["Alex"], "event": "conference", "date_range": ["Jan 3-5"], "reason": "prior commitments"}}

            Text: {text}
            Entities:
            '''
            return call_llm(prompt)
        ```

        === DIRECT LLM REASONING APPROACH ===

        CRITICAL: Previous scripts have shown that complex code generation with JSON parsing and multi-step pipelines often 
        leads to errors and low performance. Instead, focus on leveraging the LLM's natural reasoning abilities:

        1. SIMPLIFY YOUR APPROACH:
           - Minimize the number of processing steps - simpler is better
           - Directly use LLM for pattern recognition rather than writing complex code
           - Avoid trying to parse or manipulate JSON manually - pass it as text to the LLM

        2. DIRECT TRANSFORMATION:
           - Instead of trying to extract features and then apply them, use the LLM to do the transformation directly
           - Use examples to teach the LLM the pattern, then have it apply that pattern to new inputs
           - Avoid attempting to write complex algorithmic solutions when pattern recognition will work better

        3. ROBUST ERROR HANDLING:
           - Include multiple approaches in case one fails (direct approach + fallback approach)
           - Use simple validation to check if outputs are in the expected format
           - Include a last-resort approach that will always return something valid

        4. AVOID COMMON PITFALLS:
           - Do NOT attempt to use json.loads() or complex JSON parsing - it often fails
           - Do NOT create overly complex Python pipelines that require perfect indentation
           - Do NOT create functions that generate or execute dynamic code
           - Do NOT create unnecessarily complex data transformations

        5. SUCCESSFUL EXAMPLES:
           - The most successful approaches have used direct pattern matching with multiple examples
           - Scripts with simple validation and fallback approaches perform better
           - Scripts with fewer processing steps have higher success rates
        
        IMPLEMENTATION STRATEGIES:
        1. Maintain a "example bank" of successful and failed examples to select from
        2. Implement n-shot prompting with n=3 as default, but adapt based on performance
        3. For complex tasks, use up to 5 examples; for simpler tasks, 2-3 may be sufficient
        4. Include examples with a range of complexity levels, rather than all similar examples



        VALIDATION AND VERIFICATION GUIDANCE:
        1. CRITICAL: Consider implementing validation loops for EACH key processing step, not just final outputs
        2. Design your system to detect, diagnose, and recover from specific errors. This will help future learnings
        3. For every LLM extraction or generation, add a verification step that checks:
           - Whether the output is well-formed and complete
           - Whether the output is logically consistent with the input
           - Whether all constraints are satisfied
        4. Add feedback loops that retry failures with specific feedback
        5. Include diagnostic outputs that reveal exactly where failures occur. Add print statements and intermediate outputs such that you can see them later to determine why things are going wrong.
        6. Include capability to trace through execution steps to identify failure points

        Example of pipeline without verification:
        ```python
        def process_question(question):
            entities = extract_entities(question)
            constraints = identify_constraints(question)
            solution = generate_solution(entities, constraints)
            return solution
        ```

        Example of robust pipeline with verification:
        ```python
        def process_question(question, max_attempts=3):
            # Step 1: Extract entities with verification
            entities_result = extract_entities_with_verification(question)
            if not entities_result.get("is_valid"):
                print(f"Entity extraction failed: {entities_result.get('validation_feedback')}")
                return f"Error in entity extraction: {entities_result.get('validation_feedback')}"

            # Step 2: Identify constraints with verification
            constraints_result = identify_constraints_with_verification(question, entities_result["entities"])
            if not constraints_result.get("is_valid"):
                print(f"Constraint identification failed: {constraints_result.get('validation_feedback')}")
                return f"Error in constraint identification: {constraints_result.get('validation_feedback')}"

            # Step 3: Generate solution with verification
            solution_result = generate_solution_with_verification(
                question, 
                entities_result["entities"], 
                constraints_result["constraints"]
            )
            if not solution_result.get("is_valid"):
                print(f"Solution generation failed: {solution_result.get('validation_feedback')}")
                return f"Error in solution generation: {solution_result.get('validation_feedback')}"

            return solution_result["solution"]

        def extract_entities_with_verification(question, max_attempts=3):
            #Extract entities and verify their validity with feedback loop.
            system_instruction = "You are an expert at extracting and validating entities."

            for attempt in range(max_attempts):
                # First attempt at extraction
                extraction_prompt = f'''
                Extract key entities from this question. 
                Return a JSON object with the extracted entities.

                Example 1: [example with entities]
                Example 2: [example with different entities]
                Example 3: [example with complex entities]

                Question: {question}
                Extraction:
                '''

                extracted_data = call_llm(extraction_prompt, system_instruction)

                try:
                    # Parse the extraction
                    data = json.loads(extracted_data)

                    # Verification step
                    verification_prompt = f'''
                    Verify if these extracted entities are complete and correct:

                    Question: {question}
                    Extracted entities: {json.dumps(data, indent=2)}

                    Check if:
                    1. All relevant entities are extracted
                    2. No irrelevant entities are included
                    3. All entity values are correct

                    Return a JSON with:
                    {{
                      "is_valid": true/false,
                      "validation_feedback": "detailed explanation",
                      "missing_entities": ["entity1", "entity2"],
                      "incorrect_entities": ["entity3"]
                    }}
                    '''

                    verification_result = call_llm(verification_prompt, system_instruction)
                    verification_data = json.loads(verification_result)

                    if verification_data.get("is_valid", False):
                        data["is_valid"] = True
                        data["validation_feedback"] = "All entities are valid."
                        return data

                    # If not valid and we have attempts left, refine with feedback
                    if attempt < max_attempts - 1:
                        feedback = verification_data.get("validation_feedback", "")
                        print(f"Validation failed (attempt {attempt+1}/{max_attempts}): {feedback}")
                        continue

                    # If we're out of attempts, return the best we have with validation info
                    data["is_valid"] = False
                    data["validation_feedback"] = verification_data.get("validation_feedback", "Unknown validation error")
                    return data

                except Exception as e:
                    print(f"Error in extraction/validation (attempt {attempt+1}/{max_attempts}): {str(e)}")
                    if attempt >= max_attempts - 1:
                        return {
                            "is_valid": False,
                            "validation_feedback": f"Error during processing: {str(e)}"
                        }

            return {
                "is_valid": False,
                "validation_feedback": "Failed to extract valid entities after multiple attempts."
            }
        ```

        VALIDATION IMPLEMENTATION STRATEGIES:
        1. Create detailed verification functions for each major processing step
        2. Implement max_attempts limits on all retry loops (typically 3-5 attempts)
        3. Pass specific feedback from verification to subsequent retry attempts
        4. Log all verification failures to help identify systemic issues
        5. Design fallback behaviors when verification repeatedly fails

        

            
        ACCUMULATED LEARNINGS FROM PREVIOUS ITERATIONS:
        ```
# Math Question Dataset: Evolving Research Log

This document serves as a dynamic research log, capturing our evolving understanding, strategies, and findings related to the task of solving math questions from the provided dataset. It prioritizes concrete, task-specific insights.

## 1. DATASET PATTERNS & CHARACTERISTICS

*   **Mathematical Content Variety:** The dataset contains a diverse set of math problems, encompassing arithmetic, number theory, and probability, in addition to algebra, geometry, and more complex topics. This requires the system to handle a broad range of mathematical concepts and problem-solving strategies. Examples include divisibility rules, prime factorization, area calculations, and probability calculations.
*   **Question Content:** Predominantly multi-step mathematical reasoning problems. Requires a combination of algebra, geometry, and number theory. Questions range in complexity, requiring both computational and conceptual understanding.
*   **Mathematical Formulation:** Questions are primarily mathematical problems, often requiring symbolic manipulation (using LaTeX notation), number theory concepts, or geometric reasoning.
*   **Multi-Step Solutions:** The "expected" answers often involve multiple steps of logical deduction or calculation. This reinforces the necessity of decomposing problems into smaller, manageable sub-problems.
*   **Word Problem Complexity:** Questions are presented as word problems, often involving fictional scenarios or abstract concepts (e.g., "Penteria"). This necessitates strong natural language understanding to correctly translate the problem into mathematical terms.
*   **Answer Style:** Concise, step-by-step solutions using LaTeX. Final answers often boxed.
*   **Formatting:** Uses LaTeX for mathematical expressions and Asymptote code for diagrams. Accurate LaTeX interpretation is crucial.
*   **Numerical Focus:** Many questions require finding specific numerical values (e.g., smallest possible value, probability, arithmetic mean), demanding precise calculations.
*   **Reasoning Types:** Deductive, algebraic manipulation, spatial, computational, and logical.
*   **Hidden Constraints and Assumptions:** Problems often rely on implicit constraints or assumptions that are not explicitly stated, making accurate interpretation challenging. For example, the "Penteria" problem implicitly assumes the initial population is a positive integer.
*   **Dataset Size and Diversity:** While initial experiments focused on smaller samples, the dataset contains sufficient variety in topics (number theory, algebra, probability, etc.) and difficulty to necessitate testing robustness and generalizability. This includes abstract concepts and creative problem-solving skills.
*   **Multi-faceted problems:** The dataset contains questions that often require a combination of different mathematical concepts (e.g., geometry and vector algebra, number theory and combinatorics, probability and spatial reasoning). This necessitates a broad knowledge base and the ability to synthesize information from different domains.
*   **Visual component integration:** Many questions include diagrams or visual aids (e.g., geometric figures, game boards) that are crucial for understanding and solving the problem. The system needs to be able to effectively interpret and utilize this visual information. The spatial reasoning and extraction of numerical data from the images is a common requirement.
*   **Constraint-heavy problems:** A significant number of problems impose constraints on the solution, such as restrictions on digit usage or valid moves on a game board. The system must be able to explicitly identify, represent, and enforce these constraints during the solution process.
*   **Examples:**
    *   Geometry problems involving area/circumference calculations, vector geometry.
    *   Number theory problems involving divisibility, digit sums, and prime factorization.
    *   Algebra problems involving solving equations.
    *   Probability Problems involving calculations based on provided sets.
    *   Probability problems involving spatial reasoning on a game board (e.g., requiring identifying all possible paths to a target sum).

## 2. EFFECTIVE TASK-SPECIFIC STRATEGIES

*   **Ineffective (Baseline):** Direct LLM call. Accuracy ~50%. Insufficient for the complexity and precision required.
*   **(Untested) Chain-of-Thought (CoT):** Breaking down questions into smaller, manageable sub-problems appears promising due to the multi-step nature of the solutions. However, this strategy remained untested initially due to data processing errors preventing successful LLM calls. Now integrated into the more successful "Decompose-Solve-Verify" approach.
*   **Modular Analysis:** The "Problem Analyzer" agent's structured JSON output (problem type, topic, knowns, unknowns, steps) appears beneficial in breaking down complex problems into manageable components. This structured representation can be leveraged for more robust reasoning. Incorporated into "Decompose-Solve-Verify".
*   **Prime Factorization Considerations:** Prime factorization of relevant values (e.g., set members in probability problems) can be crucial for identifying solutions.
*   **Decompose-Solve-Verify:** This approach breaks down complex problems into manageable sub-problems. This has proven effective in recent experiments, contributing to a 100% accuracy rate in one iteration.
*   **Multi-Example Prompting:** Guiding the LLM with multiple examples improves accuracy by providing relevant context.
*   **Specialized System Instructions:** Using specialized system instructions for each step of the process (e.g., "expert at decomposing complex math problems") enhances the quality of the LLM's output. This applies specifically to the "Decompose-Solve-Verify" approach.
*   **Explicit Knowledge Retrieval and Verification:** Explicitly retrieving and verifying knowledge seems beneficial as a first step. The accuracy, however, hinges on *how* the knowledge is used in the subsequent synthesis step.
*   **Constraint-Aware Search:** For problems involving constraints (e.g., valid moves, digit restrictions), integrating a search algorithm (e.g., backtracking, breadth-first search) is needed to systematically explore the solution space while explicitly enforcing all constraints. (Not yet implemented but a planned strategy).
*   **Visual Reasoning Module:** Enhancing the system's ability to interpret and extract information from diagrams and visual aids. Consider incorporating techniques for image analysis, shape recognition, and spatial reasoning. (Not yet implemented but a planned strategy).

## 3. COMMON FAILURE MODES ON THIS DATASET

*   **Arithmetic and Logical Calculation Errors:** Consistent errors in basic arithmetic and logical calculations (e.g., median, probability). *Example: Incorrectly calculating the median in the stem and leaf plot question.*
*   **Misinterpretation of Problem Context:** Failing to fully understand the constraints or conditions stated in the problem, leading to incorrect solution paths. *Example: LLM jumps directly to a numerical answer without proper justification in divisibility question.* In the "Penteria" problem, the LLM does not properly handle the hourly reset condition.
*   **LaTeX Interpretation Issues:** Subtle errors in interpreting LaTeX can lead to misconstrued equations and wrong answers.
*   **Difficulty:** Understanding the problem statement, which may involve complex mathematical notation. Choosing the right approach and applying the correct formulas. Performing accurate calculations. Dealing with multi-step problems requiring a sequence of logical deductions. Interpreting visual information from diagrams (when present).
*   **Edge Cases/Complexities:** Problems with subtle wording that can lead to misinterpretation. Questions requiring creative problem-solving or non-obvious insights. Diagrams that may be misleading or require careful analysis. Calculations involving fractions, radicals, or other potentially error-prone operations.
*   **`NoneType` Error in LLM Call:** The LLM call consistently failed due to receiving a `NoneType` argument. This suggests a problem with the script's data processing flow *before* the `call_llm` function. A variable expected to hold a string or iterable (likely the prompt or a list of sub-questions) is unexpectedly becoming `None`.
    *   **Script Error Log [2025-05-28 01:51:54]:** ERROR: TypeError: 'NoneType' is not iterable
    *   **Script Error Log [2025-05-28 01:51:59]:** ERROR: NoneType not iterable
    *   **Script Error Log [2025-05-28 01:52:04]:** ERROR: TypeError: 'NoneType' is not iterable
*   **Inconsistent Application of Constraints:** The primary failure mode is the model's inability to consistently apply constraints within the problem statement. This leads to misinterpretations and incorrect solutions. For example, in the "Penteria" problem, the LLM does not properly handle the hourly reset condition.
*   **Misinterpreting Problem Logic:** Even with a structured analysis, the "Solution Generator" struggles to translate the analysis into correct mathematical operations. In the "Penteria" problem, the agent misinterprets the problem's reset condition and makes incorrect calculations.
*   **Inability to handle implicit constraints:** The set member values of {2, 4, 12, 14, 21, 28, 98} are all positive integers. The solution does not seem to check that the initial population of the Penteria problem should also be a positive integer. This highlights the need for explicit constraint handling.
*   **Ambiguity and Complexity:** Even with successful strategies like "Decompose-Solve-Verify," more challenging or ambiguous questions could reveal new failure modes, emphasizing the need for continuous testing and refinement.
*   **Incomplete Enumeration (Probability):** The probability question demonstrates a key failure mode: the inability to systematically enumerate all possible valid scenarios. The model identifies *some* paths that lead to the target sum (30), but fails to account for all of them, leading to an underestimation of the probability. The failure occurs because the system lacks a robust search or backtracking mechanism to explore the entire solution space while respecting the problem's constraints.
*   **Missing edge cases and invalid paths:** In the provided example, the "actual" solution explores a handful of paths but prematurely deems other paths as invalid without fully justifying why. The system needs to be more thorough and explicitly show *why* each possibility is (or isn't) valid.
*   **Weak constraint enforcement:** Constraints, such as the allowable movements on the game board, are not consistently enforced. This results in the inclusion of impossible sequences of moves, skewing the calculation of favorable outcomes.

## 4. EXPERIMENT LOG & FINDINGS

*   **Experiment 0 (Baseline):**
    *   **Description:** Direct call to the LLM with the question.
    *   **Accuracy:** ~50%
    *   **Findings:** The baseline approach is inadequate. Requires more than just general knowledge; necessitates precise calculation and logical reasoning capabilities. Calculation errors and misinterpretations of context are frequent.
*   **Experiment 1:**
    *   **Description:** Attempt to implement a Chain-of-Thought (CoT) approach by breaking down the question into sub-questions.
    *   **Accuracy:** 0% (LLM call failed consistently)
    *   **Findings:** The core CoT strategy remains untested *in isolation*. The LLM call consistently fails due to a `NoneType` error originating *before* the `call_llm` function. Further debugging is needed to identify the source of the `None` value. Error handling only catches exceptions *during* the LLM call, not problems in data preparation *before* the call. The `NoneType` error halted script execution, preventing any assessment of the CoT's effectiveness on this dataset. Highlighted the importance of robust input validation. The underlying principle of CoT, however, contributed to the later "Decompose-Solve-Verify" success.
*   **Experiment 2:**
    *   **Description:** Implemented a modular approach with "Problem Analyzer," "Solution Generator," and "Solution Validator" agents. The "Problem Analyzer" generated structured JSON output.
    *   **Accuracy:** 0.33
    *   **Findings:** The initial hypothesis that decomposing the problem into analysis, solution generation, and validation steps helps in math problem-solving is partially supported, as indicated by the structured JSON output. However, the low accuracy indicates that the current implementation of this approach is not robust enough. Highlights the limitations of the Gemini LLM in complex mathematical reasoning, especially when dealing with implicit constraints and nuanced problem logic. Ultimately led to the development of the "Decompose-Solve-Verify" strategy.
*   **Experiment 3:**
    *   **Description:** Implemented the "Decompose-Solve-Verify" approach with multi-example prompting and specialized system instructions.
    *   **Accuracy:** 1.00
    *   **Findings:** This experiment confirms that the "Decompose-Solve-Verify" approach, combined with multi-example prompting and specialized system instructions, can effectively solve math word problems in this dataset, at least on the tested sample. However, further testing on a larger and more diverse dataset is needed to ensure robustness and generalizability. A perfect accuracy suggests that the LLM can handle the complexity and variety of questions *within the tested sample*.
*   **Experiment 4:**
    *   **Description:** "Knowledge Retrieval and Solution Synthesis" approach.
    *   **Findings:** The "Knowledge Retrieval and Solution Synthesis" approach shows promise, but its effectiveness is limited by the subsequent solution synthesis step. Retrieving relevant knowledge is not sufficient if the system cannot apply it correctly and exhaustively to the problem. The isolated success of knowledge retrieval and verification highlights a key area for improvement: enhancing the solution synthesis agent's reasoning and problem-solving capabilities. The failure to consider all possible scenarios suggests that exploration is not wide enough. The system failed to systematically enumerate all valid scenarios and prematurely deemed other paths as invalid without fully justifying why. Constraints were not consistently enforced.

## 5. NEXT RESEARCH DIRECTIONS

*   **Debugging Data Flow:** *HIGH PRIORITY*. Revisit and thoroughly debug the data flow to prevent `NoneType` errors. Add print statements or logging to track the values of variables at each step of the data processing pipeline, especially before calling `call_llm`. Specifically, examine the data preparation steps within the `main` function and related functions.
*   **Input Validation:** Add checks *before* calling `call_llm` to ensure that the prompt (or any other input it receives) is not `None`. If it is, log an error message and potentially try to recover (e.g., by substituting a default prompt or skipping the question). Implement a clear error handling strategy for these cases.
*   **Re-evaluate CoT (Indirectly Addressed):** While pure CoT failed initially, the "Decompose-Solve-Verify" approach incorporates the core principle. No need for separate evaluation.
*   **Implement Calculator Tool:** Offload arithmetic calculations to a tool for accurate numerical computation.
*   **Step-by-Step Reasoning:** Continue incorporating a step-by-step reasoning approach in the prompt to decompose problems into verifiable steps. This is inherent in "Decompose-Solve-Verify". The solution synthesis agent needs to explicitly justify each step of its reasoning, demonstrating why each possibility is either valid or invalid. This requires more detailed explanations and explicit references to the problem's constraints. The agent should aim for a more exhaustive and rigorous analysis of the solution space.
*   **Verifier Implementation:** Continue to use a verifier to check the LLM's final answer against the problem's constraints and logical consistency. This is already part of the "Decompose-Solve-Verify" framework.
*   **LaTeX Handling Improvement:** Improve LaTeX handling either via pre-processing or prompt engineering.
*   **Constraint Enforcement Module:** Implement a module specifically designed to identify and enforce constraints within the problem statement. This could involve explicitly listing constraints in the JSON output of the "Problem Analyzer" and using them to guide the "Solution Generator." Explicitly add constraints to the problem that the initial population must be a positive integer (e.g., in "Penteria"-like problems).
*   **Verification Step:** Create a calculation checker to make sure the math is calculated correctly.
*   **Targeted Prompt Engineering:** Refine the prompts for the "Solution Generator" to emphasize constraint adherence and logical reasoning.
*   **Self-Consistency Checks:** Incorporate self-consistency checks within the "Solution Validator" to identify contradictions or inconsistencies in the generated solution.
*   **Broader Dataset Testing:** Expand testing to a larger and more diverse set of problems to assess the generalizability and robustness of the "Decompose-Solve-Verify" strategy.
*   **Ambiguity Stress Testing:** Introduce more challenging and ambiguous questions to specifically identify potential failure points and limitations of the current approach.
*   **Efficiency Optimization:** Explore ways to optimize the prompts and system instructions to improve the efficiency and scalability of the "Decompose-Solve-Verify" approach.
*   **Solution Strategies:** (Reminder of potential techniques)
    *   **Direct Calculation:** Solve the problem by applying relevant formulas and performing calculations directly.
    *   **Equation Solving:** Set up equations based on the problem statement and solve for the unknown variables.
    *   **Geometric Reasoning:** Use geometric properties and relationships to find the solution.
    *   **Casework:** Divide the problem into different cases and solve each case separately.
    *   **Pattern Recognition:** Identify patterns or relationships that can help solve the problem.
*   **Problem Decomposition:** (Reminder of decomposition steps)
    1.  **Understand the Problem:** Carefully read the question and identify the knowns and unknowns. Translate the problem into mathematical notation.
    2.  **Develop a Plan:** Determine which formulas, theorems, or techniques are relevant to the problem.
    3.  **Execute the Plan:** Apply the chosen techniques to solve the problem.
    4.  **Check the Answer:** Verify that the answer is reasonable and consistent with the problem statement.
*   **Validation Techniques:** (Reminder of validation techniques)
    *   **Unit Analysis:** Check that the units of the answer are correct.
    *   **Estimation:** Estimate the answer to see if it's in the right ballpark.
    *   **Substitution:** Plug the answer back into the original problem to see if it works.
    *   **Dimensional Analysis:** Check that the dimensions of the quantities are consistent.
    *   **Consider extreme values:** check the answer works for extreme values of some variable.
*   **Creative Insights:** (Reminder of creative insight techniques)
    *   Sometimes, a geometric problem can be solved more easily using algebra, or vice versa.
    *   Looking for symmetries in the problem can simplify the solution.
    *   Rearranging the problem statement or using a different coordinate system can sometimes reveal a simpler solution path. Think about the problem from a different angle. Can you reframe the question or use a different representation? Instead of trying to solve the problem directly, try to solve a simpler version of the problem first. Draw analogies to other problem domains where similar concepts or techniques apply.
*   **Implementation Recommendations:** (Reminder of implementation aspects)
    *   **Verification Steps:** Mathematical Correctness: The most crucial aspect. Verify that each step in the solution is mathematically sound. Consistency with Problem Statement: Ensure that the solution addresses the specific question asked and uses the given information correctly. Reasonableness of Answer: Check if the answer is reasonable in the context of the problem (e.g., a negative length is likely wrong). Edge Case Testing: Test the solution with edge cases or extreme values to ensure it holds true in all scenarios.
    *   **Intermediate Steps/Representations:** Symbolic Representation: Maintain the problem in symbolic form (using variables and equations) as long as possible to avoid premature numerical evaluation. Equation Tree: Represent the equations as a tree structure to facilitate manipulation and simplification. Diagrammatic Representation: (If applicable) Use a graph or diagram to represent the geometric relationships in the problem.
    *   **Text-Based Techniques:** LaTeX Parsing & Generation: While avoiding complex code generation, leverage LLMs' ability to understand and generate LaTeX. This is crucial for both interpreting questions and formatting answers. Step-by-Step Reasoning Chain: Prompt the LLM to explicitly state its reasoning in a step-by-step manner. This allows for easier debugging and verification. Each step should be a complete sentence. Formula Identification: Train the LLM to identify relevant formulas based on keywords in the problem statement. Equation Simplification: Use prompting to guide the LLM to simplify equations and expressions. Example-Based Learning: Fine-tune the LLM on a large dataset of similar problems and solutions. Verification Prompting: Use separate prompts to verify the correctness of each step in the solution and the final answer. For example, "Is this step logically valid based on the previous step?" "Does this answer make sense in the context of the problem?" Avoid Over-Reliance on Code: Don't try to offload the *reasoning* to external code. Use code only for arithmetic or symbolic manipulation if absolutely necessary, and always verify the results.
*   **Implement a constraint-aware search algorithm:** For problems involving constraints (e.g., valid moves, digit restrictions), integrate a search algorithm (e.g., backtracking, breadth-first search) into the solution synthesis agent. This algorithm should systematically explore the solution space while explicitly enforcing all constraints. The model needs to develop the ability to explore more scenarios, and intelligently backtrack when an invalid possibility is found.
*   **Develop a visual reasoning module:** Enhance the system's ability to interpret and extract information from diagrams and visual aids. Consider incorporating techniques for image analysis, shape recognition, and spatial reasoning. This would allow the system to better understand the spatial relationships and constraints presented in the visual components of the problems. For example, determining valid board positions after N moves.
*   **Focus on exhaustive reasoning and validation:** The solution synthesis agent needs to explicitly justify each step of its reasoning, demonstrating why each possibility is either valid or invalid. This requires more detailed explanations and explicit references to the problem's constraints. The agent should aim for a more exhaustive and rigorous analysis of the solution space.
*   **Increase exploration and back-tracking:** Develop the ability for the model to explore more scenarios, and intelligently backtrack when an invalid possibility is found.
```
        

            
        CAPABILITY ASSESSMENT & IMPROVEMENT GUIDANCE:
        SYSTEM ANALYSIS & GUIDANCE


        

            BEST SCRIPT TO REFINE:
            Iteration: 3
            Accuracy: 1.00
            Approach Summary: The script employs a "Decompose-Solve-Verify" approach using the Gemini LLM, enhanced by multi-example prompting to improve accuracy. The problem is broken down into smaller steps by `decompose_problem`, then `solve_sub_problems` solves these steps, and `synthesize_solutions` combines the solutions into a final answer which is then verified for coherency using `check_coherency`. The `call_llm` function is used as a wrapper to call the Gemini API with different prompts and system instructions, defining roles like "expert at decomposing complex math problems" for each step. The overall workflow involves decomposing the initial question, solving the sub-problems, synthesizing the solutions, verifying that the response is coherent and then returning the final answer or an error message if the coherency check fails.

            CURRENT BEST SCRIPT CODE:
            ```python
            import os
from google import genai
from google.genai import types

def call_llm(prompt, system_instruction=None):
    """Call the Gemini LLM with a prompt and return the response. DO NOT deviate from this example template or invent configuration options. This is how you call the LLM."""
    try:
        # Initialize the Gemini client
        client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))

        # Call the API with system instruction if provided
        if system_instruction:
            response = client.models.generate_content(
                model="gemini-2.0-flash", 
                config=types.GenerateContentConfig(
                    system_instruction=system_instruction
                ),
                contents=prompt
            )
        else:
            response = client.models.generate_content(
                model="gemini-2.0-flash",
                contents=prompt
            )

        return response.text
    except Exception as e:
        print(f"Error calling Gemini API: {str(e)}")
        return f"Error: {str(e)}"

def main(question):
    """
    This script implements a 'Decompose-Solve-Verify' approach with multi-example prompting for each step.
    Hypothesis: Explicit examples in prompts improve accuracy and robustness by guiding the LLM. The solution is checked with another prompt to make sure the response is coherent.
    """

    # Step 1: Decompose the problem into smaller, manageable steps
    def decompose_problem(question):
        """Breaks down the problem into smaller steps."""
        system_instruction = "You are an expert at decomposing complex math problems into smaller, solvable steps."
        prompt = f"""
        Decompose the following math problem into smaller, manageable steps.

        Example 1:
        Problem: What is the area of a square with side length 10, and what is the area if the side length is increased by 50%?
        Decomposition:
        1. Calculate the area of the square with side length 10.
        2. Calculate the new side length after increasing it by 50%.
        3. Calculate the area of the square with the new side length.

        Example 2:
        Problem: A train travels at 60 mph for 2.5 hours. How far does it go and how much time is spent going the first half of the distance if the train travels at a constant velocity?
        Decomposition:
        1. Calculate the total distance traveled.
        2. Divide the total distance by 2.
        3. Calculate the time spent for the first half.

        Problem: {question}
        Decomposition:
        """
        return call_llm(prompt, system_instruction)

    # Step 2: Solve each sub-problem independently
    def solve_sub_problems(decomposition):
        """Solves each sub-problem from the decomposition."""
        system_instruction = "You are an expert at solving math sub-problems."
        prompt = f"""
        Solve the following sub-problems.

        Example:
        Sub-problems:
        1. Calculate the area of the square with side length 10.
        2. Calculate the new side length after increasing it by 50%.
        3. Calculate the area of the square with the new side length.
        Solutions:
        1. 100
        2. 15
        3. 225

         Sub-problems: {decomposition}
        Solutions:
        """
        return call_llm(prompt, system_instruction)

    # Step 3: Synthesize the solutions into a final answer
    def synthesize_solutions(question, sub_problems, solutions):
        """Synthesizes the solutions to the sub-problems into a final answer."""
        system_instruction = "You are an expert at synthesizing solutions to math problems."
        prompt = f"""
        Synthesize the following solutions into a final answer for the given question.

        Example:
        Question: What is the area of a square with side length 10, and what is the area if the side length is increased by 50%?
        Sub-problems:
        1. Calculate the area of the square with side length 10.
        2. Calculate the new side length after increasing it by 50%.
        3. Calculate the area of the square with the new side length.
        Solutions:
        1. 100
        2. 15
        3. 225
        Final Answer: The area of the square with side length 10 is 100. If the side length is increased by 50%, the new area is 225.

        Question: {question}
        Sub-problems: {sub_problems}
        Solutions: {solutions}
        Final Answer:
        """
        return call_llm(prompt, system_instruction)

    #Step 4: Check for response coherency
    def check_coherency(question, solution):
        """Verifies if the solution is coherent."""
        system_instruction = "You are an expert solution coherency verifier."
        prompt = f"""
        Is this response coherent with the question?

        Example 1:
        Question: What is the capital of France?
        Solution: The capital of France is Paris.
        Coherent: True

        Example 2:
        Question: What is the capital of France?
        Solution: I like apples.
        Coherent: False

        Question: {question}
        Solution: {solution}
        Coherent:
        """
        return call_llm(prompt, system_instruction)
    try:
        # Call the decomposition function
        decomposition = decompose_problem(question)
        print(f"Decomposition: {decomposition}")

        # Call the solve sub-problems function
        solutions = solve_sub_problems(decomposition)
        print(f"Solutions: {solutions}")

        # Call the synthesize solutions function
        final_answer = synthesize_solutions(question, decomposition, solutions)
        print(f"Final Answer: {final_answer}")

        #Call the coherency checker
        is_coherent = check_coherency(question, final_answer)
        print(f"Coherency: {is_coherent}")
        if "True" in is_coherent:
            return final_answer
        else:
            return f"Response not coherent. Answer: {final_answer}"
    except Exception as e:
        print(f"Error: {e}")
        return f"Error: {e}"
            ```

            SPECIFIC SUCCESS CASES (what the script does well):
            [
  {
    "question": "One morning each member of Angela's family drank an 8-ounce mixture of coffee with milk. The amounts of coffee and milk varied from cup to cup, but were never zero. Angela drank a quarter of the total amount of milk and a sixth of the total amount of coffee. How many people are in the family?",
    "system_answer": "The number of people in Angela's family is 5.",
    "golden_answer": "Suppose that the whole family drank $x$ cups of milk and $y$ cups of coffee. Let $n$ denote the number of people in the family. The information given implies that $\\frac{x}{4}+\\frac{y}{6}=\\frac{x+y}{n}$. This leads to \\[\n3x(n-4)=2y(6-n).\n\\]Since $x$ and $y$ are positive, the only positive integer $n$ for which both sides have the same sign is $n=\\boxed{5}$.",
    "explanation": "Both answers state that the number of people in Angela's family is 5."
  },
  {
    "question": "How many integer divisors does $7$ have?",
    "system_answer": "The number 7 has 4 integer divisors: 1, 7, -1, and -7.",
    "golden_answer": "The factors of $7$ are $-7, -1, 1,$ and $7$, for a total of $\\boxed{4}$ factors.",
    "explanation": "Both answers state that the number 7 has 4 integer divisors/factors, which are -7, -1, 1, and 7. The wording and formatting differ slightly, but the core information conveyed is the same."
  },
  {
    "question": "Given that a particular positive integer is a four-digit palindrome, what is the probability that it is a multiple of $99?$ Express your answer as a common fraction.",
    "system_answer": "The probability that a four-digit palindrome is a multiple of 99 is $\\frac{1}{9}$.",
    "golden_answer": "First we find the number of $4$ digit palindromes. There are ten palindromes for every distinct thousandth digit from $1$ to $9$ because there are $10$ numbers from $0$ to $9$ we could pick for the second and third digit. This gives us a total of $9 \\cdot 10$ palindromes.\n\nNext, we can get that all palindromes are multiples of $11$. The divisibility rule for $11$ tells us that for a number $abcd$ to be divisible by $11$, then $a-b+c-d$ is divisible by $11$. Since $a=d$ and $b=c$, $a-b+c-d$ is always divisible by $11$ so all four digit palindromes are divisible by $11$.\n\nNow we want to find now many of these palindromes are divisible by $9$. For a number to be divisible by $9$, the sum of the digits must be divisible by $9.$ It's impossible for the sum of the digits to be equal to $9$ or $27$ because it must be an even number (the sum is $a+b+c+d=2(a+b)$). We find the number of palindromes whose digits add up to $18.$ Since $a+b+c+d=2(a+b)=18,$ we get that $a+b=9.$ There are $9$ possible answers, where $a$ goes from $1$ to $9$ and $b=9-a$. We then find the number of palindromes whose digit add up to $36.$ There is only one four-digit number that does so, $9999.$\n\nTherefore, we have that there are $9+1=10$ four-digit palindromes that are divisible by $99.$\n\nSince there is a total of $90$ palindromes, the probability that it is divisible by $99$ is $\\frac{10}{90}=\\boxed{\\frac19}$.",
    "explanation": "Both answers state that the probability that a four-digit palindrome is a multiple of 99 is 1/9."
  }
]

            SPECIFIC FAILURE CASES (what needs improvement):
            []

            REFINEMENT ANALYSIS GUIDANCE:
            1. IDENTIFY THE CORE STRENGTH:
               - What specific technique or approach makes this script successful?
               - Which components are working well and must be preserved?
               - What is the script's main competitive advantage?

            2. PINPOINT SPECIFIC WEAKNESSES:
               - Where exactly do the failures occur in the processing pipeline?
               - What specific patterns cause the script to fail?
               - Are failures due to information extraction, reasoning, formatting, or verification?
               - Can you identify the exact function or step where problems arise?

            3. FORM A SPECIFIC HYPOTHESIS:
               - What is the ONE most critical weakness to address?
               - What specific change would most likely improve performance?
               - How can you fix this weakness without breaking the existing strengths?
               - What verification can you add to test if your fix works?

            4. SURGICAL IMPROVEMENT STRATEGY:
               - Make the MINIMUM changes necessary to address the identified weakness
               - Preserve all successful components and logic
               - Add targeted verification for the specific area being improved
               - Enhance error handling for the identified failure mode
               - Add debugging output to verify the fix is working

            SPECIFIC REFINEMENT TECHNIQUES:
            - If failures are in information extraction: Improve prompts, add verification, better parsing
            - If failures are in reasoning: Add chain-of-thought, verification loops, multi-step reasoning
            - If failures are in formatting: Add output validation, format checking, retry logic
            - If failures are inconsistent: Add confidence scoring, multiple attempts, consensus approaches

            CRITICAL REFINEMENT REQUIREMENTS:
            1. Preserve the core successful approach - don't change what's working
            2. Make targeted, minimal changes focused on the specific weakness identified
            3. Add verification steps specifically for the area being improved
            4. Include debugging output to verify improvements are working
            5. EVERY LLM PROMPT must include embedded examples
            6. Test your hypothesis with additional verification

            Here's how to call the Gemini API. Use this example without modification:
            def call_llm(prompt, system_instruction=None):
    """Call the Gemini LLM with a prompt and return the response. DO NOT deviate from this example template or invent configuration options. This is how you call the LLM."""
    try:
        from google import genai
        from google.genai import types

        # Initialize the Gemini client
        client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))

        # Call the API with system instruction if provided
        if system_instruction:
            response = client.models.generate_content(
                model="gemini-2.0-flash", 
                config=types.GenerateContentConfig(
                    system_instruction=system_instruction
                ),
                contents=prompt
            )
        else:
            response = client.models.generate_content(
                model="gemini-2.0-flash",
                contents=prompt
            )

        return response.text
    except Exception as e:
        print(f"Error calling Gemini API: {str(e)}")
        return f"Error: {str(e)}"

            REFINEMENT IMPLEMENTATION:
            State Your Hypothesis: Clearly comment what specific weakness you're addressing and how
            Preserve Strengths: Keep all successful components intact
            Targeted Fix: Implement the minimal change needed to address the weakness
            Add Verification: Include checks to ensure your fix is working
            Debug Output: Add print statements to track the improvement

            Return a COMPLETE, RUNNABLE Python script that:
            1. Preserves the successful core approach of the original script
            2. Makes targeted improvements to address the specific identified weakness
            3. Includes a clear comment stating your improvement hypothesis
            4. Adds verification specifically for the improved component
            5. Includes embedded examples in EVERY LLM prompt
            6. Is COMPLETE - no missing code, no "..." placeholders
            7. Closes all string literals properly

            REFINEMENT HYPOTHESIS: [State your specific hypothesis about what to improve and why in a comment]

            BE EXTREMELY CAREFUL TO PROPERLY CLOSE ALL STRING QUOTES AND TRIPLE QUOTES!
            MAKE SURGICAL IMPROVEMENTS WHILE PRESERVING THE SCRIPT'S CORE STRENGTHS!
            