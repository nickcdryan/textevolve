
            You are creating a NEW Python script by SYNTHESIZING the best elements from multiple successful approaches.
            Your goal is to identify what makes each approach successful and combine these strengths into a superior hybrid solution.
    
            Here are example problems from previously seen data:
            [
  {
    "id": 0,
    "question": "The positive three-digit integer $N$ has a ones digit of $0$. What is the probability that $N$ is divisible by $4$? Express your answer as a common fraction.",
    "answer": "An integer is divisible by 4 if and only if a number formed from the last two digits is divisible by 4. If the units digit is 0, all the numbers with even tens digits are divisible by 4 (00, 20, 40, 60, 80), and all the numbers with odd tens digits are not (10, 30, 50, 70, 90). Since there are the same number of even digits as odd digits, there is a $\\boxed{\\frac{1}{2}}$ probability that $N$ is divisible by 4."
  },
  {
    "id": 1,
    "question": "For the three identical squares shown, points $A$, $B$ and $C$ are vertices, and $AB$ = $2\\sqrt{5}$ cm. What is the length of $AC$, in centimeters? Express your answer in simplest radical form.\n\n[asy]\ndraw((0,0)--(0,10)--(30,10)--(30,0)--cycle);\ndraw((10,0)--(10,10));\ndraw((20,0)--(20,10));\ndraw((0,10)--(20,0),linewidth(1));\nlabel(\"$A$\",(0,10),NW);\nlabel(\"$B$\",(20,0),S);\nlabel(\"$C$\",(30,0),S);\n[/asy]",
    "answer": "Let the side length of one of the squares be $x$. Looking at the right triangle with hypotenuse $AB$, we have the equation $x^2+(2x)^2=(2\\sqrt{5})^2$ from the Pythagorean Theorem.  Simplifying this equation gives $x^2=4$. Looking at the right triangle with hypotenuse $AC$, we have the equation $x^2+(3x)^2=AC^2 \\Rightarrow AC^2=10x^2=40$. Thus, $AC=\\sqrt{40}=\\boxed{2\\sqrt{10}}$ centimeters."
  },
  {
    "id": 2,
    "question": "Let $n$ be a positive integer and let $k$ be the number of positive integers less than $2^n$ that are invertible modulo $2^n$. If $2^n\\equiv 3\\pmod{13}$, then what is the remainder when $k$ is divided by $13$?",
    "answer": "Since $2^n$ is a power of $2$, its only prime factor is $2$. So every odd integer is invertible modulo $2^n$ and every even integer is non-invertible modulo $2^n$. Among the positive integers less than $2^n$, there are precisely $\\frac{2^n}{2}=2^{n-1}$ odd integers. Thus, \\[k=2^{n-1}\\equiv 2^{-1}2^n\\equiv 7\\cdot 3\\equiv 21\\equiv \\boxed{8}\\pmod {13}\\]"
  }
]
    
            
        ITERATION HISTORY SUMMARY:
        - Total iterations completed: 7
        - Current explore/exploit balance: 30/50
        - Best accuracy achieved: 1.00 (iteration 3)

        APPROACH HISTORY (last 7 iterations):
        [
  {
    "iteration": 0,
    "strategy": "baseline",
    "accuracy": 0.5,
    "approach": "Simple baseline script: Direct LLM call without sophisticated techniques"
  },
  {
    "iteration": 1,
    "strategy": "refine",
    "accuracy": 0.0,
    "approach": "The script implements a chain-of-thought approach to answer a question by breaking it down into sub-questions, answering each sub-question independently, and then synthesizing the individual answers into a final response. The `main` function orchestrates this process, using `call_llm` to interact with the Gemini model for question breakdown, answering sub-questions, and synthesizing the final answer. No agent roles are explicitly defined. The `call_llm` function is used to send prompts to the LLM and return the response, `main` takes the question and orchestrates the calls to `call_llm` to get the sub-questions, answers to sub-questions, and a final synthesis. The overall workflow involves question decomposition, answering sub-questions, and synthesizing the final answer."
  },
  {
    "iteration": 2,
    "strategy": "explore",
    "accuracy": 0.3333333333333333,
    "approach": "The script employs a two-agent approach using the Gemini LLM to solve math problems: a \"Problem Analyzer\" that formats the question into a structured JSON and a \"Solution Generator\" that produces a step-by-step solution based on the analysis. A third \"Solution Validator\" agent is also used to validate the generated solution against the original question. The problem is decomposed into analysis, solution generation, and validation steps. The `main` function orchestrates the process by calling `analyze_problem` to analyze the input question, then `generate_solution` to create the solution, and finally `validate_solution` to check the solution, and the `call_llm` function is used to call the LLM with different system instructions and prompts for each agent."
  },
  {
    "iteration": 3,
    "strategy": "explore",
    "accuracy": 1.0,
    "approach": "The script employs a \"Decompose-Solve-Verify\" approach using the Gemini LLM, enhanced by multi-example prompting to improve accuracy. The problem is broken down into smaller steps by `decompose_problem`, then `solve_sub_problems` solves these steps, and `synthesize_solutions` combines the solutions into a final answer which is then verified for coherency using `check_coherency`. The `call_llm` function is used as a wrapper to call the Gemini API with different prompts and system instructions, defining roles like \"expert at decomposing complex math problems\" for each step. The overall workflow involves decomposing the initial question, solving the sub-problems, synthesizing the solutions, verifying that the response is coherent and then returning the final answer or an error message if the coherency check fails."
  },
  {
    "iteration": 4,
    "strategy": "explore",
    "accuracy": 0.6666666666666666,
    "approach": "The script employs a \"Knowledge Retrieval and Solution Synthesis\" approach using the Gemini LLM with specialized agents. First, `retrieve_knowledge` retrieves relevant information based on the input question, acting as a knowledge retrieval expert. The `verify_knowledge_retrieval` function then verifies the relevance of the knowledge. Finally, `synthesize_solution` acts as a solution synthesis expert, generating a step-by-step solution using the retrieved knowledge. The overall workflow involves retrieving knowledge, verifying it, and then synthesizing a solution based on that knowledge."
  },
  {
    "iteration": 5,
    "strategy": "refine",
    "accuracy": 0.6,
    "approach": "The script employs a \"Decompose-Solve-Verify\" approach using the Gemini LLM to answer questions, decomposing the problem into smaller steps, solving each sub-problem independently, synthesizing the solutions, and then verifying the coherency of the final answer. The script defines functions for each step: `decompose_problem`, `solve_sub_problems`, `synthesize_solutions`, and `check_coherency`, with each function acting as an agent with a specific system instruction. Each of these functions use `call_llm` to communicate with the Gemini model, using multi-example prompting to guide the model at each stage. The overall workflow involves calling each function in sequence to generate and validate the final answer."
  },
  {
    "iteration": 6,
    "strategy": "explore",
    "accuracy": 0.8,
    "approach": "The script uses a \"Reflexion-Enhanced Solution Synthesis\" approach, where an LLM first generates an initial solution, then critiques its own solution to identify errors, and finally synthesizes a refined solution based on the critique which is then validated. The problem is decomposed into four steps: initial solution generation, reflexion and critique, refined solution synthesis, and verification of the refined solution. The agent roles involved are expert problem solver, critical self-evaluator and solution validator. Other functions used include `call_llm` which is used to interact with the Gemini API.\n\nThe function `generate_initial_solution` calls `call_llm` to provide an initial solution to the problem. The function `reflect_and_critique` calls `call_llm` to provide a critique on the solution. The function `synthesize_refined_solution` then calls `call_llm` to provide a refined solution based on the critique. Finally, the function `verify_refined_solution` calls `call_llm` to validate the refined solution. The overall workflow is sequential, where each function is called in order, passing the results of the previous function to the next."
  }
]

        COMMON ERROR PATTERNS:
        []

        PRIMARY ISSUES (last 3 iterations):
        [
  {
    "iteration": 0,
    "issue": "The most critical problem to fix is the **inaccuracy in performing arithmetic and logical calculations**. This includes median calculation, LCM calculations, and general numerical manipulation errors within algebraic solutions. This undermines the entire solution process, even if the initial problem setup and equation formulation are correct."
  },
  {
    "iteration": 1,
    "issue": "The most critical problem is the consistent failure of the LLM call due to a `NoneType` argument. This suggests a data processing stage before the LLM call is producing a `None` value unexpectedly, which is then being passed as an argument when it should be an iterable. We need to identify *where* this `None` is originating and *why*."
  },
  {
    "iteration": 2,
    "issue": "The most critical problem is the **inconsistent and incomplete application of constraints within the problem statement**. This results in misinterpretations, contradictions, and ultimately, incorrect solutions or the system giving up."
  },
  {
    "iteration": 3,
    "issue": "Given there are no error cases to analyze, there is no primary issue to fix."
  },
  {
    "iteration": 4,
    "issue": "The most critical problem to fix is the **incomplete enumeration of possibilities and the lack of rigorous constraint enforcement**. This leads to undercounting favorable outcomes in probability problems or overlooking invalid solutions in other problem types. The system needs a better mechanism to ensure all possibilities are considered and that solutions are rigorously checked against constraints."
  },
  {
    "iteration": 5,
    "issue": "The primary issue is the system's vulnerability to making numerical calculation mistakes, which leads to incorrect answers, particularly when dealing with decimal expansions and modular arithmetic."
  },
  {
    "iteration": 6,
    "issue": "The primary issue is the lack of robust solution verification. The system can perform the necessary steps to solve the problems, but it fails to adequately check its work for arithmetic errors. This leads to incorrect final answers, even when the overall approach is correct."
  }
]

        TARGETED IMPROVEMENTS:
        [
  "Develop More Robust Board State Representation and Transition Logic:** For game board problems, improve the internal representation of the board state and the logic for determining valid transitions between states. This might involve using graph structures or state transition tables.",
  "String Formatting Debugging:** When building strings, ensure that escape sequences and special characters are correctly handled to prevent errors like \"Invalid \\\\escape\". Introduce unit tests specifically for string formatting.",
  "Strengthen Self-Critique:** Enhance the self-critique process to specifically target arithmetic errors and logical inconsistencies. The critique should be more detailed and focus on verifying the correctness of each step.",
  "Test-Driven Development:** Use a test-driven development approach to create a suite of test cases with known solutions. The system can then run these test cases to identify and fix errors.",
  "Constraint Programming Techniques:** Incorporate constraint programming techniques to represent and manage constraints explicitly, allowing the system to prune search paths that violate constraints early on.",
  "Implement Robust Numerical Verification:** Add checks after each numerical computation to verify the result's validity (e.g., using modular arithmetic checks, or comparing with known properties of the numbers involved).",
  "Introduce Redundancy:** Introduce redundancy by performing calculations in multiple ways and comparing the results. For instance, the distance could be calculated differently, and then compared.",
  "Implement a Numerical Checker:** Develop a numerical checker that can automatically verify the accuracy of calculations involving square roots and other mathematical operations. This checker could use a numerical approximation to compare intermediate results and identify potential errors.",
  "Add Explicit Verification Steps:** Include explicit verification steps in the solution process, where each candidate solution is rigorously checked against all constraints.",
  "Add Unit Tests for Edge Cases:** Create unit tests that specifically target cases like repeating decimals, modular arithmetic with different moduli, and calculations involving vectors."
]
        

EXAMPLE OF EFFECTIVE LLM USAGE PATTERNS:

```python
def extract_information_with_examples(text):
    """Extract key information from the input text using embedded examples."""
    system_instruction = "You are an information extraction specialist focusing on identifying key entities and relationships."
    
    prompt = f"""
    Extract key information from this text. Focus on identifying all entities, relationships, and important attributes.
    
    Example usage:
    
    Input Text:
    The company XYZ Corp reported quarterly earnings of $3.5 million, which represents a 12% increase from last year. The CEO, Jane Smith, attributed this growth to their new product line launched in March, which has already captured 8% of the market share. They expect to expand their operations to Europe by Q2 2023.
    
    Let's think step by step.
    
    The key entities are:
    - XYZ Corp (company)
    - Jane Smith (person, CEO)
    - New product line (product)
    
    The key information points are:
    - Financial: Quarterly earnings of $3.5 million
    - Performance: 12% increase from previous year
    - Product: New product line launched in March
    - Market: 8% market share for new product
    - Plans: Expansion to Europe by Q2 2023
    
    Extracted Information:
    {{
      "entities": [
        {{"name": "XYZ Corp", "type": "company"}},
        {{"name": "Jane Smith", "type": "person", "role": "CEO"}},
        {{"name": "New product line", "type": "product", "launch_date": "March"}}
      ],
      "financial_data": {{
        "quarterly_earnings": "$3.5 million",
        "growth_rate": "12%"
      }},
      "market_data": {{
        "product_market_share": "8%"
      }},
      "future_plans": [
        {{"type": "expansion", "region": "Europe", "timeline": "Q2 2023"}}
      ]
    }}
    
    Now, extract information from this new text:
    {text}
    """
    
    return call_llm(prompt, system_instruction)
```

```python
def verify_solution_with_examples(problem, proposed_solution):
    """Verify if the proposed solution satisfies all requirements using embedded examples."""
    system_instruction = "You are a critical evaluator who verifies if solutions correctly address problems."
    
    prompt = f"""
    Verify if this proposed solution correctly addresses all aspects of the problem.
    
    Example usage:
    
    Problem:
    Design a data structure that can efficiently perform the following operations:
    1. Insert a value
    2. Delete a value
    3. Get a random value with equal probability for all stored values
    All operations should have average time complexity of O(1).
    
    Proposed Solution:
    I'll use a combination of a hashmap and an array. The hashmap will store the value as the key and its index in the array as the value. The array will store all the inserted values.
    
    For insert: Add the value to the end of the array and update the hashmap with the value and its index. O(1) time.
    
    For delete: Look up the index of the value in the hashmap, swap the value with the last element in the array, update the hashmap for the swapped element, remove the last element from the array, and remove the value from the hashmap. O(1) time.
    
    For get random: Generate a random index within the array's bounds and return the value at that index. O(1) time.
    
    Verification:
    Let me check each requirement:
    1. Insert operation: The solution adds the value to the end of the array and updates the hashmap with O(1) time complexity ✓
    2. Delete operation: The solution uses the hashmap to find the index, then swaps with the last element and updates accordingly with O(1) time complexity ✓
    3. Get random operation: The solution generates a random index within the array bounds with O(1) time complexity ✓
    4. All operations have O(1) average time complexity ✓
    
    Result: VALID - The solution correctly addresses all requirements with the specified time complexity.
    
    Problem:
    {problem}
    
    Proposed Solution:
    {proposed_solution}
    
    Verification:
    """
    
    return call_llm(prompt, system_instruction)
```

```python
def solve_with_validation_loop(problem, max_attempts=3):
    """Solve a problem with iterative refinement through validation feedback loop."""
    system_instruction_solver = "You are an expert problem solver who creates detailed, correct solutions."
    system_instruction_validator = "You are a critical validator who carefully checks solutions against all requirements."
    
    # Initial solution generation
    solution_prompt = f"""
    Provide a detailed solution to this problem. Be thorough and ensure you address all requirements.
    
    Problem:
    {problem}
    """
    
    solution = call_llm(solution_prompt, system_instruction_solver)
    
    # Validation loop
    for attempt in range(max_attempts):
        # Validate the current solution
        validation_prompt = f"""
        Carefully validate if this solution correctly addresses all aspects of the problem.
        If the solution is valid, respond with "VALID: [brief reason]".
        If the solution has any issues, respond with "INVALID: [detailed explanation of issues]".
        
        Problem:
        {problem}
        
        Proposed Solution:
        {solution}
        """
        
        validation_result = call_llm(validation_prompt, system_instruction_validator)
        
        # Check if solution is valid
        if validation_result.startswith("VALID:"):
            return solution
        
        # If invalid, refine the solution
        refined_prompt = f"""
        Your previous solution to this problem has some issues that need to be addressed.
        
        Problem:
        {problem}
        
        Your previous solution:
        {solution}
        
        Validation feedback:
        {validation_result}
        
        Please provide a completely revised solution that addresses all the issues mentioned.
        """
        
        solution = call_llm(refined_prompt, system_instruction_solver)
    
    return solution
```

```python
def multi_perspective_analysis(problem):
    """Analyze a problem from multiple specialized perspectives and synthesize the insights."""
    # Define specialized analysis functions
    def analyze_factual_content(problem):
        system_instruction = "You are a factual analyst who focuses on identifying key facts and data points."
        prompt = f"""
        Analyze this problem for factual content only. Identify explicit facts, constraints, and requirements.
        
        Problem:
        {problem}
        """
        return call_llm(prompt, system_instruction)
    
    def analyze_structure(problem):
        system_instruction = "You are a structural analyst who specializes in problem organization and patterns."
        prompt = f"""
        Analyze the structure of this problem. Identify its components, relationships, and patterns.
        
        Problem:
        {problem}
        """
        return call_llm(prompt, system_instruction)
    
    # Execute parallel analyses
    factual_analysis = analyze_factual_content(problem)
    structural_analysis = analyze_structure(problem)
    
    # Synthesize the results
    synthesis_prompt = f"""
    Synthesize these two different analyses of the same problem into a comprehensive understanding.
    
    Factual Analysis:
    {factual_analysis}
    
    Structural Analysis:
    {structural_analysis}
    
    Provide a unified analysis that leverages both perspectives.
    """
    
    return call_llm(synthesis_prompt, "You are an insight synthesizer who combines multiple analyses.")
```

```python
def best_of_n_approach(problem, n=3):
    """Generate multiple solutions and select the best one based on a quality evaluation."""
    system_instruction_solver = "You are an expert problem solver who provides detailed, correct solutions."
    system_instruction_evaluator = "You are a quality evaluator who assesses solutions based on correctness, completeness, and clarity."
    
    # Generate n different solutions
    solutions = []
    for i in range(n):
        diversity_factor = f"Solution approach {i+1}/{n}: Use a different perspective from previous solutions."
        solution_prompt = f"""
        Provide a detailed solution to this problem.
        {diversity_factor if i > 0 else ""}
        
        Problem:
        {problem}
        """
        
        solutions.append(call_llm(solution_prompt, system_instruction_solver))
    
    # Evaluate each solution
    evaluations = []
    for i, solution in enumerate(solutions):
        evaluation_prompt = f"""
        Evaluate this solution on correctness, completeness, and clarity (1-10 scale).
        
        Problem:
        {problem}
        
        Solution {i+1}:
        {solution}
        
        Provide your evaluation as a JSON with scores and explanation.
        """
        
        evaluations.append(call_llm(evaluation_prompt, system_instruction_evaluator))
    
    # Find the best solution
    comparison_prompt = f"""
    Compare these solutions and their evaluations. Select the best one.
    
    Problem:
    {problem}
    
    {["Solution " + str(i+1) + ": " + solutions[i] + "\n\nEvaluation: " + evaluations[i] for i in range(n)]}
    
    Which solution is best? Respond with the solution number and explanation.
    """
    
    best_solution_index = int(call_llm(comparison_prompt, "You are a solution selector.").split()[1]) - 1
    return solutions[best_solution_index]
```

```python
def solve_with_react_pattern(problem):
    """Solve problems through iterative Reasoning and Acting (ReAct) approach."""
    system_instruction = "You are a problem-solving agent that follows the ReAct pattern: Reason about the current state, take an Action, observe the result, and repeat until reaching a solution."
    
    # Initialize ReAct process
    prompt = f"""
    Solve this problem using the ReAct pattern - alternate between Reasoning and Acting until you reach a final answer.
    
    Example usage:
    
    Problem: What is the capital of the country where the Great Barrier Reef is located, and what is the population of that capital?
    
    Thought 1: I need to determine which country the Great Barrier Reef is in, then find its capital, and finally the population of that capital.
    Action 1: Search[Great Barrier Reef location]
    Observation 1: The Great Barrier Reef is located off the coast of Queensland in northeastern Australia.
    
    Thought 2: Now I know the Great Barrier Reef is in Australia. I need to find Australia's capital city.
    Action 2: Search[capital of Australia]
    Observation 2: The capital of Australia is Canberra.
    
    Thought 3: Now I need to find the population of Canberra.
    Action 3: Search[population of Canberra]
    Observation 3: As of 2021, the population of Canberra is approximately 431,500.
    
    Thought 4: I have found all the required information. The capital of Australia (where the Great Barrier Reef is located) is Canberra, and its population is approximately 431,500.
    Action 4: Finish[The capital of Australia is Canberra, with a population of approximately 431,500.]
    
    Now solve this new problem:
    {problem}
    
    Start with Thought 1:
    """
    
    # Initial reasoning and action planning
    react_response = call_llm(prompt, system_instruction)
    
    # Extract the action from the response
    action = extract_action(react_response)
    
    # Continue the ReAct loop until we reach a "Finish" action
    while not action["type"] == "Finish":
        # Perform the requested action and get an observation
        if action["type"] == "Search":
            observation = perform_search(action["query"])
        elif action["type"] == "Calculate":
            observation = perform_calculation(action["expression"])
        elif action["type"] == "Lookup":
            observation = perform_lookup(action["term"])
        else:
            observation = f"Unknown action type: {action['type']}"
        
        # Continue the ReAct process with the new observation
        continuation_prompt = f"""
        {react_response}
        Observation {action["step_number"]}: {observation}
        
        Continue with the next thought and action:
        """
        
        # Get the next reasoning step and action
        react_response += "\n" + call_llm(continuation_prompt, system_instruction)
        
        # Extract the next action
        action = extract_action(react_response)
    
    # Extract the final answer from the Finish action
    final_answer = action["answer"]
    return final_answer

def extract_action(text):
    """Parse the ReAct response to extract the current action."""
    # Find the last action in the text
    action_matches = re.findall(r"Action (\d+): (\w+)\[(.*?)\]", text)
    if not action_matches:
        return {"type": "Error", "step_number": 0, "query": "No action found"}
    
    # Get the most recent action
    last_action = action_matches[-1]
    step_number = int(last_action[0])
    action_type = last_action[1]
    action_content = last_action[2]
    
    # Handle different action types
    if action_type == "Finish":
        return {"type": "Finish", "step_number": step_number, "answer": action_content}
    elif action_type in ["Search", "Lookup", "Calculate"]:
        return {"type": action_type, "step_number": step_number, "query": action_content}
    else:
        return {"type": "Unknown", "step_number": step_number, "query": action_content}

def perform_search(query):
    """Simulate a search action in the ReAct pattern."""
    # In a real implementation, this would call an actual search API
    return call_llm(f"Provide a factual answer about: {query}", "You are a helpful search engine that provides concise, factual information.")

def perform_calculation(expression):
    """Perform a calculation action in the ReAct pattern."""
    try:
        # Safely evaluate the expression
        result = eval(expression, {"__builtins__": {}}, {"math": math})
        return f"The result is {result}"
    except Exception as e:
        return f"Error in calculation: {str(e)}"

def perform_lookup(term):
    """Simulate a lookup action for specific information."""
    # In a real implementation, this would query a knowledge base or database
    return call_llm(f"Provide specific information about: {term}", "You are a knowledge base that provides specific factual information.")
```MULTI-EXAMPLE PROMPTING GUIDANCE:
        1. CRITICAL: Use MULTIPLE examples (2-5) in EVERY LLM prompt, not just one
        2. Vary the number of examples based on task complexity - more complex tasks need more examples
        3. Select diverse examples that showcase different patterns and edge cases
        4. Structure your few-shot examples to demonstrate clear step-by-step reasoning
        5. Consider using both "easy" and "challenging" examples to help the LLM learn from contrasts
        6. The collection of examples should collectively cover all key aspects of the problem
        7. When available, use examples from previous iterations that revealed specific strengths or weaknesses.
        8. USE REAL EXAMPLES FROM THE DATASET WHERE POSSIBLE!!

        Example of poor single-example prompting:
        ```python
        def extract_entities(text):
            prompt = f'''
            Extract entities from this text.

            Example:
            Text: John will meet Mary at 3pm on Tuesday.
            Entities: {{"people": ["John", "Mary"], "time": "3pm", "day": "Tuesday"}}

            Text: {text}
            Entities:
            '''
            return call_llm(prompt)
        ```

        Example of effective multi-example prompting:
        ```python
        def extract_entities(text):
            prompt = f'''
            Extract entities from this text.

            Example 1:
            Text: John will meet Mary at 3pm on Tuesday.
            Entities: {{"people": ["John", "Mary"], "time": "3pm", "day": "Tuesday"}}

            Example 2:
            Text: The team needs to submit the report by Friday at noon.
            Entities: {{"people": ["the team"], "time": "noon", "day": "Friday", "object": "report"}}

            Example 3:
            Text: Alex cannot attend the conference from Jan 3-5 due to prior commitments.
            Entities: {{"people": ["Alex"], "event": "conference", "date_range": ["Jan 3-5"], "reason": "prior commitments"}}

            Text: {text}
            Entities:
            '''
            return call_llm(prompt)
        ```

        === DIRECT LLM REASONING APPROACH ===

        CRITICAL: Previous scripts have shown that complex code generation with JSON parsing and multi-step pipelines often 
        leads to errors and low performance. Instead, focus on leveraging the LLM's natural reasoning abilities:

        1. SIMPLIFY YOUR APPROACH:
           - Minimize the number of processing steps - simpler is better
           - Directly use LLM for pattern recognition rather than writing complex code
           - Avoid trying to parse or manipulate JSON manually - pass it as text to the LLM

        2. DIRECT TRANSFORMATION:
           - Instead of trying to extract features and then apply them, use the LLM to do the transformation directly
           - Use examples to teach the LLM the pattern, then have it apply that pattern to new inputs
           - Avoid attempting to write complex algorithmic solutions when pattern recognition will work better

        3. ROBUST ERROR HANDLING:
           - Include multiple approaches in case one fails (direct approach + fallback approach)
           - Use simple validation to check if outputs are in the expected format
           - Include a last-resort approach that will always return something valid

        4. AVOID COMMON PITFALLS:
           - Do NOT attempt to use json.loads() or complex JSON parsing - it often fails
           - Do NOT create overly complex Python pipelines that require perfect indentation
           - Do NOT create functions that generate or execute dynamic code
           - Do NOT create unnecessarily complex data transformations

        5. SUCCESSFUL EXAMPLES:
           - The most successful approaches have used direct pattern matching with multiple examples
           - Scripts with simple validation and fallback approaches perform better
           - Scripts with fewer processing steps have higher success rates
        
        IMPLEMENTATION STRATEGIES:
        1. Maintain a "example bank" of successful and failed examples to select from
        2. Implement n-shot prompting with n=3 as default, but adapt based on performance
        3. For complex tasks, use up to 5 examples; for simpler tasks, 2-3 may be sufficient
        4. Include examples with a range of complexity levels, rather than all similar examples



        VALIDATION AND VERIFICATION GUIDANCE:
        1. CRITICAL: Consider implementing validation loops for EACH key processing step, not just final outputs
        2. Design your system to detect, diagnose, and recover from specific errors. This will help future learnings
        3. For every LLM extraction or generation, add a verification step that checks:
           - Whether the output is well-formed and complete
           - Whether the output is logically consistent with the input
           - Whether all constraints are satisfied
        4. Add feedback loops that retry failures with specific feedback
        5. Include diagnostic outputs that reveal exactly where failures occur. Add print statements and intermediate outputs such that you can see them later to determine why things are going wrong.
        6. Include capability to trace through execution steps to identify failure points

        Example of pipeline without verification:
        ```python
        def process_question(question):
            entities = extract_entities(question)
            constraints = identify_constraints(question)
            solution = generate_solution(entities, constraints)
            return solution
        ```

        Example of robust pipeline with verification:
        ```python
        def process_question(question, max_attempts=3):
            # Step 1: Extract entities with verification
            entities_result = extract_entities_with_verification(question)
            if not entities_result.get("is_valid"):
                print(f"Entity extraction failed: {entities_result.get('validation_feedback')}")
                return f"Error in entity extraction: {entities_result.get('validation_feedback')}"

            # Step 2: Identify constraints with verification
            constraints_result = identify_constraints_with_verification(question, entities_result["entities"])
            if not constraints_result.get("is_valid"):
                print(f"Constraint identification failed: {constraints_result.get('validation_feedback')}")
                return f"Error in constraint identification: {constraints_result.get('validation_feedback')}"

            # Step 3: Generate solution with verification
            solution_result = generate_solution_with_verification(
                question, 
                entities_result["entities"], 
                constraints_result["constraints"]
            )
            if not solution_result.get("is_valid"):
                print(f"Solution generation failed: {solution_result.get('validation_feedback')}")
                return f"Error in solution generation: {solution_result.get('validation_feedback')}"

            return solution_result["solution"]

        def extract_entities_with_verification(question, max_attempts=3):
            #Extract entities and verify their validity with feedback loop.
            system_instruction = "You are an expert at extracting and validating entities."

            for attempt in range(max_attempts):
                # First attempt at extraction
                extraction_prompt = f'''
                Extract key entities from this question. 
                Return a JSON object with the extracted entities.

                Example 1: [example with entities]
                Example 2: [example with different entities]
                Example 3: [example with complex entities]

                Question: {question}
                Extraction:
                '''

                extracted_data = call_llm(extraction_prompt, system_instruction)

                try:
                    # Parse the extraction
                    data = json.loads(extracted_data)

                    # Verification step
                    verification_prompt = f'''
                    Verify if these extracted entities are complete and correct:

                    Question: {question}
                    Extracted entities: {json.dumps(data, indent=2)}

                    Check if:
                    1. All relevant entities are extracted
                    2. No irrelevant entities are included
                    3. All entity values are correct

                    Return a JSON with:
                    {{
                      "is_valid": true/false,
                      "validation_feedback": "detailed explanation",
                      "missing_entities": ["entity1", "entity2"],
                      "incorrect_entities": ["entity3"]
                    }}
                    '''

                    verification_result = call_llm(verification_prompt, system_instruction)
                    verification_data = json.loads(verification_result)

                    if verification_data.get("is_valid", False):
                        data["is_valid"] = True
                        data["validation_feedback"] = "All entities are valid."
                        return data

                    # If not valid and we have attempts left, refine with feedback
                    if attempt < max_attempts - 1:
                        feedback = verification_data.get("validation_feedback", "")
                        print(f"Validation failed (attempt {attempt+1}/{max_attempts}): {feedback}")
                        continue

                    # If we're out of attempts, return the best we have with validation info
                    data["is_valid"] = False
                    data["validation_feedback"] = verification_data.get("validation_feedback", "Unknown validation error")
                    return data

                except Exception as e:
                    print(f"Error in extraction/validation (attempt {attempt+1}/{max_attempts}): {str(e)}")
                    if attempt >= max_attempts - 1:
                        return {
                            "is_valid": False,
                            "validation_feedback": f"Error during processing: {str(e)}"
                        }

            return {
                "is_valid": False,
                "validation_feedback": "Failed to extract valid entities after multiple attempts."
            }
        ```

        VALIDATION IMPLEMENTATION STRATEGIES:
        1. Create detailed verification functions for each major processing step
        2. Implement max_attempts limits on all retry loops (typically 3-5 attempts)
        3. Pass specific feedback from verification to subsequent retry attempts
        4. Log all verification failures to help identify systemic issues
        5. Design fallback behaviors when verification repeatedly fails

        
    
            
        ACCUMULATED LEARNINGS FROM PREVIOUS ITERATIONS:
        ```
# Math Question Dataset: Evolving Research Log

This document serves as a dynamic research log, capturing our evolving understanding, strategies, and findings related to the task of solving math questions from the provided dataset. It prioritizes concrete, task-specific insights.

## 1. DATASET PATTERNS & CHARACTERISTICS

*   **Mathematical Content Variety:** The dataset contains a diverse set of math problems, encompassing arithmetic, number theory, and probability, in addition to algebra, geometry, and more complex topics. This requires the system to handle a broad range of mathematical concepts and problem-solving strategies. Examples include divisibility rules, prime factorization, area calculations, and probability calculations.
*   **Question Content:** Predominantly multi-step mathematical reasoning problems. Requires a combination of algebra, geometry, and number theory. Questions range in complexity, requiring both computational and conceptual understanding.
*   **Mathematical Formulation:** Questions are primarily mathematical problems, often requiring symbolic manipulation (using LaTeX notation), number theory concepts, or geometric reasoning.
*   **Multi-Step Solutions:** The "expected" answers often involve multiple steps of logical deduction or calculation. This reinforces the necessity of decomposing problems into smaller, manageable sub-problems.
*   **Word Problem Complexity:** Questions are presented as word problems, often involving fictional scenarios or abstract concepts (e.g., "Penteria"). This necessitates strong natural language understanding to correctly translate the problem into mathematical terms.
*   **Answer Style:** Concise, step-by-step solutions using LaTeX. Final answers often boxed. Answers often need to be expressed within a specific range or format (e.g., "an integer from 0 to 16, inclusive"), indicating a need for the model to be precise with its final result.
*   **Formatting:** Uses LaTeX for mathematical expressions and Asymptote code for diagrams. Accurate LaTeX interpretation is crucial. The inclusion of diagrams using `[asy]` is a common feature.
*   **Numerical Focus:** Many questions require finding specific numerical values (e.g., smallest possible value, probability, arithmetic mean), demanding precise calculations.
*   **Reasoning Types:** Deductive, algebraic manipulation, spatial, computational, and logical.
*   **Hidden Constraints and Assumptions:** Problems often rely on implicit constraints or assumptions that are not explicitly stated, making accurate interpretation challenging. For example, the "Penteria" problem implicitly assumes the initial population is a positive integer. Explicitly add constraints to the problem that the initial population must be a positive integer (e.g., in "Penteria"-like problems).
*   **Dataset Size and Diversity:** While initial experiments focused on smaller samples, the dataset contains sufficient variety in topics (number theory, algebra, probability, etc.) and difficulty to necessitate testing robustness and generalizability. This includes abstract concepts and creative problem-solving skills.
*   **Multi-faceted problems:** The dataset contains questions that often require a combination of different mathematical concepts (e.g., geometry and vector algebra, number theory and combinatorics, probability and spatial reasoning). This necessitates a broad knowledge base and the ability to synthesize information from different domains.
*   **Visual component integration:** Many questions include diagrams or visual aids (e.g., geometric figures, game boards) that are crucial for understanding and solving the problem. The system needs to be able to effectively interpret and utilize this visual information. The spatial reasoning and extraction of numerical data from the images is a common requirement. For example, determining valid board positions after N moves.
*   **Constraint-heavy problems:** A significant number of problems impose constraints on the solution, such as restrictions on digit usage or valid moves on a game board. The system must be able to explicitly identify, represent, and enforce these constraints during the solution process.
*   **Variable Definitions & State Management:** A common pattern is the presence of defined variables and relationships that need to be understood and applied (e.g., "$n$ is the inverse of $2 \\pmod{17}$"). This requires the model to maintain state and correctly substitute values.
*   **Fractions, Modular Arithmetic, and Algebraic Expressions:** The dataset consists of math problems, often requiring a sequence of calculations and manipulations involving fractions, modular arithmetic, and algebraic expressions.
*   **Repeating Decimal Expansions:** Problems involving repeating decimal expansions pose a challenge. The model struggles to identify and utilize the repeating pattern to find a specific digit far down the sequence.
*   **Answers often require simplification:** expressing radicals in simplest form, providing probabilities as common fractions.
*   **Geometry problems involving geometric figures or concepts:** Geometry problems often require visual reasoning or the application of geometric theorems (Pythagorean theorem, area/volume calculations).
*   **Examples:**
    *   Geometry problems involving area/circumference calculations, vector geometry.
    *   Number theory problems involving divisibility, digit sums, and prime factorization.
    *   Algebra problems involving solving equations.
    *   Probability Problems involving calculations based on provided sets.
    *   Probability problems involving spatial reasoning on a game board (e.g., requiring identifying all possible paths to a target sum).

## 2. EFFECTIVE TASK-SPECIFIC STRATEGIES

*   **Ineffective (Baseline):** Direct LLM call. Accuracy ~50%. Insufficient for the complexity and precision required.
*   **(Untested) Chain-of-Thought (CoT):** Breaking down questions into smaller, manageable sub-problems appears promising due to the multi-step nature of the solutions. However, this strategy remained untested initially due to data processing errors preventing successful LLM calls. Now integrated into the more successful "Decompose-Solve-Verify" approach.
*   **Modular Analysis:** The "Problem Analyzer" agent's structured JSON output (problem type, topic, knowns, unknowns, steps) appears beneficial in breaking down complex problems into manageable components. This structured representation can be leveraged for more robust reasoning. Incorporated into "Decompose-Solve-Verify".
*   **Prime Factorization Considerations:** Prime factorization of relevant values (e.g., set members in probability problems) can be crucial for identifying solutions.
*   **Decompose-Solve-Verify:** This approach breaks down complex problems into manageable sub-problems. This has proven effective in recent experiments, contributing to a 100% accuracy rate in one iteration. It is particularly useful for math problems with multiple steps. The approach seems to work better when individual sub-problems are relatively straightforward and don't require complex reasoning on their own.
*   **Reflexion-Enhanced Solution Synthesis:** Decomposing the problem into initial solution, critique, refined solution, and validation stages seems to provide a structured approach that encourages more careful consideration of each step.
*   **Using the distance formula:** Useful strategy to solve geometry questions.
*   **Multi-Example Prompting:** Guiding the LLM with multiple examples improves accuracy by providing relevant context. Multi-example prompting is useful for guiding the LLM in each stage (decomposition, solving, synthesis, verification). This helps to align the model's reasoning with the desired approach.
*   **Specialized System Instructions:** Using specialized system instructions for each step of the process (e.g., "expert at decomposing complex math problems") enhances the quality of the LLM's output. This applies specifically to the "Decompose-Solve-Verify" approach.
*   **Explicit Knowledge Retrieval and Verification:** Explicitly retrieving and verifying knowledge seems beneficial as a first step. The accuracy, however, hinges on *how* the knowledge is used in the subsequent synthesis step.
*   **Implement a constraint-aware search algorithm:** For problems involving constraints (e.g., valid moves, digit restrictions), integrate a search algorithm (e.g., backtracking, breadth-first search) into the solution synthesis agent. This algorithm should systematically explore the solution space while explicitly enforcing all constraints. The model needs to develop the ability to explore more scenarios, and intelligently backtrack when an invalid possibility is found.
*   **Develop a visual reasoning module:** Enhance the system's ability to interpret and extract information from diagrams and visual aids. Consider incorporating techniques for image analysis, shape recognition, and spatial reasoning. This would allow the system to better understand the spatial relationships and constraints presented in the visual components of the problems.
*   **Focus on exhaustive reasoning and validation:** The solution synthesis agent needs to explicitly justify each step of its reasoning, demonstrating why each possibility is either valid or invalid. This requires more detailed explanations and explicit references to the problem's constraints. The agent should aim for a more exhaustive and rigorous analysis of the solution space.
*   **Increase exploration and back-tracking:** Develop the ability for the model to explore more scenarios, and intelligently backtrack when an invalid possibility is found.

## 3. COMMON FAILURE MODES ON THIS DATASET

*   **Arithmetic and Logical Calculation Errors:** Consistent errors in basic arithmetic and logical calculations (e.g., median, probability). *Example: Incorrectly calculating the median in the stem and leaf plot question.* The system frequently makes mistakes in arithmetic, particularly when dealing with decimal expansions (e.g., calculating digits of repeating decimals) and modular arithmetic (e.g., finding modular inverses and computing powers modulo n). This often leads to completely incorrect final answers. Arithmetic errors during simplification, especially with radicals. The LLM doesn't consistently verify these calculations.
*   **Misinterpretation of Problem Context:** Failing to fully understand the constraints or conditions stated in the problem, leading to incorrect solution paths. *Example: LLM jumps directly to a numerical answer without proper justification in divisibility question.* In the "Penteria" problem, the LLM does not properly handle the hourly reset condition.
*   **LaTeX Interpretation Issues:** Subtle errors in interpreting LaTeX can lead to misconstrued equations and wrong answers.
*   **Difficulty:** Understanding the problem statement, which may involve complex mathematical notation. Choosing the right approach and applying the correct formulas. Performing accurate calculations. Dealing with multi-step problems requiring a sequence of logical deductions. Interpreting visual information from diagrams (when present).
*   **Edge Cases/Complexities:** Problems with subtle wording that can lead to misinterpretation. Questions requiring creative problem-solving or non-obvious insights. Diagrams that may be misleading or require careful analysis. Calculations involving fractions, radicals, or other potentially error-prone operations.
*   **`NoneType` Error in LLM Call:** The LLM call consistently failed due to receiving a `NoneType` argument. This suggests a problem with the script's data processing flow *before* the `call_llm` function. A variable expected to hold a string or iterable (likely the prompt or a list of sub-questions) is unexpectedly becoming `None`.
    *   **Script Error Log [2025-05-28 01:51:54]:** ERROR: TypeError: 'NoneType' is not iterable
    *   **Script Error Log [2025-05-28 01:51:59]:** ERROR: NoneType not iterable
    *   **Script Error Log [2025-05-28 01:52:04]:** ERROR: TypeError: 'NoneType' is not iterable
*   **Inconsistent Application of Constraints:** The primary failure mode is the model's inability to consistently apply constraints within the problem statement. This leads to misinterpretations and incorrect solutions. For example, in the "Penteria" problem, the LLM does not properly handle the hourly reset condition.
*   **Misinterpreting Problem Logic:** Even with a structured analysis, the "Solution Generator" struggles to translate the analysis into correct mathematical operations. In the "Penteria" problem, the agent misinterprets the problem's reset condition and makes incorrect calculations.
*   **Inability to handle implicit constraints:** The set member values of {2, 4, 12, 14, 21, 28, 98} are all positive integers. The solution does not seem to check that the initial population of the Penteria problem should also be a positive integer. This highlights the need for explicit constraint handling.
*   **Ambiguity and Complexity:** Even with successful strategies like "Decompose-Solve-Verify," more challenging or ambiguous questions could reveal new failure modes, emphasizing the need for continuous testing and refinement.
*   **Incomplete Enumeration (Probability):** The probability question demonstrates a key failure mode: the inability to systematically enumerate all possible valid scenarios. The model identifies *some* paths that lead to the target sum (30), but fails to account for all of them, leading to an underestimation of the probability. The failure occurs because the system lacks a robust search or backtracking mechanism to explore the entire solution space while respecting the problem's constraints.
*   **Missing edge cases and invalid paths:** In the provided example, the "actual" solution explores a handful of paths but prematurely deems other paths as invalid without fully justifying why. The system needs to be more thorough and explicitly show *why* each possibility is (or isn't) valid.
*   **Weak constraint enforcement:** Constraints, such as the allowable movements on the game board, are not consistently enforced. This results in the inclusion of impossible sequences of moves, skewing the calculation of favorable outcomes.
*   **Lack of Precision:** Even when the overall strategy is correct, small inaccuracies in calculations or a failure to adhere to the required answer format (e.g., failing to reduce modulo 17) lead to incorrect answers. This indicates a lack of "carefulness" in the execution.
*   **Error Propagation:** The "Decompose-Solve-Verify" strategy, while conceptually sound, is highly susceptible to error propagation. A single mistake in any of the sub-steps can invalidate the entire solution.
*   **Difficulty with Repeating Patterns:** Problems involving repeating decimal expansions pose a challenge. The model struggles to identify and utilize the repeating pattern to find a specific digit far down the sequence.
*   **Lack of Quantitative Validation:** The validation step in the current approach seems more focused on reiterating the logic rather than performing independent numerical checks. It fails to catch errors stemming from miscalculations.
*   **Self-critique Limitations:** The self-critique stage, while logically sound, doesn't reliably identify subtle arithmetic errors. The LLM often confirms the correctness of a flawed solution.

## 4. EXPERIMENT LOG & FINDINGS

*   **Experiment 0 (Baseline):**
    *   **Description:** Direct call to the LLM with the question.
    *   **Accuracy:** ~50%
    *   **Findings:** The baseline approach is inadequate. Requires more than just general knowledge; necessitates precise calculation and logical reasoning capabilities. Calculation errors and misinterpretations of context are frequent.
*   **Experiment 1:**
    *   **Description:** Attempt to implement a Chain-of-Thought (CoT) approach by breaking down the question into sub-questions.
    *   **Accuracy:** 0% (LLM call failed consistently)
    *   **Findings:** The core CoT strategy remains untested *in isolation*. The LLM call consistently fails due to a `NoneType` error originating *before* the `call_llm` function. Further debugging is needed to identify the source of the `None` value. Error handling only catches exceptions *during* the LLM call, not problems in data preparation *before* the call. The `NoneType` error halted script execution, preventing any assessment of the CoT's effectiveness on this dataset. Highlighted the importance of robust input validation. The underlying principle of CoT, however, contributed to the later "Decompose-Solve-Verify" success.
*   **Experiment 2:**
    *   **Description:** Implemented a modular approach with "Problem Analyzer," "Solution Generator," and "Solution Validator" agents. The "Problem Analyzer" generated structured JSON output.
    *   **Accuracy:** 0.33
    *   **Findings:** The initial hypothesis that decomposing the problem into analysis, solution generation, and validation steps helps in math problem-solving is partially supported, as indicated by the structured JSON output. However, the low accuracy indicates that the current implementation of this approach is not robust enough. Highlights the limitations of the Gemini LLM in complex mathematical reasoning, especially when dealing with implicit constraints and nuanced problem logic. Ultimately led to the development of the "Decompose-Solve-Verify" strategy.
*   **Experiment 3:**
    *   **Description:** Implemented the "Decompose-Solve-Verify" approach with multi-example prompting and specialized system instructions.
    *   **Accuracy:** 1.00
    *   **Findings:** This experiment confirms that the "Decompose-Solve-Verify" approach, combined with multi-example prompting and specialized system instructions, can effectively solve math word problems in this dataset, at least on the tested sample. However, further testing on a larger and more diverse dataset is needed to ensure robustness and generalizability. A perfect accuracy suggests that the LLM can handle the complexity and variety of questions *within the tested sample*.
*   **Experiment 4:**
    *   **Description:** "Knowledge Retrieval and Solution Synthesis" approach.
    *   **Findings:** The "Knowledge Retrieval and Solution Synthesis" approach shows promise, but its effectiveness is limited by the subsequent solution synthesis step. Retrieving relevant knowledge is not sufficient if the system cannot apply it correctly and exhaustively to the problem. The isolated success of knowledge retrieval and verification highlights a key area for improvement: enhancing the solution synthesis agent's reasoning and problem-solving capabilities. The failure to consider all possible scenarios suggests that exploration is not wide enough. The system failed to systematically enumerate all valid scenarios and prematurely deemed other paths as invalid without fully justifying why. Constraints were not consistently enforced.
*   **Experiment 5:**
    *   **Description:** Testing "Decompose-Solve-Verify" on a new set of problems involving fractions, modular arithmetic, and algebraic expressions.
    *   **Accuracy:** 60%
    *   **Findings:** The "Decompose-Solve-Verify" strategy, while conceptually sound, is highly susceptible to error propagation. A single mistake in any of the sub-steps can invalidate the entire solution. The 60% accuracy indicates that the core reasoning framework is working to some extent, but the model needs significant improvement in its ability to perform calculations and maintain precision. The experiment highlights the importance of robust calculation and meticulousness, which are challenging for LLMs.
*   **Experiment 6:**
    *   **Description:** Reflexion-Enhanced Solution Synthesis approach.
    *   **Accuracy:** 80%
    *   **Findings:** The Reflexion-Enhanced Solution Synthesis approach demonstrates potential, achieving 80% accuracy, but is vulnerable to arithmetic mistakes. The self-critique stage, while logically sound, doesn't reliably identify subtle arithmetic errors. The LLM often confirms the correctness of a flawed solution.

## 5. NEXT RESEARCH DIRECTIONS

*   **Debugging Data Flow:** *HIGH PRIORITY*. Revisit and thoroughly debug the data flow to prevent `NoneType` errors. Add print statements or logging to track the values of variables at each step of the data processing pipeline, especially before calling `call_llm`. Specifically, examine the data preparation steps within the `main` function and related functions.
*   **Input Validation:** Add checks *before* calling `call_llm` to ensure that the prompt (or any other input it receives) is not `None`. If it is, log an error message and potentially try to recover (e.g., by substituting a default prompt or skipping the question). Implement a clear error handling strategy for these cases.
*   **Re-evaluate CoT (Indirectly Addressed):** While pure CoT failed initially, the "Decompose-Solve-Verify" approach incorporates the core principle. No need for separate evaluation.
*   **Implement Calculator Tool (Calculator Agent):** Offload arithmetic calculations to a tool for accurate numerical computation. Introduce a specialized "Calculator" agent that performs arithmetic operations. The main LLM agent should delegate all calculations to this agent to minimize numerical errors. The Calculator agent can be rule-based, calling an external calculator, or fine-tuned specifically for calculation.
*   **Enhance Verification with Calculation Checks:** Modify the validation step (either the existing `check_coherency` function or the validation stage within Reflexion-Enhanced Synthesis) to include concrete numerical checks *independent* of the derived symbolic solution and to specifically verify the correctness of intermediate calculations. This would involve re-performing the calculations and comparing the results. This could involve:
    *   Substituting the calculated answer back into the original problem statement to see if it satisfies the conditions.
    *   Using alternative methods to calculate intermediate values and comparing them to the derived values.
    *   For geometry problems, testing if the calculated lengths and angles satisfy geometric constraints (e.g., triangle inequality).
*   **Focus on Unit Testing of Simplification Steps:** Add unit tests or specific checks within the simplification logic to ensure that radical simplification, fraction reduction, etc., are performed correctly. This could involve comparing the numerical values of expressions before and after simplification.
*   **Prompt Engineering for Validation:** Re-engineer the prompt for the validation stage (within Reflexion-Enhanced Synthesis) to explicitly instruct the LLM to look for potential arithmetic errors and to perform independent calculations to verify the result.
*   **Dataset Augmentation for Arithmetic Errors:** Intentionally introduce examples into the training/fine-tuning set that have subtle arithmetic errors in the "initial solution" to train the LLM to better detect and correct them during the critique and refinement stages (within Reflexion-Enhanced Synthesis).
*   **Step-by-Step Reasoning:** Continue incorporating a step-by-step reasoning approach in the prompt to decompose problems into verifiable steps. This is inherent in "Decompose-Solve-Verify". The solution synthesis agent needs to explicitly justify each step of its reasoning, demonstrating why each possibility is either valid or invalid. This requires more detailed explanations and explicit references to the problem's constraints. The agent should aim for a more exhaustive and rigorous analysis of the solution space.
*   **Verifier Implementation:** Continue to use a verifier to check the LLM's final answer against the problem's constraints and logical consistency. This is already part of the "Decompose-Solve-Verify" framework.
*   **LaTeX Handling Improvement:** Improve LaTeX handling either via pre-processing or prompt engineering.
*   **Constraint Enforcement Module:** Implement a module specifically designed to identify and enforce constraints within the problem statement. This could involve explicitly listing constraints in the JSON output of the "Problem Analyzer" and using them to guide the "Solution Generator." Explicitly add constraints to the problem that the initial population must be a positive integer (e.g., in "Penteria"-like problems).
*   **Targeted Prompt Engineering:** Refine the prompts for the "Solution Generator" to emphasize constraint adherence and logical reasoning.
*   **Self-Consistency Checks:** Incorporate self-consistency checks within the "Solution Validator" to identify contradictions or inconsistencies in the generated solution.
*   **Broader Dataset Testing:** Expand testing to a larger and more diverse set of problems to assess the generalizability and robustness of the "Decompose-Solve-Verify" strategy.
*   **Ambiguity Stress Testing:** Introduce more challenging and ambiguous questions to specifically identify potential failure points and limitations of the current approach.
*   **Efficiency Optimization:** Explore ways to optimize the prompts and system instructions to improve the efficiency and scalability of the "Decompose-Solve-Verify" approach.
*   **Address Repeating Decimal Problems:** Investigate methods for handling repeating decimal problems. This could involve incorporating rules or examples that explicitly demonstrate how to identify repeating patterns and calculate digits at specific positions.
*   **Introduce Unit Tests:** Create a suite of unit tests focused on numerical calculations, modular arithmetic, and other common mathematical operations. This will allow for rapid identification and correction of errors in the calculation logic.
*   **Solution Strategies:** (Reminder of potential techniques)
    *   **Direct Calculation:** Solve the problem by applying relevant formulas and performing calculations directly.
    *   **Equation Solving:** Set up equations based on the problem statement and solve for the unknown variables.
    *   **Geometric Reasoning:** Use geometric properties and relationships to find the solution.
    *   **Casework:** Divide the problem into different cases and solve each case separately.
    *   **Pattern Recognition:** Identify patterns or relationships that can help solve the problem.
*   **Problem Decomposition:** (Reminder of decomposition steps)
    1.  **Understand the Problem:** Carefully read the question and identify the knowns and unknowns. Translate the problem into mathematical notation.
    2.  **Develop a Plan:** Determine which formulas, theorems, or techniques are relevant to the problem.
    3.  **Execute the Plan:** Apply the chosen techniques to solve the problem.
    4.  **Check the Answer:** Verify that the answer is reasonable and consistent with the problem statement.
*   **Validation Techniques:** (Reminder of validation techniques)
    *   **Unit Analysis:** Check that the units of the answer are correct.
    *   **Estimation:** Estimate the answer to see if it's in the right ballpark.
    *   **Substitution:** Plug the answer back into the original problem to see if it works.
    *   **Dimensional Analysis:** Check that the dimensions of the quantities are consistent.
    *   **Consider extreme values:** check the answer works for extreme values of some variable.
*   **Creative Insights:** (Reminder of creative insight techniques)
    *   Sometimes, a geometric problem can be solved more easily using algebra, or vice versa.
    *   Looking for symmetries in the problem can simplify the solution.
    *   Rearranging the problem statement or using a different coordinate system can sometimes reveal a simpler solution path. Think about the problem from a different angle. Can you reframe the question or use a different representation? Instead of trying to solve the problem directly, try to solve a simpler version of the problem first. Draw analogies to other problem domains where similar concepts or techniques apply.
*   **Implementation Recommendations:** (Reminder of implementation aspects)
    *   **Verification Steps:** Mathematical Correctness: The most crucial aspect. Verify that each step in the solution is mathematically sound. Consistency with Problem Statement: Ensure that the solution addresses the specific question asked and uses the given information correctly. Reasonableness of Answer: Check if the answer is reasonable in the context of the problem (e.g., a negative length is likely wrong). Edge Case Testing: Test the solution with edge cases or extreme values to ensure it holds true in all scenarios.
    *   **Intermediate Steps/Representations:** Symbolic Representation: Maintain the problem in symbolic form (using variables and equations) as long as possible to avoid premature numerical evaluation. Equation Tree: Represent the equations as a tree structure to facilitate manipulation and simplification. Diagrammatic Representation: (If applicable) Use a graph or diagram to represent the geometric relationships in the problem.
    *   **Text-Based Techniques:** LaTeX Parsing & Generation: While avoiding complex code generation, leverage LLMs' ability to understand and generate LaTeX. This is crucial for both interpreting questions and formatting answers. Step-by-Step Reasoning Chain: Prompt the LLM to explicitly state its reasoning in a step-by-step manner. This allows for easier debugging and verification. Each step should be a complete sentence. Formula Identification: Train the LLM to identify relevant formulas based on keywords in the problem statement. Equation Simplification: Use prompting to guide the LLM to simplify equations and expressions. Example-Based Learning: Fine-tune the LLM on a large dataset of similar problems and solutions. Verification Prompting: Use separate prompts to verify the correctness of each step in the solution and the final answer. For example, "Is this step logically valid based on the previous step?" "Does this answer make sense in the context of the problem?" Avoid Over-Reliance on Code: Don't try to offload the *reasoning* to external code. Use code only for arithmetic or symbolic manipulation if absolutely necessary, and always verify the results.
```
        
    
            
        CAPABILITY ASSESSMENT & IMPROVEMENT GUIDANCE:
        SYSTEM ANALYSIS & GUIDANCE


        
    
            MULTIPLE TOP PERFORMING APPROACHES TO SYNTHESIZE:
            
=== TOP PERFORMING APPROACH #1 ===
Iteration: 3
Accuracy: 1.00
Approach Summary: The script employs a "Decompose-Solve-Verify" approach using the Gemini LLM, enhanced by multi-example prompting to improve accuracy. The problem is broken down into smaller steps by `decompose_problem`, then `solve_sub_problems` solves these steps, and `synthesize_solutions` combines the solutions into a final answer which is then verified for coherency using `check_coherency`. The `call_llm` function is used as a wrapper to call the Gemini API with different prompts and system instructions, defining roles like "expert at decomposing complex math problems" for each step. The overall workflow involves decomposing the initial question, solving the sub-problems, synthesizing the solutions, verifying that the response is coherent and then returning the final answer or an error message if the coherency check fails.

FULL SCRIPT CODE:
```python
import os
from google import genai
from google.genai import types

def call_llm(prompt, system_instruction=None):
    """Call the Gemini LLM with a prompt and return the response. DO NOT deviate from this example template or invent configuration options. This is how you call the LLM."""
    try:
        # Initialize the Gemini client
        client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))

        # Call the API with system instruction if provided
        if system_instruction:
            response = client.models.generate_content(
                model="gemini-2.0-flash", 
                config=types.GenerateContentConfig(
                    system_instruction=system_instruction
                ),
                contents=prompt
            )
        else:
            response = client.models.generate_content(
                model="gemini-2.0-flash",
                contents=prompt
            )

        return response.text
    except Exception as e:
        print(f"Error calling Gemini API: {str(e)}")
        return f"Error: {str(e)}"

def main(question):
    """
    This script implements a 'Decompose-Solve-Verify' approach with multi-example prompting for each step.
    Hypothesis: Explicit examples in prompts improve accuracy and robustness by guiding the LLM. The solution is checked with another prompt to make sure the response is coherent.
    """

    # Step 1: Decompose the problem into smaller, manageable steps
    def decompose_problem(question):
        """Breaks down the problem into smaller steps."""
        system_instruction = "You are an expert at decomposing complex math problems into smaller, solvable steps."
        prompt = f"""
        Decompose the following math problem into smaller, manageable steps.

        Example 1:
        Problem: What is the area of a square with side length 10, and what is the area if the side length is increased by 50%?
        Decomposition:
        1. Calculate the area of the square with side length 10.
        2. Calculate the new side length after increasing it by 50%.
        3. Calculate the area of the square with the new side length.

        Example 2:
        Problem: A train travels at 60 mph for 2.5 hours. How far does it go and how much time is spent going the first half of the distance if the train travels at a constant velocity?
        Decomposition:
        1. Calculate the total distance traveled.
        2. Divide the total distance by 2.
        3. Calculate the time spent for the first half.

        Problem: {question}
        Decomposition:
        """
        return call_llm(prompt, system_instruction)

    # Step 2: Solve each sub-problem independently
    def solve_sub_problems(decomposition):
        """Solves each sub-problem from the decomposition."""
        system_instruction = "You are an expert at solving math sub-problems."
        prompt = f"""
        Solve the following sub-problems.

        Example:
        Sub-problems:
        1. Calculate the area of the square with side length 10.
        2. Calculate the new side length after increasing it by 50%.
        3. Calculate the area of the square with the new side length.
        Solutions:
        1. 100
        2. 15
        3. 225

         Sub-problems: {decomposition}
        Solutions:
        """
        return call_llm(prompt, system_instruction)

    # Step 3: Synthesize the solutions into a final answer
    def synthesize_solutions(question, sub_problems, solutions):
        """Synthesizes the solutions to the sub-problems into a final answer."""
        system_instruction = "You are an expert at synthesizing solutions to math problems."
        prompt = f"""
        Synthesize the following solutions into a final answer for the given question.

        Example:
        Question: What is the area of a square with side length 10, and what is the area if the side length is increased by 50%?
        Sub-problems:
        1. Calculate the area of the square with side length 10.
        2. Calculate the new side length after increasing it by 50%.
        3. Calculate the area of the square with the new side length.
        Solutions:
        1. 100
        2. 15
        3. 225
        Final Answer: The area of the square with side length 10 is 100. If the side length is increased by 50%, the new area is 225.

        Question: {question}
        Sub-problems: {sub_problems}
        Solutions: {solutions}
        Final Answer:
        """
        return call_llm(prompt, system_instruction)

    #Step 4: Check for response coherency
    def check_coherency(question, solution):
        """Verifies if the solution is coherent."""
        system_instruction = "You are an expert solution coherency verifier."
        prompt = f"""
        Is this response coherent with the question?

        Example 1:
        Question: What is the capital of France?
        Solution: The capital of France is Paris.
        Coherent: True

        Example 2:
        Question: What is the capital of France?
        Solution: I like apples.
        Coherent: False

        Question: {question}
        Solution: {solution}
        Coherent:
        """
        return call_llm(prompt, system_instruction)
    try:
        # Call the decomposition function
        decomposition = decompose_problem(question)
        print(f"Decomposition: {decomposition}")

        # Call the solve sub-problems function
        solutions = solve_sub_problems(decomposition)
        print(f"Solutions: {solutions}")

        # Call the synthesize solutions function
        final_answer = synthesize_solutions(question, decomposition, solutions)
        print(f"Final Answer: {final_answer}")

        #Call the coherency checker
        is_coherent = check_coherency(question, final_answer)
        print(f"Coherency: {is_coherent}")
        if "True" in is_coherent:
            return final_answer
        else:
            return f"Response not coherent. Answer: {final_answer}"
    except Exception as e:
        print(f"Error: {e}")
        return f"Error: {e}"
```

=== TOP PERFORMING APPROACH #2 ===
Iteration: 6
Accuracy: 0.80
Approach Summary: The script uses a "Reflexion-Enhanced Solution Synthesis" approach, where an LLM first generates an initial solution, then critiques its own solution to identify errors, and finally synthesizes a refined solution based on the critique which is then validated. The problem is decomposed into four steps: initial solution generation, reflexion and critique, refined solution synthesis, and verification of the refined solution. The agent roles involved are expert problem solver, critical self-evaluator and solution validator. Other functions used include `call_llm` which is used to interact with the Gemini API.

The function `generate_initial_solution` calls `call_llm` to provide an initial solution to the problem. The function `reflect_and_critique` calls `call_llm` to provide a critique on the solution. The function `synthesize_refined_solution` then calls `call_llm` to provide a refined solution based on the critique. Finally, the function `verify_refined_solution` calls `call_llm` to validate the refined solution. The overall workflow is sequential, where each function is called in order, passing the results of the previous function to the next.

FULL SCRIPT CODE:
```python
import os
from google import genai
from google.genai import types

def call_llm(prompt, system_instruction=None):
    """Call the Gemini LLM with a prompt and return the response. DO NOT deviate from this example template or invent configuration options. This is how you call the LLM."""
    try:
        # Initialize the Gemini client
        client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))

        # Call the API with system instruction if provided
        if system_instruction:
            response = client.models.generate_content(
                model="gemini-2.0-flash", 
                config=types.GenerateContentConfig(
                    system_instruction=system_instruction
                ),
                contents=prompt
            )
        else:
            response = client.models.generate_content(
                model="gemini-2.0-flash",
                contents=prompt
            )

        return response.text
    except Exception as e:
        print(f"Error calling Gemini API: {str(e)}")
        return f"Error: {str(e)}"

def main(question):
    """
    This script implements a "Reflexion-Enhanced Solution Synthesis" approach.
    Hypothesis: Adding a reflection step, where the LLM critiques its OWN initial solution, will lead to improved accuracy.
    This directly addresses the need for better precision by explicitly focusing on self-critique.
    """

    # === Step 1: Initial Solution Generation ===
    def generate_initial_solution(question):
        """Generates an initial solution to the problem."""
        system_instruction = "You are an expert problem solver. Generate a detailed initial solution."
        prompt = f"""
        Provide a detailed initial solution to the following problem:

        Example:
        Problem: What is the area of a square with side length 5?
        Solution: The area of a square is side * side. So, the area is 5 * 5 = 25.
        Answer: 25

        Problem: {question}
        Solution:
        """
        try:
            solution = call_llm(prompt, system_instruction)
            print(f"Initial Solution: {solution}")
            return solution
        except Exception as e:
            print(f"Error generating initial solution: {e}")
            return "Error: Could not generate initial solution."

    # === Step 2: Reflexion and Critique ===
    def reflect_and_critique(question, solution):
        """Reflects on the initial solution and identifies potential issues."""
        system_instruction = "You are a critical self-evaluator. Analyze the solution and identify any potential errors, inconsistencies, or areas for improvement."
        prompt = f"""
        Analyze the following solution to the problem and identify any potential errors or inconsistencies.

        Example:
        Problem: What is the area of a circle with radius 5?
        Solution: The area of a circle is radius * radius. So, the area is 5 * 5 = 25.
        Critique: The solution incorrectly states the formula for the area of a circle. It should be pi * radius^2.

        Problem: {question}
        Solution: {solution}
        Critique:
        """
        try:
            critique = call_llm(prompt, system_instruction)
            print(f"Critique: {critique}")
            return critique
        except Exception as e:
            print(f"Error generating critique: {e}")
            return "Error: Could not generate critique."

    # === Step 3: Refined Solution Synthesis ===
    def synthesize_refined_solution(question, initial_solution, critique):
        """Synthesizes a refined solution based on the initial solution and the critique."""
        system_instruction = "You are an expert problem solver. Use the critique to generate a refined solution."
        prompt = f"""
        Based on the critique, generate a refined solution to the problem.

        Example:
        Problem: What is the area of a circle with radius 5?
        Initial Solution: The area of a circle is radius * radius. So, the area is 5 * 5 = 25.
        Critique: The solution incorrectly states the formula for the area of a circle. It should be pi * radius^2.
        Refined Solution: The area of a circle is pi * radius^2. So, the area is pi * 5^2 = 25pi.
        Answer: 25pi

        Problem: {question}
        Initial Solution: {initial_solution}
        Critique: {critique}
        Refined Solution:
        """
        try:
            refined_solution = call_llm(prompt, system_instruction)
            print(f"Refined Solution: {refined_solution}")
            return refined_solution
        except Exception as e:
            print(f"Error generating refined solution: {e}")
            return "Error: Could not generate refined solution."
    
    # === Step 4: Verification of the Refined Solution ===
    def verify_refined_solution(question, refined_solution):
        """Verifies if the refined solution correctly addresses the problem."""
        system_instruction = "You are a solution validator. Check the solution for correctness and completeness."
        prompt = f"""
        Validate the refined solution for correctness and completeness.

        Example 1:
        Question: What is 2 + 2?
        Solution: 4
        Verdict: Correct.

        Example 2:
        Question: What is the capital of France?
        Solution: London
        Verdict: Incorrect.

        Question: {question}
        Solution: {refined_solution}
        Verdict:
        """
        try:
            validation = call_llm(prompt, system_instruction)
            print(f"Validation: {validation}")
            return validation
        except Exception as e:
            print(f"Error validating solution: {e}")
            return "Error: Could not validate the solution."

    # Call the functions in sequence
    initial_solution = generate_initial_solution(question)
    critique = reflect_and_critique(question, initial_solution)
    refined_solution = synthesize_refined_solution(question, initial_solution, critique)
    validation_result = verify_refined_solution(question, refined_solution)

    return f"Initial Solution: {initial_solution}\nCritique: {critique}\nRefined Solution: {refined_solution}\nValidation: {validation_result}"
```

=== TOP PERFORMING APPROACH #3 ===
Iteration: 4
Accuracy: 0.67
Approach Summary: The script employs a "Knowledge Retrieval and Solution Synthesis" approach using the Gemini LLM with specialized agents. First, `retrieve_knowledge` retrieves relevant information based on the input question, acting as a knowledge retrieval expert. The `verify_knowledge_retrieval` function then verifies the relevance of the knowledge. Finally, `synthesize_solution` acts as a solution synthesis expert, generating a step-by-step solution using the retrieved knowledge. The overall workflow involves retrieving knowledge, verifying it, and then synthesizing a solution based on that knowledge.

FULL SCRIPT CODE:
```python
import os

def call_llm(prompt, system_instruction=None):
    """Call the Gemini LLM with a prompt and return the response. DO NOT deviate from this example template or invent configuration options. This is how you call the LLM."""
    try:
        from google import genai
        from google.genai import types

        # Initialize the Gemini client
        client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))

        # Call the API with system instruction if provided
        if system_instruction:
            response = client.models.generate_content(
                model="gemini-2.0-flash", 
                config=types.GenerateContentConfig(
                    system_instruction=system_instruction
                ),
                contents=prompt
            )
        else:
            response = client.models.generate_content(
                model="gemini-2.0-flash",
                contents=prompt
            )

        return response.text
    except Exception as e:
        print(f"Error calling Gemini API: {str(e)}")
        return f"Error: {str(e)}"

def main(question):
    """
    This script employs a "Knowledge Retrieval and Solution Synthesis" approach.
    Hypothesis: Combining targeted knowledge retrieval with a final synthesis agent can improve problem-solving accuracy. We will also add a verification call to validate the "Targeted Knowledge Retrieval" stage to understand its success in the pipeline.
    """

    # === Step 1: Targeted Knowledge Retrieval ===
    def retrieve_knowledge(question):
        """Retrieves relevant knowledge based on the question."""
        system_instruction = "You are a knowledge retrieval expert. Identify key concepts and retrieve relevant information to solve the given problem."
        prompt = f"""
        Identify the mathematical concepts required to solve the following problem and retrieve relevant formulas or theorems.

        Example 1:
        Problem: What is the area of a circle with a radius of 5?
        Concepts: Area of a circle
        Retrieved Information: The area of a circle is given by the formula A = πr^2, where r is the radius.

        Example 2:
        Problem: Solve for x: 2x + 3 = 7
        Concepts: Solving linear equations
        Retrieved Information: To solve a linear equation, isolate the variable by performing inverse operations on both sides.

        Problem: {question}
        Concepts and Retrieved Information:
        """
        try:
            knowledge = call_llm(prompt, system_instruction)
            print(f"Retrieved Knowledge: {knowledge}")
            return knowledge
        except Exception as e:
            print(f"Error retrieving knowledge: {e}")
            return "Error: Could not retrieve knowledge."

    def verify_knowledge_retrieval(question, knowledge):
        """Verifies if the retrieved knowledge is relevant and complete."""
        system_instruction = "You are an expert at verifying the relevance of the knowledge."
        prompt = f"""
        Verify if the retrieved knowledge is sufficient and necessary to solve the given problem.

        Example 1:
        Problem: What is the area of a circle with a radius of 5?
        Retrieved Knowledge: The area of a circle is given by the formula A = πr^2, where r is the radius.
        Verification: The retrieved knowledge is both necessary and sufficient to solve the problem.

        Example 2:
        Problem: Solve for x: 2x + 3 = 7
        Retrieved Knowledge: To solve a linear equation, isolate the variable by performing inverse operations on both sides.
        Verification: The retrieved knowledge is necessary and sufficient to solve the problem.

        Problem: {question}
        Retrieved Knowledge: {knowledge}
        Verification:
        """

        try:
            verification = call_llm(prompt, system_instruction)
            print(f"Knowledge Verification: {verification}")  # Print validation result
            return verification
        except Exception as e:
            print(f"Error validating solution: {e}")
            return "Error: Could not validate the retrieved knowledge."

    # === Step 2: Solution Synthesis ===
    def synthesize_solution(question, knowledge):
        """Synthesizes a solution based on the retrieved knowledge."""
        system_instruction = "You are a solution synthesis expert. Use the retrieved knowledge to generate a step-by-step solution to the problem."
        prompt = f"""
        Synthesize a step-by-step solution to the problem using the retrieved knowledge.

        Example 1:
        Problem: What is the area of a circle with a radius of 5?
        Retrieved Knowledge: The area of a circle is given by the formula A = πr^2, where r is the radius.
        Solution:
        1. Identify the formula: A = πr^2
        2. Substitute the radius: A = π(5)^2
        3. Calculate the area: A = 25π
        Answer: The area of the circle is 25π.

        Example 2:
        Problem: Solve for x: 2x + 3 = 7
        Retrieved Knowledge: To solve a linear equation, isolate the variable by performing inverse operations on both sides.
        Solution:
        1. Subtract 3 from both sides: 2x = 4
        2. Divide both sides by 2: x = 2
        Answer: x = 2

        Problem: {question}
        Retrieved Knowledge: {knowledge}
        Solution:
        """
        try:
            solution = call_llm(prompt, system_instruction)
            print(f"Synthesized Solution: {solution}")
            return solution
        except Exception as e:
            print(f"Error synthesizing solution: {e}")
            return "Error: Could not synthesize the solution."

    # Call the knowledge retrieval function
    knowledge = retrieve_knowledge(question)
    knowledge_verification = verify_knowledge_retrieval(question, knowledge)

    # Call the solution synthesis function
    solution = synthesize_solution(question, knowledge)

    return f"Knowledge: {knowledge}\nKnowledge Verification: {knowledge_verification}\nSolution: {solution}"
```

    
            EXPLOITATION SYNTHESIS GUIDANCE:
            1. ANALYZE EACH TOP SCRIPT to identify:
               - What specific techniques make each approach successful?
               - What unique strengths does each approach have?
               - What weaknesses or limitations does each approach have?
               - Which components could be combined effectively?
    
            2. IDENTIFY SYNTHESIS OPPORTUNITIES:
               - Which successful techniques from different scripts could work together?
               - How can you combine the best reasoning patterns from multiple approaches?
               - What hybrid approach would leverage strengths while avoiding weaknesses?
               - Can you create a multi-stage pipeline using the best parts of each?
    
            3. CREATE A HYBRID APPROACH that:
               - Takes the most effective reasoning techniques from each top script
               - Combines different successful verification/validation strategies
               - Integrates the best error handling approaches
               - Merges effective prompt engineering techniques from multiple scripts
               - Creates a more robust solution than any individual approach
    
            4. SPECIFIC SYNTHESIS STRATEGIES:
               - If Script A excels at information extraction and Script B excels at reasoning, combine both
               - If Script A has great verification and Script B has great generation, merge the pipelines
               - If multiple scripts use different successful prompting styles, create a multi-perspective approach
               - If different scripts handle different types of errors well, create comprehensive error handling
    
            5. AVOID SIMPLE COPYING:
               - Don't just take one script and make minor changes
               - Don't just concatenate approaches without thoughtful integration
               - Create something that's genuinely better than the sum of its parts
               - Ensure the hybrid approach addresses weaknesses that individual scripts had
    
            CRITICAL REQUIREMENTS FOR SYNTHESIS:
            1. The script MUST be a true hybrid that combines elements from multiple top approaches
            2. Include a clear comment explaining which elements came from which approaches
            3. EVERY LLM PROMPT must include embedded examples showing:
               - Sample input similar to the dataset
               - Expected reasoning steps
               - Desired output format
            4. The hybrid should be more robust than any individual approach
            5. Address the weaknesses identified in the capability assessment through synthesis
    
            Here's how to call the Gemini API. Use this example without modification:
            def call_llm(prompt, system_instruction=None):
    """Call the Gemini LLM with a prompt and return the response. DO NOT deviate from this example template or invent configuration options. This is how you call the LLM."""
    try:
        from google import genai
        from google.genai import types

        # Initialize the Gemini client
        client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))

        # Call the API with system instruction if provided
        if system_instruction:
            response = client.models.generate_content(
                model="gemini-2.0-flash", 
                config=types.GenerateContentConfig(
                    system_instruction=system_instruction
                ),
                contents=prompt
            )
        else:
            response = client.models.generate_content(
                model="gemini-2.0-flash",
                contents=prompt
            )

        return response.text
    except Exception as e:
        print(f"Error calling Gemini API: {str(e)}")
        return f"Error: {str(e)}"
    
            SYNTHESIS IMPLEMENTATION:
            - Create a main function that orchestrates the combined approach
            - Integrate the best reasoning patterns from multiple scripts
            - Combine the most effective verification strategies
            - Merge successful prompt engineering techniques
            - Create comprehensive error handling that addresses issues from all approaches
    
            Return a COMPLETE, RUNNABLE Python script that represents a true synthesis of the top approaches:
            1. Has a main function that takes a question string as input and returns the answer string
            2. Combines reasoning techniques from multiple successful scripts
            3. Integrates the best verification and error handling from different approaches
            4. Includes embedded examples in EVERY LLM prompt
            5. Is COMPLETE - no missing code, no "..." placeholders
            6. Closes all string literals properly
            7. Includes comments explaining which techniques came from which top scripts
    
            BE EXTREMELY CAREFUL TO PROPERLY CLOSE ALL STRING QUOTES AND TRIPLE QUOTES!
            CREATE A TRUE HYBRID THAT'S BETTER THAN ANY INDIVIDUAL APPROACH!
            