
            You are developing a Python script to solve problems using LLM reasoning capabilities.
            You are in the EXPLORATION PHASE. You must generate a NEW approach that's different from previous approaches but informed by their successes and failures. With this approach, you will have a specific NEW HYPOTHESIS or variable you are trying to test. Your goal is to see if this new approach works, and you must add verification and validation steps to deduce if this new change is helpful. You may also test RADICAL NEW APPROACHES that are substantially different from previous approaches. 
            
            You should try NEW THINGS:
            
            Break down the problem into smaller pieces
            Think CREATIVELY about how to solve your problem if other approaches aren't working
            Transform data into different formats to see if it helps

            # YOUR TASK
            You are deeply familiar with prompting techniques and the agent works from the literature. 
            Your goal is to maximize the specified performance metrics by proposing interestingly new agents.
            Observe the past discovered agents and scripts carefully and think about what insights, lessons, or stepping stones can be learned from them.
            Be creative when thinking about the next interesting agent to try. You are encouraged to draw inspiration from related agent papers or academic papers from other research areas.
            Use the knowledge from the archive and inspiration from academic literature to propose the next interesting agentic system design.
            THINK OUTSIDE THE BOX.
            

            Here are example problems from previously seen data:
            [
  {
    "id": 0,
    "question": "Multi-hop reasoning task:\n\nQuestion: What animated movie, starring Danny Devito, featured music written and produced by Kool Kojak?\n\nSupporting Documents:\n=== Document 1: Best Friend's Brother ===\n\"Best Friend's Brother\" is a song performed by American pop recording artist Victoria Justice, billed as Cast of \"Victorious\" featuring Victoria Justice. It was produced by Kool Kojak, who also co-wrote the song with Savan Kotecha and Victoria Justice, for \"\" (2011), the soundtrack to the Nickelodeon television series, \"Victorious\". It was released as the album's third single on May 20, 2011 through Columbia Records in association with Nickelodeon. Musically, the song runs through an electropop oriented dance beat with teen pop lyrics, and the lyrics speak of a girl's crush on her best friend's brother. \n\n=== Document 2: Curmudgeons (film) ===\nCurmudgeons is a 2016 American comedy short film directed, produced by, and starring Danny DeVito. It is written and co-produced by Joshua Conkel. \n\n=== Document 3: Blow (Kesha song) ===\n\"Blow\" is a song by American singer and songwriter Kesha from her first extended play (EP), \"Cannibal\" (2010). The song was released on February 8, 2011. It was written by Kesha, along with Klas \u00c5hlund, Lukasz Gottwald, Allan Grigg, Benjamin Levin and Max Martin, with production done by Dr. Luke, Max Martin, Benny Blanco and Kool Kojak. According to Kesha the song's lyrics are representative of herself and her fans. \"Blow\" is dominantly an electropop and dance-pop song and is described as a party anthem as it portrays a simple message of having a desire to have a good time at a club. \n\n=== Document 4: Brian R. Etting ===\nBrian R. Etting is an American producer, director, and screenwriter known for producing \"Broken\", \"Funny or Die\", \"A Good Old Fashioned Orgy\", and Relative Strangers starring Danny DeVito. He also executive produced \"Drunk History: Douglass & Lincoln\" which won Best Short Film at the 2010 Sundance Film Festival. Etting also owns his own production company with Josh Etting called Garlin Pictures. \n\n=== Document 5: Va Va Voom ===\n\"Va Va Voom\" is a song by Trinidadian recording artist Nicki Minaj from the deluxe version of her second studio album, \"\". It was released on September 12, 2012 by Young Money, Cash Money, and Universal Republic as the fifth single from the album. The song was written by Minaj, Lukasz Gottwald, Allan Grigg, Max Martin, and Henry Walter, and it was produced by Dr. Luke, Kool Kojak, and Cirkut. Being released as the fifth single, it was sent to UK radio stations on September 15, 2012 and later sent to Top 40 mainstream radio on October 23, 2012. It was planned to serve as the lead single, but its release was postponed at the last minute in favor of \"Starships\"; it was later released as a promotion for the album's reissue \"\". \n\n=== Document 6: Kool Kojak ===\nAllan P. Grigg, better known by his stage name Kool Kojak and stylized as \"KoOoLkOjAk\", is an American musician, songwriter, record producer, film director, and artist notable for co-writing and co-producing Flo Rida's #1 Billboard hit single \"Right Round\", Nicki Minaj's hit single \"Va Va Voom\" , and Ke$ha's top 10 single \"Blow\". Kool Kojak has written and produced for artists such as Sean Paul, Yelle, Waka Flocka Flame, Travis Barker, Dr. Seuss's The Lorax, Britney Spears, Jesse and Joy, Andy Milonakis, Icona Pop, N.A.S.A., Dirt Nasty, Lordz of Brooklyn, Ursula 1000, and Warren G. Kool Kojak was a featured producer on the Simon Cowell TV program X Factor and has appeared as himself on the Nickelodeon show \"Victorious\". He has won two ASCAP Pop Awards and one ASCAP Urban Award, a WormTown Sound Award, and has been awarded the Key to the City of Worcester, Massachusetts. \n\n=== Document 7: The Lorax (film) ===\nThe Lorax (also known as Dr. Seuss' The Lorax) is a 2012 American 3D computer-animated musical fantasy\u2013comedy film produced by Illumination Entertainment and based on Dr. Seuss's children's book of the same name. The film was released by Universal Pictures on March 2, 2012, on the 108th birthday of Dr. Seuss. The second film adaptation of the book (following the 1972 animated television special), the film builds on the book by expanding the story of Ted, the previously unnamed boy who visits the Once-ler. The cast includes Danny DeVito as the Lorax, Ed Helms as the Once-ler, and Zac Efron as Ted. New characters introduced in the film are Audrey (voiced by Taylor Swift), Aloysius O'Hare (Rob Riggle), Mrs. Wiggins, Ted's mother (Jenny Slate), and Grammy Norma (Betty White). \n\n=== Document 8: Rock Me (One Direction song) ===\n\"Rock Me\" is a song by English-Irish boy band One Direction from their second studio album, \"Take Me Home\" (2012). It was written by Peter Svensson, Sam Hollander, Lukasz Gottwald, Henry Walter, Breanna Smith, and Allan Grigg, with production handled by Dr. Luke, Circut and Kool Kojak. Created in one day, Grigg carried out the mid-tempo beat, Hollander conceptualised the title and the pop rock melody \"just came\". Its clapping riff has been noted as similar to that of the Queen 1977 single \"We Will Rock You\". \n\n=== Document 9: Victorious: Music from the Hit TV Show ===\nVictorious: the debut soundtrack for the Nickelodeon TV series \"Victorious\". The majority of the album was sung by the lead actress of the television series, Victoria Justice, with the \"Victorious\" cast being listed beside her. Some of the other singers on the album feature Ariana Grande, Elizabeth Gillies, Miranda Cosgrove, Matt Bennett, Daniella Monet and Avan Jogia. The majority of the album was written by Michael Corcoran, Dan Schneider, Savan Kotecha, Kool Kojak and CJ Abraham with Victoria Justice involved in the composition of \"Best Friend's Brother\" and Leon Thomas III on \"Song 2 You\". \n\n=== Document 10: Give the Drummer Some ===\nGive the Drummer Some is the first solo record by Blink-182 drummer Travis Barker. Barker had earlier announced that the album would be slated for a September 2010 release, but was later pushed back, with the album being released on March 15, 2011. The album, released under Interscope Records, was produced by the drummer himself, alongside The Neptunes, RZA, Kool Kojak, Chuck Inglish, Transplants, Kid Cudi, EDIT, Corey Taylor and Steve Aoki. The album debuted at number nine on the US \"Billboard\" 200 chart, with first-week sales of 28,000 copies in the United States. \n\n\nProvide your answer based on the information in the supporting documents.",
    "answer": "The Lorax"
  },
  {
    "id": 1,
    "question": "Multi-hop reasoning task:\n\nQuestion: Out of the actors who have played the role of Luc Deveraux in the Universal Soldier franchise, which actor has also starred in the movies Holby City, Doctor Strange, the Bourne Ultimatum and Zero Dark Thirty?\n\nSupporting Documents:\n=== Document 1: Nick Jordan (character) ===\nNick Jordan is a fictional character from the BBC medical dramas \"Casualty\" and \"Holby City\", portrayed by actor Michael French. Jordan first appeared in two episodes of \"Casualty\" in 1998, before becoming a main character in spin-off show \"Holby City\" from its 1999 conception, in the role of Cardiothoracic Surgical Registrar. He departed from the show in its second series, returning for a 2005 Christmas crossover special between the two series, styled \"Casualty@Holby City\". He returned again to \"Holby City\" in 2006, taking on the role of General Surgical Consultant, departing a few months later in order to pursue a transfer back to cardiothoracics. In 2008, he rejoined the cast of \"Casualty\", becoming Clinical Lead of the show's Emergency Department. French left his role as Nick Jordan in February 2013, four weeks after his return. \n\n=== Document 2: Universal Soldier (franchise) ===\nThe Universal Soldier franchise is a series of science fiction action films. The franchise began in 1992 with \"Universal Soldier\" and as of 2012 comprises six entries (some of which are now considered non-canon). The films centered on the character of Luc Deveraux (played first by Jean-Claude Van Damme and then by Matt Battaglia) until \"\", which focuses on a new protagonist named John (played by Scott Adkins). \n\n=== Document 3: Adrian Fletcher (character) ===\nAdrian \"Fletch\" Fletcher is a fictional character from the BBC medical dramas \"Casualty\" and \"Holby City\", portrayed by actor Alex Walkinshaw. He first appeared in the twenty-sixth series episode \"Zero Sum Game\", broadcast on 7 July 2012. Fletch was a Staff Nurse in Holby City Hospital's emergency department upon his arrival, but was promoted to Senior Staff Nurse in 2013. On 1 April 2014, Walkinshaw announced his departure from \"Casualty\", but revealed that he would be reprising his role as the ward manager of the fictitious AAU ward in spin-off show \"Holby City\". Fletch departed \"Casualty\" on 29 June 2014 and made his debut on \"Holby City\" on 12 August 2014, over six weeks later. Walkinshaw reprised his role in \"Casualty\" for the 30th anniversary episode \"Too Old for This Shift\", which aired on 27 August 2016. \n\n=== Document 4: Universal Soldier (1992 film) ===\nUniversal Soldier is a 1992 American military science fiction action film directed by Roland Emmerich, produced by Mario Kassar and Allen Shapiro, and written by Richard Rothstein and Dean Devlin. The film tells the story of Luc Deveraux, a former US Army soldier who was killed in Vietnam War in 1969, and returned to life following a secret military project called the \"Universal Soldier\" program. However, he finds out about his past even although his memory was erased, and escapes alongside a young TV journalist. Along the way, they have to deal with the return of his archenemy, Sgt. Andrew Scott, who had lost his sanity in the Vietnam War, and became a psychotic megalomaniac, intent on killing him and leading the Universal Soldiers. \"Universal Soldier\" was released by TriStar Pictures on July 10, 1992. The film grossed $36 million worldwide against its budget of $23 million. It spawned a series of films, including several rather poorly received direct-to-TV films: \"\", which has since been removed from the series canon, followed by \"\" and \"\". \n\n=== Document 5: Universal Soldier: Regeneration ===\nUniversal Soldier: Regeneration (also known in some countries as Universal Soldier: A New Beginning) is a 2009 American sci-fi action film directed and edited by John Hyams (the son of director Peter Hyams, who previously worked with Jean-Claude Van Damme on three films, 1994's \"Timecop\", 1995's \"Sudden Death\" and 2013's \"Enemies Closer\"; in this film Peter is the director of photography). The film stars Jean-Claude Van Damme and Dolph Lundgren, who both reprise their roles from the first film. It is the third theatrical installment in the \"Universal Soldier series\". The film is a direct sequel to the original \"Universal Soldier\" from 1992, unrelated to the two \"Universal Soldier\" television sequels that were produced in 1998 and completely ignores the events from the 1999 theatrical sequel \"\". \n\n=== Document 6: Luc Deveraux ===\nLuc Deveraux is a fictional character and the protagonist of the \"Universal Soldier\" film series. He is most famously portrayed by Belgian actor and martial artist Jean-Claude Van Damme. Van Damme portrays Luc in the 1992 film \"Universal Soldier\" and its sequels \"\" (1999), \"\" (2009), and \"\" (2012); he is portrayed by Matt Battaglia in the direct-to-video sequels \"\" (1998) and \"\" (1998). \n\n=== Document 7: Jayne Grayson ===\nJayne Grayson is a fictional character in the BBC medical drama \"Holby City\", portrayed by actress Stella Gonet. The character first appeared on-screen on 10 July 2007 in episode \"Under the Radar\" - series 9, episode 39 of the programme. Her role in the show was that of Chief Executive Officer of the Holby City Hospital Primary Care Trust, making her the only regular character who is not a medic by profession. Gonet formerly appeared as a doctor in \"Holby City\"<nowiki>'</nowiki>s sister show \"Casualty\", and has since appeared in crossover episodes of the drama, this time as Jayne Grayson. Her storylines in \"Holby City\" have revolved around issues of hospital bureaucracy, as well as her husband's affair with her colleague Connie Beauchamp. A two-part episode which saw Jayne fight the hospital's Board of Directors and the British government over the separation surgery of the conjoined twin daughters of illegal Korean immigrants proved a critical success, and was positively received by many tabloid TV critics. \n\n=== Document 8: List of accolades received by Zero Dark Thirty ===\n\"Zero Dark Thirty\" is a 2012 American action thriller directed and co-produced by Kathryn Bigelow with screenplay by Mark Boal. The film was released in the United States on December 19, 2012, with a limited release at five theaters in Los Angeles and New York City. It made $124,848 in its limited release weekend, making it one of the biggest limited mid-week openings ever. As of March 6, 2013, \"Zero Dark Thirty\" has grossed a worldwide total of $106.8 million. \"Zero Dark Thirty\" also received a high critical acclaim, accumulating an approval rating of 93% on the review aggregator site Rotten Tomatoes. \n\n=== Document 9: Scott Adkins ===\nScott Edward Adkins (born 17 June 1976) is an English actor and martial artist who is best known for playing Russian prison fighter Yuri Boyka in the 2006 film \"\" and its following two sequels: \"\" (2010) and \"\" (2016) and Casey Bowman in Ninja and its sequel . He is also known for playing Bradley Hume in \"Holby City\", Lucian in \"Doctor Strange\", Kiley in \"The Bourne Ultimatum\" and John in \"Zero Dark Thirty\". Adkins has also appeared in \"EastEnders\", \"Hollyoaks\", \"Doctors\" as well as starred in many direct-to-video films. \n\n=== Document 10: Connie Beauchamp ===\nConstance \"Connie\" Beauchamp is a fictional character from the BBC medical dramas \"Holby City\" and \"Casualty\", portrayed by actress Amanda Mealing. She first appeared in the series six, episode 35, \"In at the Deep End\", broadcast on 1 June 2004, and appeared in \"Holby City's\" sister show \"Casualty\" multiple times, having already appeared in crossover \"Casualty@Holby City\" episodes. Mealing continued her role as Connie until the thirteenth series of \"Holby City\", departing in the 28 December 2010 episode \"Snow Queens\". Connie's role in \"Holby City\" was that of Clinical Lead of Cardiothoracic Surgery in Darwin, and Joint Director of Surgery. \n\n\nProvide your answer based on the information in the supporting documents.",
    "answer": "Scott Adkins"
  },
  {
    "id": 2,
    "question": "Multi-hop reasoning task:\n\nQuestion: Tommy's Honour was a drama film that included the actor who found success with what 2016 BBC miniseries?\n\nSupporting Documents:\n=== Document 1: Tommy's Honour ===\nTommy's Honour is a 2016 historical drama film depicting the lives and careers of, and the complex relationship between, the pioneering Scottish golfing champions Old Tom Morris and his son Young Tom Morris. The film is directed by Jason Connery, and the father and son are portrayed by Peter Mullan and Jack Lowden. The film won Best Feature Film at the 2016 British Academy Scotland Awards. \n\n=== Document 2: H\u00e9l\u00e8ne Kuragina ===\nPrincess Yelena \"H\u00e9l\u00e8ne\" Vasilyevna Kuragina (Russian: \u0415\u043b\u0435\u043d\u0430 \"\u042d\u043b\u0435\u0301\u043d\" \u0412\u0430\u0441\u0438\u0301\u043b\u044c\u0435\u0432\u043d\u0430 \u041a\u0443\u0440\u0430\u0301\u0433\u0438\u043d\u0430 ) is a fictional character in Leo Tolstoy's novel \"War and Peace\" and its various cinematic adaptations. She is played by Anita Ekberg in the 1956 film, by Amber Gray in \"Natasha, Pierre & The Great Comet of 1812\", and by Tuppence Middleton in the 2016 BBC miniseries. \n\n=== Document 3: Kevin McKidd ===\nKevin McKidd (born 9 August 1973) is a Scottish-American television and film actor, director, and occasional singer. Before playing the role of Owen Hunt in \"Grey's Anatomy\", for which he is perhaps most widely known, McKidd starred as Dan Vasser in the NBC Series \"Journeyman\" (2007), Tommy in Danny Boyle's \"Trainspotting\" (1996), Count Vronsky in the BBC miniseries \"Anna Karenina\" (2000), and Lucius Vorenus in the historical drama series \"Rome\" (2005\u20132007). He also provides the voice of John \"Soap\" MacTavish in the video games \"\" and \"\". He also played Poseidon in the film \"\". \n\n=== Document 4: Ken Stott ===\nKenneth Campbell \"Ken\" Stott (born 19 October 1954) is a Scottish stage, television and film actor who won the Laurence Olivier Award for Best Actor in a Supporting Role in 1995 in the play \"Broken Glass\" at Royal National Theatre. He is more recently known for his role as the dwarf Balin in \"The Hobbit\" film trilogy (2012\u20132014), and as Ian Garrett in the 2014 BBC TV mini-series \"The Missing\" starring alongside James Nesbitt. His many notable roles in UK television include the role of Edward 'Eddie' McKenna in the Scottish BBC miniseries \"Takin' Over The Asylum\" (1994) co-starring with a young David Tennant, the title character DI John Rebus in the crime fiction-mystery series \"Rebus\" (2000\u20132007) and also as DCI Red Metcalfe in \"Messiah\" (2001\u20132008). \n\n=== Document 5: Elisabeth Moss ===\nElisabeth Singleton Moss (born July 24, 1982) is an American film, stage, and television actor. She is known for her roles as Zoey Bartlet, the youngest daughter of President Josiah Bartlet, on the NBC television series \"The West Wing\" (1999\u20132006); Peggy Olson, secretary-turned-copywriter, on the AMC series \"Mad Men\" (2007\u20132015), which earned her six Emmy Awards nominations and a Golden Globe nomination; Det. Robin Griffin in the BBC miniseries \"Top of the Lake\" (2013, 2017), which won her a Golden Globe for Best Actress in a Miniseries or TV Film; and Offred on the Hulu series \"The Handmaid's Tale\", for which she won the Primetime Emmy Award for Outstanding Lead Actress in a Drama Series and the Primetime Emmy Award for Outstanding Drama Series, as producer. \n\n=== Document 6: Tina Heath ===\nTina Heath is a British actress and former television presenter. Her first TV appearance came in 1969, when she appeared in \"Broaden Your Mind\" on BBC Two alongside Graeme Garden and Tim Brooke-Taylor. A one-off appearance in \"Z-Cars\" followed in 1970. In 1973, she played the title role in the popular children's television serial \"Lizzie Dripping\" after first playing the character in an episode of \"Jackanory Playhouse\" in 1972; her character was supposed to be 12 years old, but in fact Heath was already 20 at the time. She also played, in that same year's BBC miniseries production of \"Jane Eyre\" (1973), the character of Helen Burns, the fourteen-year-old boarding-school girl who is cruelly birched by Miss Scatcherd and who befriends the ten-year-old Jane when Jane is a newcomer to Lowood Institute. Other TV appearances included a role in the BBC's \"Play Of The Month: The Linden Tree\" by J.B. Priestley in 1974; \"Churchill's People\" in 1975; Muriel Spark's \"The Girls Of Slender Means\"; and The Sweeney in 1976. \n\n=== Document 7: Jack Lowden ===\nJack Andrew Lowden (born 2 June 1990) is a Scottish stage, television, and film actor. Following a highly successful and award-winning four-year stage career, his first major international onscreen success was in the 2016 BBC miniseries \"War & Peace\", which led to starring roles in feature films. \n\n=== Document 8: Kate Buffery ===\nKatharine Winifred Buffery (born 23 July 1957) is an English actress. She is known for her numerous roles on British television, including the ITV drama series \"Wish Me Luck\" (1988-1990), BBC miniseries \"Close Relations\" (1998), Channel 5 legal drama \"Wing and a Prayer\" (1997-1999) and the ITV police drama \"Trial and Retribution\" (1997-2002). Her stage work includes the 1983 original West End production of \"Daisy Pulls it Off\", which earned her an Olivier Award nomination. \n\n=== Document 9: Cultural depictions of William III of England ===\nWilliam III of England has been played on screen by Bernard Lee in the 1937 film \"The Black Tulip\", based on the novel by Alexandre Dumas, p\u00e8re, Henry Daniell in the 1945 film \"Captain Kidd\", Olaf Hytten in the 1952 film \"Against All Flags\", Alan Rowe in the 1969 BBC drama series \"The First Churchills\", Laurence Olivier in the 1986 NBC TV mini-series \"Peter the Great\", Thom Hoffman in the 1992 film \"Orlando\", based on the novel by Virginia Woolf, Corin Redgrave in the 1995 film \"England, My England\", the story of the composer Henry Purcell, Jochum ten Haaf in the 2003 BBC miniseries \"\", Bernard Hill in the 2005 film \"The League of Gentlemen's Apocalypse\", Russell Pate in the 2008 BBC film \"King Billy Above All\", Egbert-Jan Weber in the 2015 film \"Michiel de Ruyter\", George Webster in \"Versailles\" (2015) and Carl Prekopp in the 2015 premiere of the play \"Queen Anne\". \n\n=== Document 10: The Day of the Triffids (2009 TV miniseries) ===\nThe Day of the Triffids is a BBC miniseries adaptation of John Wyndham's novel of the same name. The novel had previously been adapted in 1962 as a theatrical film and by the BBC in a 1981 series. \n\n\nProvide your answer based on the information in the supporting documents.",
    "answer": "War & Peace"
  }
]

            HISTORICAL CONTEXT:
            
        ITERATION HISTORY SUMMARY:
        - Total iterations completed: 1
        - Current explore/exploit balance: 60/20
        - Best accuracy achieved: 0.80 (iteration 0)

        APPROACH HISTORY (last 1 iterations):
        [
  {
    "iteration": 0,
    "strategy": "baseline",
    "accuracy": 0.8,
    "approach": "Simple baseline script: Direct LLM call without sophisticated techniques"
  }
]

        COMMON ERROR PATTERNS:
        []

        PRIMARY ISSUES (last 1 iterations):
        [
  {
    "iteration": 0,
    "issue": "The primary issue is the system's **inability to synthesize extracted information to provide precise and concise answers** that directly address the core question, even when relevant information is present in the documents."
  }
]

        TARGETED IMPROVEMENTS:
        []
        

EXAMPLE OF EFFECTIVE LLM USAGE PATTERNS:

```python
def extract_information_with_examples(text):
    """Extract key information from the input text using embedded examples."""
    system_instruction = "You are an information extraction specialist focusing on identifying key entities and relationships."
    
    prompt = f"""
    Extract key information from this text. Focus on identifying all entities, relationships, and important attributes.
    
    Example usage:
    
    Input Text:
    The company XYZ Corp reported quarterly earnings of $3.5 million, which represents a 12% increase from last year. The CEO, Jane Smith, attributed this growth to their new product line launched in March, which has already captured 8% of the market share. They expect to expand their operations to Europe by Q2 2023.
    
    Let's think step by step.
    
    The key entities are:
    - XYZ Corp (company)
    - Jane Smith (person, CEO)
    - New product line (product)
    
    The key information points are:
    - Financial: Quarterly earnings of $3.5 million
    - Performance: 12% increase from previous year
    - Product: New product line launched in March
    - Market: 8% market share for new product
    - Plans: Expansion to Europe by Q2 2023
    
    Extracted Information:
    {{
      "entities": [
        {{"name": "XYZ Corp", "type": "company"}},
        {{"name": "Jane Smith", "type": "person", "role": "CEO"}},
        {{"name": "New product line", "type": "product", "launch_date": "March"}}
      ],
      "financial_data": {{
        "quarterly_earnings": "$3.5 million",
        "growth_rate": "12%"
      }},
      "market_data": {{
        "product_market_share": "8%"
      }},
      "future_plans": [
        {{"type": "expansion", "region": "Europe", "timeline": "Q2 2023"}}
      ]
    }}
    
    Now, extract information from this new text:
    {text}
    """
    
    return call_llm(prompt, system_instruction)
```

```python
def verify_solution_with_examples(problem, proposed_solution):
    """Verify if the proposed solution satisfies all requirements using embedded examples."""
    system_instruction = "You are a critical evaluator who verifies if solutions correctly address problems."
    
    prompt = f"""
    Verify if this proposed solution correctly addresses all aspects of the problem.
    
    Example usage:
    
    Problem:
    Design a data structure that can efficiently perform the following operations:
    1. Insert a value
    2. Delete a value
    3. Get a random value with equal probability for all stored values
    All operations should have average time complexity of O(1).
    
    Proposed Solution:
    I'll use a combination of a hashmap and an array. The hashmap will store the value as the key and its index in the array as the value. The array will store all the inserted values.
    
    For insert: Add the value to the end of the array and update the hashmap with the value and its index. O(1) time.
    
    For delete: Look up the index of the value in the hashmap, swap the value with the last element in the array, update the hashmap for the swapped element, remove the last element from the array, and remove the value from the hashmap. O(1) time.
    
    For get random: Generate a random index within the array's bounds and return the value at that index. O(1) time.
    
    Verification:
    Let me check each requirement:
    1. Insert operation: The solution adds the value to the end of the array and updates the hashmap with O(1) time complexity ✓
    2. Delete operation: The solution uses the hashmap to find the index, then swaps with the last element and updates accordingly with O(1) time complexity ✓
    3. Get random operation: The solution generates a random index within the array bounds with O(1) time complexity ✓
    4. All operations have O(1) average time complexity ✓
    
    Result: VALID - The solution correctly addresses all requirements with the specified time complexity.
    
    Problem:
    {problem}
    
    Proposed Solution:
    {proposed_solution}
    
    Verification:
    """
    
    return call_llm(prompt, system_instruction)
```

```python
def solve_with_validation_loop(problem, max_attempts=3):
    """Solve a problem with iterative refinement through validation feedback loop."""
    system_instruction_solver = "You are an expert problem solver who creates detailed, correct solutions."
    system_instruction_validator = "You are a critical validator who carefully checks solutions against all requirements."
    
    # Initial solution generation
    solution_prompt = f"""
    Provide a detailed solution to this problem. Be thorough and ensure you address all requirements.
    
    Problem:
    {problem}
    """
    
    solution = call_llm(solution_prompt, system_instruction_solver)
    
    # Validation loop
    for attempt in range(max_attempts):
        # Validate the current solution
        validation_prompt = f"""
        Carefully validate if this solution correctly addresses all aspects of the problem.
        If the solution is valid, respond with "VALID: [brief reason]".
        If the solution has any issues, respond with "INVALID: [detailed explanation of issues]".
        
        Problem:
        {problem}
        
        Proposed Solution:
        {solution}
        """
        
        validation_result = call_llm(validation_prompt, system_instruction_validator)
        
        # Check if solution is valid
        if validation_result.startswith("VALID:"):
            return solution
        
        # If invalid, refine the solution
        refined_prompt = f"""
        Your previous solution to this problem has some issues that need to be addressed.
        
        Problem:
        {problem}
        
        Your previous solution:
        {solution}
        
        Validation feedback:
        {validation_result}
        
        Please provide a completely revised solution that addresses all the issues mentioned.
        """
        
        solution = call_llm(refined_prompt, system_instruction_solver)
    
    return solution
```

```python
def multi_perspective_analysis(problem):
    """Analyze a problem from multiple specialized perspectives and synthesize the insights."""
    # Define specialized analysis functions
    def analyze_factual_content(problem):
        system_instruction = "You are a factual analyst who focuses on identifying key facts and data points."
        prompt = f"""
        Analyze this problem for factual content only. Identify explicit facts, constraints, and requirements.
        
        Problem:
        {problem}
        """
        return call_llm(prompt, system_instruction)
    
    def analyze_structure(problem):
        system_instruction = "You are a structural analyst who specializes in problem organization and patterns."
        prompt = f"""
        Analyze the structure of this problem. Identify its components, relationships, and patterns.
        
        Problem:
        {problem}
        """
        return call_llm(prompt, system_instruction)
    
    # Execute parallel analyses
    factual_analysis = analyze_factual_content(problem)
    structural_analysis = analyze_structure(problem)
    
    # Synthesize the results
    synthesis_prompt = f"""
    Synthesize these two different analyses of the same problem into a comprehensive understanding.
    
    Factual Analysis:
    {factual_analysis}
    
    Structural Analysis:
    {structural_analysis}
    
    Provide a unified analysis that leverages both perspectives.
    """
    
    return call_llm(synthesis_prompt, "You are an insight synthesizer who combines multiple analyses.")
```

```python
def best_of_n_approach(problem, n=3):
    """Generate multiple solutions and select the best one based on a quality evaluation."""
    system_instruction_solver = "You are an expert problem solver who provides detailed, correct solutions."
    system_instruction_evaluator = "You are a quality evaluator who assesses solutions based on correctness, completeness, and clarity."
    
    # Generate n different solutions
    solutions = []
    for i in range(n):
        diversity_factor = f"Solution approach {i+1}/{n}: Use a different perspective from previous solutions."
        solution_prompt = f"""
        Provide a detailed solution to this problem.
        {diversity_factor if i > 0 else ""}
        
        Problem:
        {problem}
        """
        
        solutions.append(call_llm(solution_prompt, system_instruction_solver))
    
    # Evaluate each solution
    evaluations = []
    for i, solution in enumerate(solutions):
        evaluation_prompt = f"""
        Evaluate this solution on correctness, completeness, and clarity (1-10 scale).
        
        Problem:
        {problem}
        
        Solution {i+1}:
        {solution}
        
        Provide your evaluation as a JSON with scores and explanation.
        """
        
        evaluations.append(call_llm(evaluation_prompt, system_instruction_evaluator))
    
    # Find the best solution
    comparison_prompt = f"""
    Compare these solutions and their evaluations. Select the best one.
    
    Problem:
    {problem}
    
    {["Solution " + str(i+1) + ": " + solutions[i] + "\n\nEvaluation: " + evaluations[i] for i in range(n)]}
    
    Which solution is best? Respond with the solution number and explanation.
    """
    
    best_solution_index = int(call_llm(comparison_prompt, "You are a solution selector.").split()[1]) - 1
    return solutions[best_solution_index]
```

```python
def solve_with_react_pattern(problem):
    """Solve problems through iterative Reasoning and Acting (ReAct) approach."""
    system_instruction = "You are a problem-solving agent that follows the ReAct pattern: Reason about the current state, take an Action, observe the result, and repeat until reaching a solution."
    
    # Initialize ReAct process
    prompt = f"""
    Solve this problem using the ReAct pattern - alternate between Reasoning and Acting until you reach a final answer.
    
    Example usage:
    
    Problem: What is the capital of the country where the Great Barrier Reef is located, and what is the population of that capital?
    
    Thought 1: I need to determine which country the Great Barrier Reef is in, then find its capital, and finally the population of that capital.
    Action 1: Search[Great Barrier Reef location]
    Observation 1: The Great Barrier Reef is located off the coast of Queensland in northeastern Australia.
    
    Thought 2: Now I know the Great Barrier Reef is in Australia. I need to find Australia's capital city.
    Action 2: Search[capital of Australia]
    Observation 2: The capital of Australia is Canberra.
    
    Thought 3: Now I need to find the population of Canberra.
    Action 3: Search[population of Canberra]
    Observation 3: As of 2021, the population of Canberra is approximately 431,500.
    
    Thought 4: I have found all the required information. The capital of Australia (where the Great Barrier Reef is located) is Canberra, and its population is approximately 431,500.
    Action 4: Finish[The capital of Australia is Canberra, with a population of approximately 431,500.]
    
    Now solve this new problem:
    {problem}
    
    Start with Thought 1:
    """
    
    # Initial reasoning and action planning
    react_response = call_llm(prompt, system_instruction)
    
    # Extract the action from the response
    action = extract_action(react_response)
    
    # Continue the ReAct loop until we reach a "Finish" action
    while not action["type"] == "Finish":
        # Perform the requested action and get an observation
        if action["type"] == "Search":
            observation = perform_search(action["query"])
        elif action["type"] == "Calculate":
            observation = perform_calculation(action["expression"])
        elif action["type"] == "Lookup":
            observation = perform_lookup(action["term"])
        else:
            observation = f"Unknown action type: {action['type']}"
        
        # Continue the ReAct process with the new observation
        continuation_prompt = f"""
        {react_response}
        Observation {action["step_number"]}: {observation}
        
        Continue with the next thought and action:
        """
        
        # Get the next reasoning step and action
        react_response += "\n" + call_llm(continuation_prompt, system_instruction)
        
        # Extract the next action
        action = extract_action(react_response)
    
    # Extract the final answer from the Finish action
    final_answer = action["answer"]
    return final_answer

def extract_action(text):
    """Parse the ReAct response to extract the current action."""
    # Find the last action in the text
    action_matches = re.findall(r"Action (\d+): (\w+)\[(.*?)\]", text)
    if not action_matches:
        return {"type": "Error", "step_number": 0, "query": "No action found"}
    
    # Get the most recent action
    last_action = action_matches[-1]
    step_number = int(last_action[0])
    action_type = last_action[1]
    action_content = last_action[2]
    
    # Handle different action types
    if action_type == "Finish":
        return {"type": "Finish", "step_number": step_number, "answer": action_content}
    elif action_type in ["Search", "Lookup", "Calculate"]:
        return {"type": action_type, "step_number": step_number, "query": action_content}
    else:
        return {"type": "Unknown", "step_number": step_number, "query": action_content}

def perform_search(query):
    """Simulate a search action in the ReAct pattern."""
    # In a real implementation, this would call an actual search API
    return call_llm(f"Provide a factual answer about: {query}", "You are a helpful search engine that provides concise, factual information.")

def perform_calculation(expression):
    """Perform a calculation action in the ReAct pattern."""
    try:
        # Safely evaluate the expression
        result = eval(expression, {"__builtins__": {}}, {"math": math})
        return f"The result is {result}"
    except Exception as e:
        return f"Error in calculation: {str(e)}"

def perform_lookup(term):
    """Simulate a lookup action for specific information."""
    # In a real implementation, this would query a knowledge base or database
    return call_llm(f"Provide specific information about: {term}", "You are a knowledge base that provides specific factual information.")
```\n\n```python\ndef solve_with_meta_programming(question):
            """
            Advanced: Script generates and executes its own code/prompts dynamically.
            The script acts as its own programmer and prompt engineer.
            """

            # Step 1: Analyze what approach is needed
            strategy_prompt = f"""
            For this problem: {question}

            What's the best approach?
            A) Generate Python code to calculate/process something
            B) Generate specialized LLM prompts for analysis  
            C) Use a hybrid approach with both code and LLM calls

            Explain your choice and what specific code or prompts I should generate.
            """


                analysis_system_prompt = """ 
                You are a problem analysis expert. You are a master of problem analysis and can 
                determine the best approach to solve a problem, understanding the strenghts and 
                weaknesses of LLMs for problem solving, when to delegate a more specific or problem 
                or subproblem to an additional LLM call, and when to write code to solve a problem.
            """
            strategy = call_llm(strategy_prompt, analysis_system_prompt)

            # Step 2: Generate and execute based on strategy
            if "###CODE_ONLY###" in strategy.lower():
                # Generate code dynamically
                code_gen_prompt = f"""
                Problem: {question}
                Strategy: {strategy}

                Write Python code to solve this problem. Include print statements for output.
                Return ONLY the Python code:
                """

                generated_code = call_llm(code_gen_prompt, "You are a Python programmer.")

                # Clean up code if wrapped in markdown
                import re
                code_match = re.search(r'```python\s*\n(.*?)\n```', generated_code, re.DOTALL)
                if code_match:
                    clean_code = code_match.group(1).strip()
                else:
                    clean_code = generated_code.strip()

                # Execute the generated code
                execution_result = execute_code(clean_code)

                # Interpret the execution result
                interpretation_prompt = f"""
                Original problem: {question}
                Generated code: {clean_code}
                Execution result: {execution_result}

                What is the final answer based on these results?
                """

                final_answer = call_llm(interpretation_prompt, "You are a solution interpreter.")
                return final_answer

            elif "###PROMPT_ONLY###" in strategy.lower():
                # Generate specialized prompts dynamically
                prompt_design = f"""
                For this problem: {question}
                Strategy: {strategy}

                Design the most effective prompt to solve this problem:
                """

                specialized_prompt = call_llm(prompt_design, "You are a prompt engineer.")

                # Use the generated prompt
                solution = call_llm(specialized_prompt, "You are an expert problem solver.")
                return solution

            else:  # Hybrid approach
                # Chain code and LLM calls dynamically
                current_result = question

                for step in range(3):
                    # Decide what to do at this step
                    step_decision = call_llm(f"""
                    Step {step + 1} of hybrid approach.
                    Current state: {current_result}

                    What should I do next?
                    - Generate and execute code
                    - Make an LLM analysis call
                    - Provide final answer

                    Choose one and explain exactly what to do.
                    """, "You are a workflow coordinator.")

                    if "final answer" in step_decision.lower():
                        return current_result
                    elif "code" in step_decision.lower():
                        # Generate code for this step
                        step_code_prompt = f"""
                        Based on this decision: {step_decision}
                        Current data: {current_result}

                        Write Python code to process this. Return only the code:
                        """
                        step_code = call_llm(step_code_prompt, "You are a Python programmer.")
                        code_result = execute_code(step_code)
                        current_result = f"Previous: {current_result}\nCode result: {code_result}"
                    else:
                        # Make LLM call for this step  
                        step_analysis = call_llm(f"Analyze this data: {current_result}\nBased on: {step_decision}", "You are an analyst.")
                        current_result = f"Previous: {current_result}\nAnalysis: {step_analysis}"

                return current_result\n```\n\n```python\ndef self_modifying_solver(problem):
            """
            A solver that rewrites its own approach based on intermediate results.
            Advanced meta-programming where the script evolves its strategy.
            """

            strategy = "direct_analysis"
            attempts = 0
            max_attempts = 3

            while attempts < max_attempts:
                attempts += 1

                if strategy == "direct_analysis":
                    # Try direct LLM analysis
                    result = call_llm(f"Solve this problem: {problem}", "You are an expert problem solver.")

                    # Evaluate if this worked
                    evaluation_prompt = f"""
                    Problem: {problem}
                    My attempt: {result}

                    Did this solve the problem correctly? If not, what approach should I try next?
                    Options: computational_approach, step_by_step_breakdown, code_generation
                    """

                    evaluation = call_llm(evaluation_prompt, "You are a solution evaluator.")

                    if "correct" in evaluation.lower() or "solved" in evaluation.lower():
                        return result
                    elif "computational" in evaluation.lower():
                        strategy = "computational_approach"
                    elif "step_by_step" in evaluation.lower():
                        strategy = "step_by_step_breakdown"  
                    else:
                        strategy = "code_generation"

                elif strategy == "computational_approach":
                    # Generate and execute computational code
                    comp_prompt = f"""
                    Problem: {problem}

                    Write Python code to solve this computationally. Include:
                    - Extract relevant numbers or data
                    - Perform calculations
                    - Print results clearly

                    Return only the Python code:
                    """

                    comp_code = call_llm(comp_prompt, "You are a computational programmer.")
                    comp_result = execute_code(comp_code)

                    # Interpret computational result
                    interpretation = call_llm(f"Problem: {problem}\nComputation result: {comp_result}\nFinal answer:", "You are an interpreter.")
                    return interpretation

                elif strategy == "step_by_step_breakdown":
                    # Generate step-by-step solution code
                    breakdown_prompt = f"""
                    Problem: {problem}

                    Write Python code that breaks this problem into steps and solves it methodically:
                    """

                    breakdown_code = call_llm(breakdown_prompt, "You are a systematic programmer.")
                    breakdown_result = execute_code(breakdown_code)

                    # Build final solution based on breakdown
                    final_solution = call_llm(f"Problem: {problem}\nStep-by-step result: {breakdown_result}\nFinal answer:", "You are a problem solver.")
                    return final_solution

                else:  # code_generation strategy
                    # Generate completely custom code for this problem
                    custom_prompt = f"""
                    Problem: {problem}

                    Write custom Python code specifically designed to solve this exact problem type:
                    """

                    custom_code = call_llm(custom_prompt, "You are a custom code generator.")
                    custom_result = execute_code(custom_code)

                    return f"Custom solution result: {custom_result}"

            return "Could not solve after multiple strategy attempts"\n```\n\n```python\ndef adaptive_chain_solver(question):
            """
            Chains multiple code generations and LLM calls adaptively.
            Each step decides what the next step should be.
            """

            current_data = question
            step_count = 0
            max_steps = 5

            while step_count < max_steps:
                step_count += 1

                # Decide what to do at this step
                decision_prompt = f"""
                Step {step_count}: Working with: {current_data}

                What should I do next to solve this problem?
                A) Generate and execute Python code to process/calculate something
                B) Generate a specialized LLM prompt for analysis
                C) I have enough information - provide final answer

                Choose A, B, or C and explain exactly what to do:
                """

                decision = call_llm(decision_prompt, "You are an adaptive workflow coordinator.")

                if "C)" in decision or "final answer" in decision.lower():
                    # Generate final answer
                    final_prompt = f"""
                    Original question: {question}
                    Current data/results: {current_data}

                    Based on all the processing done, what is the final answer?
                    """
                    return call_llm(final_prompt, "You are a solution synthesizer.")

                elif "A)" in decision or "code" in decision.lower():
                    # Generate and execute code
                    code_prompt = f"""
                    Current data: {current_data}
                    Decision: {decision}

                    Write Python code to process this data as suggested. Return only the code:
                    """

                    code = call_llm(code_prompt, "You are a Python programmer.")

                    # Execute and update current data
                    code_result = execute_code(code)
                    current_data = f"Step {step_count} result: {code_result}"

                else:  # Generate specialized LLM prompt
                    # Create specialized prompt
                    prompt_design = f"""
                    Current data: {current_data}
                    Decision: {decision}

                    Design a specialized prompt for this analysis:
                    """

                    specialized_prompt = call_llm(prompt_design, "You are a prompt engineer.")

                    # Use the specialized prompt
                    analysis_result = call_llm(specialized_prompt, "You are a specialized analyst.")
                    current_data = f"Step {step_count} analysis: {analysis_result}"

            return f"Final result after {max_steps} steps: {current_data}"\n```MULTI-EXAMPLE PROMPTING GUIDANCE:
        1. CRITICAL: Use MULTIPLE examples (2-5) in EVERY LLM prompt, not just one
        2. Vary the number of examples based on task complexity - more complex tasks need more examples
        3. Select diverse examples that showcase different patterns and edge cases
        4. Structure your few-shot examples to demonstrate clear step-by-step reasoning
        5. Consider using both "easy" and "challenging" examples to help the LLM learn from contrasts
        6. The collection of examples should collectively cover all key aspects of the problem
        7. When available, use examples from previous iterations that revealed specific strengths or weaknesses.
        8. USE REAL EXAMPLES FROM THE DATASET WHERE POSSIBLE!!

        Example of poor single-example prompting:
        ```python
        def extract_entities(text):
            prompt = f'''
            Extract entities from this text.

            Example:
            Text: John will meet Mary at 3pm on Tuesday.
            Entities: {{"people": ["John", "Mary"], "time": "3pm", "day": "Tuesday"}}

            Text: {text}
            Entities:
            '''
            return call_llm(prompt)
        ```

        Example of effective multi-example prompting:
        ```python
        def extract_entities(text):
            prompt = f'''
            Extract entities from this text.

            Example 1:
            Text: John will meet Mary at 3pm on Tuesday.
            Entities: {{"people": ["John", "Mary"], "time": "3pm", "day": "Tuesday"}}

            Example 2:
            Text: The team needs to submit the report by Friday at noon.
            Entities: {{"people": ["the team"], "time": "noon", "day": "Friday", "object": "report"}}

            Example 3:
            Text: Alex cannot attend the conference from Jan 3-5 due to prior commitments.
            Entities: {{"people": ["Alex"], "event": "conference", "date_range": ["Jan 3-5"], "reason": "prior commitments"}}

            Text: {text}
            Entities:
            '''
            return call_llm(prompt)
        ```

        === DIRECT LLM REASONING APPROACH ===

        CRITICAL: Previous scripts have shown that complex code generation with JSON parsing and multi-step pipelines often 
        leads to errors and low performance. Instead, focus on leveraging the LLM's natural reasoning abilities:

        1. SIMPLIFY YOUR APPROACH:
           - Minimize the number of processing steps - simpler is better
           - Directly use LLM for pattern recognition rather than writing complex code
           - Avoid trying to parse or manipulate JSON manually - pass it as text to the LLM

        2. DIRECT TRANSFORMATION:
           - Instead of trying to extract features and then apply them, use the LLM to do the transformation directly
           - Use examples to teach the LLM the pattern, then have it apply that pattern to new inputs
           - Avoid attempting to write complex algorithmic solutions when pattern recognition will work better

        3. ROBUST ERROR HANDLING:
           - Include multiple approaches in case one fails (direct approach + fallback approach)
           - Use simple validation to check if outputs are in the expected format
           - Include a last-resort approach that will always return something valid

        4. AVOID COMMON PITFALLS:
           - Do NOT attempt to use json.loads() or complex JSON parsing - it often fails
           - Do NOT create overly complex Python pipelines that require perfect indentation
           - Do NOT create functions that generate or execute dynamic code
           - Do NOT create unnecessarily complex data transformations

        5. SUCCESSFUL EXAMPLES:
           - The most successful approaches have used direct pattern matching with multiple examples
           - Scripts with simple validation and fallback approaches perform better
           - Scripts with fewer processing steps have higher success rates
        
        IMPLEMENTATION STRATEGIES:
        1. Maintain a "example bank" of successful and failed examples to select from
        2. Implement n-shot prompting with n=3 as default, but adapt based on performance
        3. For complex tasks, use up to 5 examples; for simpler tasks, 2-3 may be sufficient
        4. Include examples with a range of complexity levels, rather than all similar examples



        VALIDATION AND VERIFICATION GUIDANCE:
        1. CRITICAL: Consider implementing validation loops for EACH key processing step, not just final outputs
        2. Design your system to detect, diagnose, and recover from specific errors. This will help future learnings
        3. For every LLM extraction or generation, add a verification step that checks:
           - Whether the output is well-formed and complete
           - Whether the output is logically consistent with the input
           - Whether all constraints are satisfied
        4. Add feedback loops that retry failures with specific feedback
        5. Include diagnostic outputs that reveal exactly where failures occur. Add print statements and intermediate outputs such that you can see them later to determine why things are going wrong.
        6. Include capability to trace through execution steps to identify failure points

        Example of pipeline without verification:
        ```python
        def process_question(question):
            entities = extract_entities(question)
            constraints = identify_constraints(question)
            solution = generate_solution(entities, constraints)
            return solution
        ```

        Example of robust pipeline with verification:
        ```python
        def process_question(question, max_attempts=3):
            # Step 1: Extract entities with verification
            entities_result = extract_entities_with_verification(question)
            if not entities_result.get("is_valid"):
                print(f"Entity extraction failed: {entities_result.get('validation_feedback')}")
                return f"Error in entity extraction: {entities_result.get('validation_feedback')}"

            # Step 2: Identify constraints with verification
            constraints_result = identify_constraints_with_verification(question, entities_result["entities"])
            if not constraints_result.get("is_valid"):
                print(f"Constraint identification failed: {constraints_result.get('validation_feedback')}")
                return f"Error in constraint identification: {constraints_result.get('validation_feedback')}"

            # Step 3: Generate solution with verification
            solution_result = generate_solution_with_verification(
                question, 
                entities_result["entities"], 
                constraints_result["constraints"]
            )
            if not solution_result.get("is_valid"):
                print(f"Solution generation failed: {solution_result.get('validation_feedback')}")
                return f"Error in solution generation: {solution_result.get('validation_feedback')}"

            return solution_result["solution"]

        def extract_entities_with_verification(question, max_attempts=3):
            #Extract entities and verify their validity with feedback loop.
            system_instruction = "You are an expert at extracting and validating entities."

            for attempt in range(max_attempts):
                # First attempt at extraction
                extraction_prompt = f'''
                Extract key entities from this question. 
                Return a JSON object with the extracted entities.

                Example 1: [example with entities]
                Example 2: [example with different entities]
                Example 3: [example with complex entities]

                Question: {question}
                Extraction:
                '''

                extracted_data = call_llm(extraction_prompt, system_instruction)

                try:
                    # Parse the extraction
                    data = json.loads(extracted_data)

                    # Verification step
                    verification_prompt = f'''
                    Verify if these extracted entities are complete and correct:

                    Question: {question}
                    Extracted entities: {json.dumps(data, indent=2)}

                    Check if:
                    1. All relevant entities are extracted
                    2. No irrelevant entities are included
                    3. All entity values are correct

                    Return a JSON with:
                    {{
                      "is_valid": true/false,
                      "validation_feedback": "detailed explanation",
                      "missing_entities": ["entity1", "entity2"],
                      "incorrect_entities": ["entity3"]
                    }}
                    '''

                    verification_result = call_llm(verification_prompt, system_instruction)
                    verification_data = json.loads(verification_result)

                    if verification_data.get("is_valid", False):
                        data["is_valid"] = True
                        data["validation_feedback"] = "All entities are valid."
                        return data

                    # If not valid and we have attempts left, refine with feedback
                    if attempt < max_attempts - 1:
                        feedback = verification_data.get("validation_feedback", "")
                        print(f"Validation failed (attempt {attempt+1}/{max_attempts}): {feedback}")
                        continue

                    # If we're out of attempts, return the best we have with validation info
                    data["is_valid"] = False
                    data["validation_feedback"] = verification_data.get("validation_feedback", "Unknown validation error")
                    return data

                except Exception as e:
                    print(f"Error in extraction/validation (attempt {attempt+1}/{max_attempts}): {str(e)}")
                    if attempt >= max_attempts - 1:
                        return {
                            "is_valid": False,
                            "validation_feedback": f"Error during processing: {str(e)}"
                        }

            return {
                "is_valid": False,
                "validation_feedback": "Failed to extract valid entities after multiple attempts."
            }
        ```

        VALIDATION IMPLEMENTATION STRATEGIES:
        1. Create detailed verification functions for each major processing step
        2. Implement max_attempts limits on all retry loops (typically 3-5 attempts)
        3. Pass specific feedback from verification to subsequent retry attempts
        4. Log all verification failures to help identify systemic issues
        5. Design fallback behaviors when verification repeatedly fails

        

            PREVIOUSLY TRIED APPROACHES (LAST 5 SCRIPTS). YOUR APPROACH MUST BE SUBSTANTIVELY DIFFERENT THAN THESE:
            
PREVIOUSLY TRIED APPROACHES (LAST 5 SCRIPTS):

=== SCRIPT FROM ITERATION 0 (baseline, ACCURACY: 0.80) ===
Approach: Simple baseline script: Direct LLM call without sophisticated techniques

```python
import os
from google import genai
from google.genai import types

def call_llm(prompt, system_instruction=None):
    """Call the Gemini LLM with a prompt and return the response"""
    try:
        # Initialize the Gemini client
        client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))

        # Call the API with system instruction if provided
        if system_instruction:
            response = client.models.generate_content(
                model="gemini-2.0-flash", 
                config=types.GenerateContentConfig(
                    system_instruction=system_instruction
                ),
                contents=prompt
            )
        else:
            response = client.models.generate_content(
                model="gemini-2.0-flash",
                contents=prompt
            )

        return response.text
    except Exception as e:
        print(f"Error calling Gemini API: {str(e)}")
        return f"Error: {str(e)}"

def main(question):
    """
    Baseline script: Simple direct LLM call without sophisticated techniques.
    This establishes the baseline performance capability for this dataset.
    """
    system_instruction = "You are a helpful assistant. Answer the question directly and concisely based on the information provided."

    # Simple, direct call to LLM
    answer = call_llm(question, system_instruction)

    return answer
    
```


            LEARNINGS FROM PREVIOUS ITERATIONS:
            
        ACCUMULATED LEARNINGS FROM PREVIOUS ITERATIONS:
        Okay, here's the updated and synthesized version of our learnings, focusing on the specifics of this multi-hop reasoning dataset and task, organized into the requested sections:

**1. DATASET PATTERNS & CHARACTERISTICS**

*   **Explicit Multi-Hop Reasoning:** Questions are explicitly framed as multi-hop reasoning tasks, demanding information linkage across multiple documents. Single document retrieval is insufficient.
    *   *Example:* Questions require linking information about a person's career, location, and related events found in separate documents.
*   **Diverse Subject Matter:** Questions span various domains including history, geography, entertainment, and current events.
    *   *Example:* Questions range from historical figures to film trivia to geographical locations of organizations.
*   **Concise Factual Answers:** Answers are generally concise named entities, dates, or short phrases, directly responding to the question.
    *   *Example:* "1984", "Los Angeles", "Emilio Estevez".
*   **Answer Source Constraint:** Answers are *explicitly* within the provided supporting documents. The model should *not* require external knowledge. The core challenge is information retrieval and synthesis from provided texts.
*   **Information Overload:** "Supporting Documents" contain significant irrelevant information (noise). Effective models must filter and focus on relevant passages.
*   **Ambiguity:** Terms and entities can be ambiguous. Context is crucial for disambiguation.
*   **Synonymy and Paraphrasing:** Concepts are expressed differently in questions and supporting documents, requiring understanding of synonyms and paraphrases.
*   **Reasoning Depth Variation:** The number of inference "hops" to answer questions varies.
*   **Edge Cases Exist:**
    *   **Missing Information:** Documents *may not* contain the complete answer, even if relevant.
    *   **Contradictory Information:** Documents might contain conflicting information, requiring a resolution strategy.
    *   **Coreference Resolution:** Pronoun references must be resolved (e.g., "He" refers to whom?).
*   **Complex Multi-Hop Reasoning (Reinforced):** The dataset heavily relies on complex multi-hop reasoning. Answering a question often requires connecting information from multiple documents, sometimes in subtle ways.
    *   *Example:* Connecting "Emilio Estevez starred in Nightmares" with another document mentioning a film released in the same year.
*   **Information Synthesis Required (Reinforced):** Correct answers require synthesizing information rather than directly quoting a single document.
    *   *Example:* Combining facts, dates, names, and contexts to produce a derived answer.
*   **Real-World Knowledge Assumptions (Identified):** The questions often implicitly assume some basic real-world knowledge not explicitly in the documents.
    *   *Example:* Needing common-sense reasoning to understand the question's context even with supporting documents.

**2. EFFECTIVE TASK-SPECIFIC STRATEGIES**

*   *(Initial State: No strategies have been proven effective yet as this is the baseline.)*

**3. COMMON FAILURE MODES ON THIS DATASET**

*   **Information Overload:** The LLM struggles to sift through the volume of information provided in the supporting documents.
*   **Inability to Connect Disparate Facts:** The system fails when the answer requires linking information that isn't explicitly connected in the documents.
    *   *Example:* Failing to connect Emilio Estevez and Nightmares with another document mentioning a different film released in the same year.
*   **Poor Summarization and Extraction:** The system struggles to extract the specific requested detail, returning more general information.
    *   *Example:* In the "Eric S. Pistorius" example, failing to extract the *concept* of his work, instead returning a more general description of his specializations as an attorney.
*   **Lack of Temporal Reasoning:** Weakness in temporal reasoning; the system can't easily determine which events occurred in the same year.
    *   *Example:* Failure involving Emilio Estevez demonstrates a weakness in temporal reasoning; the system can't easily determine which events occurred in the same year without more sophisticated processing.
*   **Basic Information Extraction is Not Enough:** Simply extracting facts from documents is insufficient. The system must be able to reason *with* those facts.

**4. EXPERIMENT LOG & FINDINGS**

*   **Experiment 0: Baseline LLM Call**
    *   *Description:* Direct call to the LLM with the question and supporting documents.
    *   *Accuracy:* 80%
    *   *Findings:* Baseline performance indicates that the task complexity exceeds the capabilities of a simple LLM call without additional reasoning or information retrieval techniques. Highlights the need for a more structured approach to reasoning, potentially involving intermediate steps to identify relevant entities, relationships, and temporal information.
    *   *Failure Mode Examples:*
        *   Inability to connect disparate facts across documents.
        *   Poor summarization and extraction of specific details.
        *   Lack of temporal reasoning.

**5. NEXT RESEARCH DIRECTIONS**

*   **Implement Document Ranking/Filtering:** Implement a mechanism to rank or filter documents based on their relevance to the question *before* feeding them to the LLM.
    *   *Potential Techniques:* Keyword matching, semantic similarity, named entity recognition.
*   **Introduce a Chain-of-Thought Prompting:** Structure the LLM prompt to encourage chain-of-thought reasoning.
    *   *Example Prompt Structure:* Ask the LLM to first identify relevant entities, then identify relevant relationships between those entities, and finally answer the question based on those relationships.
*   **Fine-tune LLM (if feasible):** If resources allow, consider fine-tuning the LLM on a subset of the dataset to improve its ability to perform multi-hop reasoning and information synthesis. This would require a carefully constructed training set with questions and corresponding "reasoning paths".
*   **Incorporate External Knowledge (Cautiously):** Consider incorporating external knowledge sources (e.g., a knowledge graph or a database of facts) to augment the information provided in the documents. However, be careful to avoid introducing irrelevant or contradictory information.
*   **Implement a Temporal Reasoning Module:** Specifically address the temporal reasoning challenges by incorporating a module that can reason about dates, time intervals, and the order of events. This module could be a rule-based system or a machine learning model trained on temporal reasoning tasks.
        

            CAPABILITY ASSESSMENT & IMPROVEMENT GUIDANCE:
            
        CAPABILITY ASSESSMENT & IMPROVEMENT GUIDANCE:
        SYSTEM ANALYSIS & GUIDANCE


        

            EXPLORATION GUIDANCE:
            1. Review the historical approaches, error patterns, and accumulated learnings carefully
            2. Review the FULL CODE of previous scripts to understand what has already been tried
            3. Design a new approach that is DISTINCTLY DIFFERENT from previous attempts. This approach should have a specific NEW HYPOTHESIS or variable you are trying to test. 
            4. CRITICAL: Include EMBEDDED EXAMPLES directly within your LLM prompts
            5. For each key function, show a complete worked example, or include multiple examples, including:
               - Input example that resembles the dataset
               - Step-by-step reasoning through the example
               - Properly formatted output
            6. Apply the insights from the ACCUMULATED LEARNINGS section to avoid repeating past mistakes
            7. Pay SPECIAL ATTENTION to the weaknesses and improvement suggestions from the capability assessment
            8. Consider implementing one or more of these LLM usage patterns:
               - Repeated validation with feedback loops
               - Multi-perspective analysis with synthesis
               - Dynamic input-dependent routing with an orchestrator
               - Hybrid approaches combining LLM with deterministic functions
               - Best-of-n solution generation and selection
               - ReAct pattern for interactive reasoning and action
               - If it is unknown how successful a processing state or part of the pipeline is, include verification steps to different parts of the pipeline in order to help deduce which parts are successful and where the system is breaking
               - Answer checkers to validate the final answer against the problem statement. If the answer is incorrect, the checker can send the answer back to an earlier part of the system for for refinement with feedback

            Here's how to call the Gemini API. Use this example without modification and don't invent configuration options:
            def call_llm(prompt, system_instruction=None):
    """Call the Gemini LLM with a prompt and return the response. DO NOT deviate from this example template or invent configuration options. This is how you call the LLM."""
    try:
        from google import genai
        from google.genai import types

        # Initialize the Gemini client
        client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))

        # Call the API with system instruction if provided
        if system_instruction:
            response = client.models.generate_content(
                model="gemini-2.0-flash", 
                config=types.GenerateContentConfig(
                    system_instruction=system_instruction
                ),
                contents=prompt
            )
        else:
            response = client.models.generate_content(
                model="gemini-2.0-flash",
                contents=prompt
            )

        return response.text
    except Exception as e:
        print(f"Error calling Gemini API: {str(e)}")
        return f"Error: {str(e)}"

            Since this is an EXPLORATION phase:
            - Try a fundamentally different approach to reasoning about the problem. Test a NEW HYPOTHESIS or variable, and add verification steps to deduce if this new change is helpful.
            - THIS IS KEY: Break down the problem into new, distinct reasoning steps based on past performance before you start coding
            - For EACH key LLM prompt, include a relevant example with:
              * Sample input similar to the dataset
              * Expected reasoning steps
              * Desired output format
            - Apply a verifier call to different parts of the pipeline in order to understand what parts of the pipeline of calls is successful and where the system is breaking
            - Pay special attention to addressing the primary issues from previous iterations
            - Ensure your new approach addresses the weaknesses identified in the capability assessment

            CRITICAL REQUIREMENTS:
            1. The script MUST properly handle all string literals - be extremely careful with quotes and triple quotes
            2. The script MUST NOT exceed 150 lines of code to prevent truncation
            3. Include detailed comments explaining your reasoning approach
            4. EVERY SINGLE LLM PROMPT must include at least one embedded example showing:
               - Sample input with reasoning
               - Desired output format
            5. Make proper use of error handling
            6. Implement robust capabilities to address the specific weaknesses identified in the capability assessment
            7. Do NOT use json.loads() in the LLM calls to process input data. JSON formatting is good to use to structure information as inputs and outputs, but attempting to have functions process JSON data explicitly with strict built-in functionality is error prone due to formatting issues and additional text that appears as documentation, reasoning, or comments. When passing data into another LLM call, you can read it as plain text rather than trying to load it in strict json format, is the better approach.

            Return a COMPLETE, RUNNABLE Python script that:
            1. Has a main function that takes a question string as input and returns the answer string
            2. Makes multiple LLM calls for different reasoning steps
            3. Has proper error handling for API calls
            4. Includes embedded examples in EVERY LLM prompt
            5. Is COMPLETE - no missing code, no "..." placeholders
            6. Closes all string literals properly

            This should be FUNDAMENTALLY DIFFERENT from all previous approaches. Do not reuse the same overall structure.

            BE EXTREMELY CAREFUL TO PROPERLY CLOSE ALL STRING QUOTES AND TRIPLE QUOTES!
            